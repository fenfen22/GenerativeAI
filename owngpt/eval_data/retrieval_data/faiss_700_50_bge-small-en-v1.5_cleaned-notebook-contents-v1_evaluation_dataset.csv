Question,Answer,Source,Retrived_doc_1_source,Retrived_doc_1_id,Retrived_doc_1_content,Retrived_doc_1_score,Retrived_doc_2_source,Retrived_doc_2_id,Retrived_doc_2_content,Retrived_doc_2_score,Retrived_doc_3_source,Retrived_doc_3_id,Retrived_doc_3_content,Retrived_doc_3_score,Retrived_doc_4_source,Retrived_doc_4_id,Retrived_doc_4_content,Retrived_doc_4_score,Retrived_doc_5_source,Retrived_doc_5_id,Retrived_doc_5_content,Retrived_doc_5_score,Retrived_doc_6_source,Retrived_doc_6_id,Retrived_doc_6_content,Retrived_doc_6_score,Retrived_doc_7_source,Retrived_doc_7_id,Retrived_doc_7_content,Retrived_doc_7_score,Retrived_doc_8_source,Retrived_doc_8_id,Retrived_doc_8_content,Retrived_doc_8_score,Retrived_doc_9_source,Retrived_doc_9_id,Retrived_doc_9_content,Retrived_doc_9_score,Retrived_doc_10_source,Retrived_doc_10_id,Retrived_doc_10_content,Retrived_doc_10_score,recall@1,recall@2,recall@3,recall@4,recall@5,recall@6,recall@7,recall@8,recall@9,recall@10
What is PyTorch?,"It’s a Python based scientific computing package targeted at two sets of audiences:
A replacement for numpy to use the power of GPUs
a deep learning research platform that provides maximum flexibility and speed",notebook 3_1,notebook 3_1,0.0,"markdown:
# Credits

This is heavily based on https://github.com/pytorch/tutorials'

 
markdown:
# What is PyTorch?

> **NOTE** In the last part of this lab cuda is used. If you have a cuda enabled machine, read the README.md in the root of this repo on how to use nvidia-docker.


It’s a Python based scientific computing package targeted at two sets of
audiences:
-  A replacement for numpy to use the power of GPUs
-  a deep learning research platform that provides maximum flexibility
   and speed'

 
markdown:
# Getting Started

In this lab you will get a quick start on what pytorch is and how to use it.

## 1. Tensors

Tensors are similar to numpy’s ndarrays, with the addition being that
Tensors can also be used on a GPU to accelerate computing.'

 
code:
['import torch'

 
markdown:
Construct a 5x3 matrix, uninitialized'

 
code:
x = torch.Tensor(5, 3)
print(x)'

 
markdown:
Construct a randomly initialized matrix'

 
code:
x = torch.rand(5, 3)
print(x)'

 
markdown:
['Get its size'

 
code:
print(x.size())'

 
markdown:
**NOTE**: `torch.Size` is in fact a tuple, so it supports the same operations that a tuple supports.'

 
code:
x[1:3] = 2
print(x)'

 
markdown:
# Assignment

Make use of the pytorch docs <http://pytorch.org/docs/torch>
1. Make a tensor of size (2, 17)
2. Make a torch.FloatTensor of size (3, 1)
3. Make a torch.LongTensor of size (5, 2, 1)
  - fill the entire tensor with 7s
4. Make a torch.ByteTensor of size (5,)
  - fill the middle 3 indices with ones such that it records [0, 1, 1, 1, 0]'

 
markdown:
## 2. Operations', ""There are multiple syntaxes for operations. Let's see addition as an example:"", '
### 2.1 Addition: syntax 1'

 
code:
y = torch.rand(5, 3)
print(x + y)'

 
markdown:
### 2.2 Addition: syntax 2'

 
code:
print(torch.add(x, y))'

 
markdown:
### 2.3 Addition: giving an output tensor'

 
code:
result = torch.Tensor(5, 3)
torch.add(x, y, out=result)
print(result)'

 
markdown:
### 2.4 Addition: in-place

adds `x`to `y`'

 
code:
y.add_(x)
print(y)'

 
markdown:
**NOTE**: Any operation that mutates a tensor in-place is post-fixed with an `_`. For example: `x.copy_(y)`, `x.t_()`, will change `x`.'

 
markdown:
You can use standard numpy-like indexing with all bells and whistles!'

 
code:
print(x[:, 1])'",0.602103590965271,notebook 3_2,0.0,"markdown:
# Credits

This is heavily influenced or copied from https://github.com/pytorch/tutorials'

 
markdown:
# Autograd: automatic differentiation

Central to all neural networks in PyTorch is the ``autograd`` package.
Let’s first briefly visit this, and we will then go to training our first neural network.

The `autograd` package provides automatic differentiation for all operations on Tensors.
It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.

Let us see this in more simple terms with some examples.'

 
markdown:
## 1. Tensor

`torch.Tensor` is the central class of the package. Setting the attribute `.requires_grad` to `True` will make the tensor ""record"" all operations on it. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into the `.grad` attribute.

![autograd.Variable](../static_files/autograd-variable.png)

There’s one more class which is very important for autograd implementation - a `Function`.

`Tensor` and `Function` are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each tensor has a `.grad_fn` attribute that references a `Function` that has created the `Tensor` (except for Tensors created by the user - their `grad_fn` is `None`).

If you want to compute the derivatives, you can call `.backward()` on a Tensor. If `Tensor` is a scalar (i.e. it holds a one element data), you don’t need to specify any arguments to backward(), however if it has more elements, you need to specify a `gradient` argument that is a tensor of matching shape.'

 
code:
['import torch'

 
markdown:
Create a tensor'

 
code:
x = torch.ones(2, 2, requires_grad=True)
print(x)'

 
markdown:
Do a tensor operation:'

 
code:
y = x + 2
print(y)'

 
markdown:
`y` was created as a result of an operation, so it has a `grad_fn`.'

 
code:
print(y.grad_fn)'

 
markdown:
Do more operations on y'

 
code:
z = y * y * 3
out = z.mean()

print(z)
print(out)'

 
markdown:
# Assignments

1. Create a Tensor that `requires_grad` of size (5, 5)
2. Sum the values in the Tensor'

 
markdown:
## 2. Gradients

Let’s backprop now. Because `out` contains a single scalar, `out.backward()` is equivalent to `out.backward(torch.tensor([1.0]))`'

 
code:
out.backward()'

 
markdown:
Print gradients d(out)/dx'

 
code:
'print(x.grad)'

 
markdown:
You should have a matrix of `4.5`. Let’s denote the tensor `out` with $o$.

We have:
$o = \\frac{1}{4}\\sum_i z_i$, $z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$.",0.6290080547332764,notebook 7_1,3.0,"code:
import torch.nn as nn

# define size variables
num_features = 28*28

class AutoEncoder(nn.Module):
    def __init__(self, hidden_units, latent_features=2):
        super(AutoEncoder, self).__init__()
        # We typically employ an ""hourglass"" structure
        # meaning that the decoder should be an encoder
        # in reverse.
        
        self.encoder = nn.Sequential(
            nn.Linear(in_features=num_features, out_features=hidden_units),
            nn.ReLU(),
            # bottleneck layer
            nn.Linear(in_features=hidden_units, out_features=latent_features)
        )

        self.decoder = nn.Sequential(
            nn.Linear(in_features=latent_features, out_features=hidden_units),
            nn.ReLU(),
            # output layer, projecting back to image size
            nn.Linear(in_features=hidden_units, out_features=num_features)
        )

    def forward(self, x): 
        outputs = {}', ""        # we don't apply an activation to the bottleneck layer"", '        z = self.encoder(x)
        
        # apply sigmoid to output to get pixel intensities between 0 and 1
        x_hat = torch.sigmoid(self.decoder(z))
        
        return {', ""            'z': z,"", ""            'x_hat': x_hat"", '        }


# Choose the shape of the autoencoder
net = AutoEncoder(hidden_units=128, latent_features=2)

if cuda:
    net = net.cuda()

print(net)'

 
markdown:
Following we define the PyTorch functions for training and evaluation.'

 
code:
import torch.optim as optim

# if you want L2 regularization, then add weight_decay to SGD
optimizer = optim.SGD(net.parameters(), lr=0.25)

# We will use pixel wise mean-squared error as our loss function
loss_function = nn.MSELoss()'

 
markdown:
We can test the forward pass by checking whether the output shape is the same as the as the input.'

 
code:
# test the forward pass
# expect output size of [32, num_features]
x, y = next(iter(train_loader))
print(f""x.shape = {x.shape}"")

if cuda:
    x = x.cuda()

outputs = net(x)
print(f""x_hat.shape = {outputs[\'x_hat\'].shape}"")'

 
markdown:
In the training loop we sample each batch and evaluate the error, latent space, and reconstructions on every epoch.

**NOTE** this will take a while on CPU.'

 
code:
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA

num_epochs = 100

train_loss = []
valid_loss = []

for epoch in range(num_epochs):
    batch_loss = []
    net.train()
    
    # Go through each batch in the training dataset using the loader
    # Note that y is not necessarily known as it is here
    for x, y in train_loader:
        
        if cuda:
            x = x.cuda()
        
        outputs = net(x)', ""        x_hat = outputs['x_hat']"", '', ""        # note, target is the original tensor, as we're working with auto-encoders"", '        loss = loss_function(x_hat, x)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        batch_loss.append(loss.item())",0.6821279525756836,notebook 5_3,4.0,"markdown:
When working with more complex data than what we use in this exercise, creating a PyTorch `DataLoader` on top of the dataset can be beneficial. A data loader is basically a fancy generator/iterator that we can use to abstract away all of the data handling and pre-processing + it's super useful for processing batches of data as well! Data loaders will come in handy later when you start to work on your projects, so be sure to check them out!"", '
For more information on how to use datasets and data loaders in PyTorch, [consult the official guide](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).'

 
markdown:
## One-hot encodings'

 
markdown:
We now create a simple function that returns the one-hot encoded representation of a given index of a word in our vocabulary. Notice that the shape of the one-hot encoding is equal to the entire vocabulary (which can be huge!). Additionally, we define a function to automatically one-hot encode a sentence.'

 
code:
def one_hot_encode(idx, vocab_size):
    """"""
    One-hot encodes a single word given its index and the size of the vocabulary.
    
    Args:
     `idx`: the index of the given word
     `vocab_size`: the size of the vocabulary
    
    Returns a 1-D numpy array of length `vocab_size`.
    """"""
    # Initialize the encoded array
    one_hot = np.zeros(vocab_size)
    
    # Set the appropriate element to one
    one_hot[idx] = 1.0

    return one_hot


def one_hot_encode_sequence(sequence, vocab_size):
    """"""
    One-hot encodes a sequence of words given a fixed vocabulary size.
    
    Args:
     `sentence`: a list of words to encode
     `vocab_size`: the size of the vocabulary
     
    Returns a 3-D numpy array of shape (num words, vocab size, 1).
    """"""
    # Encode each word in the sentence
    encoding = np.array([one_hot_encode(word_to_idx[word], vocab_size) for word in sequence])

    # Reshape encoding s.t. it has shape (num words, vocab size, 1)
    encoding = encoding.reshape(encoding.shape[0], encoding.shape[1], 1)
    
    return encoding

', ""test_word = one_hot_encode(word_to_idx['a'], vocab_size)"", ""print(f'Our one-hot encoding of \\'a\\' has shape {test_word.shape}.')"", '', ""test_sentence = one_hot_encode_sequence(['a
b'], vocab_size)"", ""print(f'Our one-hot encoding of \\'a b\\' has shape {test_sentence.shape}.')""]'

 
markdown:
Great! Now that we have our one-hot encodings in place, we can move on to the RNNs!'

 
markdown:
# Introduction to Recurrent Neural Networks (RNN)

Reading material: [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) and (optionally) [this lecture](https://www.youtube.com/watch?v=iWea12EAu6U&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z).

___",0.6890871524810791,notebook 3_3,0.0,"markdown:
# Purpose and goals
In this notebook you will implement a simple neural network in PyTorch.

The building blocks of PyTorch are Tensors, and Operations, with these we can form dynamic computational graphs that represent neural networks.', ""In this exercise we'll start right away by defining a logistic regression model using these simple building blocks."", ""We'll initially start with a simple 2D and binary (i.e. two-class) classification problem where the class decision boundary can be visualized."", 'Initially we show that logistic regression can only separate classes linearly.
Adding a nonlinear hidden layer to the algorithm permits nonlinear class separation.

In this notebook you should:
* **First** run the code as is, and see what it does.
* **Then** modify the code, following the instructions in the bottom of the notebook.
* **Lastly** play around a bit, and do some small experiments that you come up with.

> We assume that you are already familiar with backpropagation (if not please see [Andrej Karpathy](http://cs.stanford.edu/people/karpathy/) or [Michal Nielsen](http://neuralnetworksanddeeplearning.com/chap2.html)).'

 
markdown:
# Dependencies and supporting functions
Load dependencies and supporting functions by running the code block below.'

 
code:
%matplotlib inline
import matplotlib
import numpy as np
import matplotlib.pyplot as plt
import sklearn.datasets

# Do not worry about the code below for now, it is used for plotting later
def plot_decision_boundary(pred_func, X, y):
    #from https://github.com/dennybritz/nn-from-scratch/blob/master/nn-from-scratch.ipynb
    # Set min and max values and give it some padding
    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5
    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5
    
    h = 0.01
    # Generate a grid of points with distance h between them
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    ', ""    yy = yy.astype('float32')"", ""    xx = xx.astype('float32')"", '    # Predict the function value for the whole gid
    Z = pred_func(np.c_[xx.ravel(), yy.ravel()])[:,0]
    Z = Z.reshape(xx.shape)
    # Plot the contour and training examples
    plt.figure()
    plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu)
    plt.scatter(X[:, 0], X[:, 1], c=-y, cmap=plt.cm.Spectral)

def onehot(t, num_classes):
    out = np.zeros((t.shape[0], num_classes))
    for row, col in enumerate(t):
        out[row, col] = 1
    return out'

 
markdown:
# Problem ', ""We'll initally demonstrate that Multi-layer Perceptrons (MLPs) can classify nonlinear problems, whereas a simple logistic regression model cannot."", 'For ease of visualization and computational speed we initially experiment on the simple 2D half-moon dataset, visualized below.'",0.6957156658172607,notebook 3_4,0.0,"markdown:
# Credits
> This code is a slight modification to a translation (TensorFlow --> PyTorch) of a previous version of the [02456](http://kurser.dtu.dk/course/02456) course material. 
> [Original repo link (TensorFlow)](https://github.com/DeepLearningDTU/02456-deep-learning).
> [Translated repo link (PyTorch)](https://github.com/munkai/pytorch-tutorial/tree/master/2_intermediate).'

 
code:
import torch
from torch import nn
import torch.nn.functional as F
import torch.optim as optim
import torch.nn.init as init

%matplotlib inline
import matplotlib
import numpy as np
import matplotlib.pyplot as plt

from torch.nn.parameter import Parameter
from torchvision.datasets import MNIST'

 
markdown:
# MNIST dataset
MNIST is a dataset that is often used for benchmarking. The MNIST dataset consists of 70,000 images of handwritten digits from 0-9. The dataset is split into a 50,000 images training set, 10,000 images validation set and 10,000 images test set. The images are 28x28 pixels, where each pixel represents a normalised value between 0-255 (0=black and 255=white).

![MNIST.Exampel](../static_files/mnist.png)


## Primer', ""We use a feedforward neural network to classify the 28x28 mnist images. `num_features` is therefore $28 * 28=784$, i.e. we represent each image as a vector. The ordering of the pixels in the vector does not matter, so we could permutate all images using the same permutation and still get the same performance. (You are of course encouraged to try this using ``numpy.random.permutation`` to get a random permutation. This task is therefore called the _permutation invariant_ MNIST. Obviously this throws away a lot of structure in the data. In the next module we'll fix this with the convolutional neural network wich encodes prior knowledgde about data that has either spatial or temporal structure.  ""]'

 
markdown:
## MNIST', ""First let's load the MNIST dataset and plot a few examples:""]'

 
code:
mnist_trainset = MNIST(""./temp/"", train=True, download=True)
mnist_testset = MNIST(""./temp/"", train=False, download=True)'

 
code:
# To speed up training we'll only work on a subset of the data"", 'x_train = mnist_trainset.data[:1000].view(-1, 784).float()
targets_train = mnist_trainset.targets[:1000]

x_valid = mnist_trainset.data[1000:1500].view(-1, 784).float()
targets_valid = mnist_trainset.targets[1000:1500]

x_test = mnist_testset.data[:500].view(-1, 784).float()
targets_test = mnist_testset.targets[:500]

print(""Information on dataset"")
print(""x_train"", x_train.shape)
print(""targets_train"", targets_train.shape)
print(""x_valid"", x_valid.shape)
print(""targets_valid"", targets_valid.shape)
print(""x_test"", x_test.shape)
print(""targets_test"", targets_test.shape)'",0.6967642307281494,notebook 3_1,1.0,"markdown:
You can use standard numpy-like indexing with all bells and whistles!'

 
code:
print(x[:, 1])'

 
markdown:
**Read later** 100+ Tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc are described here <http://pytorch.org/docs/torch>'

 
markdown:
# Assignment

1. multiplication of two tensors (see [torch.Tensor.mul](http://pytorch.org/docs/master/tensors.html#torch.Tensor.mul))
2. do the same, but inplace
3. division of two tensors (see [torch.Tensor.div](http://pytorch.org/docs/master/tensors.html#torch.Tensor.div))
4. perform a matrix multiplication of two tensors of size (2, 4) and (4, 2)'

 
markdown:
## 3. Numpy Bridge

Converting a torch Tensor to a numpy array and vice versa is a breeze.

The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.

### 3.1 Converting torch Tensor to numpy Array'

 
code:
a = torch.ones(5)
print(a)'

 
code:
b = a.numpy()
print(b)'

 
markdown:
See how the numpy array changed in value: the `numpy()` method provides a *view* of the original tensor, not a copy.'

 
code:
a.add_(1)
print(a)
print(b)'

 
markdown:
### 3.2 Converting numpy Array to torch Tensor

See how changing the np array changed the torch Tensor automatically'

 
code:
import numpy as np
a = np.ones(5)
b = torch.from_numpy(a)
np.add(a, 1, out=a)
print(a)
print(b)'

 
markdown:
# Assignment

1. create a tensor of size (5, 2) containing ones
2. now convert it to a numpy array
3. now convert it back to a torch tensor'

 
markdown:
All the Tensors on the CPU except a CharTensor support converting to NumPy and back.

## 4 CUDA Tensors

Tensors can be moved onto GPU using the `.cuda` function.
This is not necessary, but check the `README.md` for details on how to use a GPU with docker.'

 
code:
# let us run this cell only if CUDA is available
if torch.cuda.is_available():
    x = x.cuda()
    y = y.cuda()
    z = x + y
    # Notice that the tensors are now of type torch.cuda.FloatTensor (notice the cuda in there)
    # This is meant as a tensor to be run on the GPU.
    # The .cuda() does this to any parameter it is applied to.
    print(x)
    print(y)
    print(z)
else:
    print(""CUDA not available on your machine."")'

 
code:
'[]'",0.7118555307388306,notebook 5_1,24.0,"# Compute the positional encodings once in log space.
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0)', ""        self.register_buffer('pe', pe)"", '
    def forward(self, x):
        x = x + self.pe[:, :x.size(1)]
        return self.dropout(x)
', ""# let's assume we havee a sequence of length 10 and embedding of length 128"", '# how their positional encoding looks like

plt.figure(figsize=(10, 4))

# we define the positional encoding for a 128-dimensional vector and for this 
# example we do not use dropout
pe = PositionalEncoding(64, dropout=0, max_len=1000)

# note here we are assuming our input to be
# batch_size x sequence_length x d_model
# but in pytorch they are assuming 
# sequence_length x batch_size x d_model
# we also assume zeros so we can see how the positional encoding looks like
x_inputs = torch.zeros(1, 512, 64)
y = pe(x_inputs)

sns.heatmap(y.squeeze(0).T, cmap=sns.color_palette(""viridis"", as_cmap=True))', ""plt.ylabel('Dimension')"", ""plt.xlabel('Position in the sentence')"", 'plt.gca().invert_yaxis()
plt.show()

# in the figure below each row corresponds to the vector we are adding 
# to our embedding vector when the word is at that position in the sentence'

 
markdown:
### IV.b Base layers

*Figure: (Left) A layer of base Transformer layer with three components: multi-head attention layer, feed-forward layer, and add & norm layer. 
(Right) Multi-head attention layer.*

<img src=""images/transformer-layer.png"" alt=""base Transformer layer (without conditioning)"" width=""200"" style=""margin-right: 100px""/>
<img src=""images/multi-head-attention.png"" alt=""Multi-head attention"" width=""200""/>

Each base layer of index $l$ takes a sequence of hidden state $\\mathbf{h}_{1:T}^l$ as input, and output another sequence $\\mathbf{h}_{1:T}^{l+1}$.",0.7157503962516785,notebook 3_3,2.0,"code:
import torch
from torch import nn
import torch.nn.functional as F'

 
markdown:
[`Parameters`](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter) have a very special property when used with [`Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html?highlight=module#torch.nn.Module)s - when they’re assigned as `Module` attributes they are automatically added to the list of its parameters, and will appear e.g. in the `parameters()` iterator. \\
Assigning a Tensor doesn’t have such effect. This is because one might want to cache some temporary state (more on this later) in the model. If there was no such class as `Parameter`, these temporaries would get registered too.'

 
code:
class Net(nn.Module):

    def __init__(self):
        super(Net, self).__init__()
        # Setting up variables, these variables are weights in your 
        # network that can be updated while running our graph.
        # Notice, to make a hidden layer, the weights need to have the 
        # following dimensionality:
        #   W[number_of_units_going_out, number_of_units_going_in]
        #   b[number_of_units_going_out]
        # in the example below we have 2 input units (num_features) and 2 output units (num_output)
        # so our weights become W[2, 2], b[2]
        # if we want to make a hidden layer with 100 units, we need to define the shape of the
        # first weight to W[100, 2], b[2] and the shape of the second weight to W[2, 100], b[2]
        
        # first layer
        self.W_1 = nn.Parameter(torch.randn(num_output, num_features)) 
        self.b_1 = nn.Parameter(torch.randn(num_output))
        
        # second layer (to be completed as an exercise)
        # NB when you create a second layer, remember that you also must change parts of the first layer
        # self.W_2 = <YOUR CODE HERE>
        # self.b_2 = <YOUR CODE HERE>
        
    def forward(self, x):
        # Setting up ops, these ops will define edges along our computational graph
        # The below ops will compute a logistic regression, 
        # but can be modified to compute a neural network
        x = F.linear(x, self.W_1, self.b_1)
        
        # second layer (to be completed as an exercise)
        # NB when you create a second layer, remember that you also must change parts of the first layer
        # x = F.linear(x, self.W_2, self.b_2)
        return F.softmax(x, dim=1) # softmax to be performed on the second dimension

net = Net()'

 
markdown:
Knowing how to print your tensors is useful'

 
code:
# list all parameters in your network
print(""NAMED PARAMETERS"")
print(list(net.named_parameters()))
print()
# the .parameters() method simply gives the Tensors in the list
print(""PARAMETERS"")
print(list(net.parameters()))
print()",0.722450852394104,notebook 7_3,3.0,"code:
from torch.autograd import Variable
import os

tmp_img = ""tmp_gan_out.png""
discriminator_loss, generator_loss = [], []

num_epochs = 50
for epoch in range(num_epochs):
    batch_d_loss, batch_g_loss = [], []
    
    for x, _ in train_loader:
        batch_size = x.size(0)
        # True data is given label 1, while fake data is given label 0
        true_label = torch.ones(batch_size, 1).to(device)
        fake_label = torch.zeros(batch_size, 1).to(device)
        
        discriminator.zero_grad()
        generator.zero_grad()
        
        # Step 1. Send real data through discriminator
        #         and backpropagate its errors.
        x_true = Variable(x).to(device)        
        output = discriminator(x_true)
        
        error_true = loss(output, true_label)
        error_true.backward()
        
        # Step 2. Generate fake data G(z), where z ~ N(0, 1)
        #         is a latent code.
        z = torch.randn(batch_size, latent_dim, 1, 1)
        z = Variable(z, requires_grad=False).to(device)
        
        x_fake = generator(z)
            
        # Step 3. Send fake data through discriminator
        #         propagate error and update D weights.
        # --------------------------------------------
        # Note: detach() is used to avoid compounding generator gradients
        output = discriminator(x_fake.detach()) 
        
        error_fake = loss(output, fake_label)
        error_fake.backward()
        discriminator_optim.step()
        
        # Step 4. Send fake data through discriminator _again_
        #         propagate the error of the generator and
        #         update G weights.
        output = discriminator(x_fake)
        
        error_generator = loss(output, true_label)
        error_generator.backward()
        generator_optim.step()
        
        batch_d_loss.append((error_true/(error_true + error_fake)).item())
        batch_g_loss.append(error_generator.item())

    discriminator_loss.append(np.mean(batch_d_loss))
    generator_loss.append(np.mean(batch_g_loss))
    
    # -- Plotting --
    f, axarr = plt.subplots(1, 2, figsize=(18, 7))",0.7241029739379883,1.0,1.0,1.0,1.0,1.0,1.0,2.0,2.0,2.0,2.0
What is the MNIST dataset?,"MNIST is a dataset that is often used for benchmarking. The MNIST dataset consists of 70,000 images of handwritten digits from 0-9. The dataset is split into a 50,000 images training set, 10,000 images validation set and 10,000 images test set. The images are 28x28 pixels, where each pixel represents a normalised value between 0-255 (0=black and 255=white).
<image>",notebook 3_4,notebook 7_1,2.0,"<img src=""static/autoencoder.png"" />

*The exercises are found at the bottom of the notebook*'

 
markdown:
## MNIST
First let us load the MNIST dataset and plot a few examples. In this notebook we will use the *dataloaders* and *datasets* provided by PyTorch. Defining the loading of datasets using a dataloader has the advantage that it only load the data that is *neccessary* into memory, which enables us to use very large scale datasets.

We only load a limited amount of classes defined by the `classes` variable to speed up training.'

 
code:
import torch
cuda = torch.cuda.is_available()

from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor

# Flatten the 2d-array image into a vector
flatten = lambda x: ToTensor()(x).view(28**2)

# Define the train and test sets
dset_train = MNIST(""./"", train=True,  transform=flatten, download=True)
dset_test  = MNIST(""./"", train=False, transform=flatten)

# The digit classes to use
classes = [3, 7]

def stratified_sampler(labels, classes):
    """"""Sampler that only picks datapoints corresponding to the specified classes""""""
    from functools import reduce
    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))
    indices = torch.from_numpy(indices)
    return SubsetRandomSampler(indices)


# The loaders perform the actual work
batch_size = 64
train_loader = DataLoader(dset_train, batch_size=batch_size,
                          sampler=stratified_sampler(dset_train.targets, classes), pin_memory=cuda)
test_loader  = DataLoader(dset_test, batch_size=batch_size, 
                          sampler=stratified_sampler(dset_test.targets, classes), pin_memory=cuda)'

 
code:
# Plot a batch of MNIST examples
f, axarr = plt.subplots(4, 16, figsize=(16, 4))

# Load a batch of images into memory
images, labels = next(iter(train_loader))

for i, ax in enumerate(axarr.flat):
    ax.imshow(images[i].view(28, 28), cmap=""binary_r"")', ""    ax.axis('off')"", '    ', ""plt.suptitle('MNIST handwritten digits')"", 'plt.show()'

 
markdown:
### Building the model
When defining the model the latent layer $z$ must act as a bottleneck of information. We initialize the AE with 1 hidden layer in the encoder and decoder using ReLU units as nonlinearities. The latent layer has a dimensionality of 2 in order to make it easy to visualise. Since $x$ are pixel intensities that are normalized between 0 and 1, we use the sigmoid nonlinearity to model the reconstruction.'

 
code:
import torch.nn as nn

# define size variables
num_features = 28*28",0.4881294369697571,notebook 4_1,2.0,"code:
# Load the MNIST data. 

# Note that we reshape the data from:
#   (nsamples, num_features) = (nsamples, channels * height * width)
# to:
#   (nsamples, channels, height, width)
# in order to retain the spatial arrangements of the pixels.
', ""data = np.load('mnist.npz')"", 'channels, height, width = 1, 28, 28


def get_data(split, size):
    x = data[f""X_{split}""][:size].astype(\'float32\')
    x = x.reshape((-1, channels, height, width))
    targets = data[f""y_{split}""][:size].astype(\'int64\')
    return torch.from_numpy(x), torch.from_numpy(targets)

', ""x_train, targets_train = get_data('train', 50000)"", ""x_valid, targets_valid = get_data('valid', 2000)"", ""x_test, targets_test = get_data('test', 5000)"", '
num_classes = len(np.unique(targets_train))

print(""Information on dataset"")
print(""Shape of x_train:"", x_train.shape)
print(""Shape of targets_train:"", targets_train.shape)
print(""Shape of x_valid:"", x_valid.shape)
print(""Shape of targets_valid:"", targets_valid.shape)
print(""Shape of x_test:"", x_test.shape)
print(""Shape of targets_test:"", targets_test.shape)'

 
code:
# Plot a few MNIST examples
plt.figure(figsize=(7, 7))
plt.imshow(make_grid(x_train[:100], nrow=10).permute(1, 2, 0))', ""plt.axis('off')"", 'plt.show()'

 
markdown:
# Define a simple feed forward neural network'

 
code:
assert (channels, height, width) == x_train.shape[1:]
n_features = channels * height * width


class PrintSize(nn.Module):
    """"""Utility module to print current shape of a Tensor in Sequential, only at the first forward pass.""""""
    
    first = True
    
    def forward(self, x):
        if self.first:
            print(f""Size: {x.size()}"")
            self.first = False
        return x


class Model(nn.Module):

    def __init__(self):
        super(Model, self).__init__()
        activation_fn = nn.ReLU

        self.net = nn.Sequential(
            nn.Flatten(),  # from (1, channels, height, width) to (1, channels * height * width)
            nn.Linear(n_features, 128),
            activation_fn(),
            nn.Linear(128, 128),
            activation_fn(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.net(x)


model = Model()
print(model)

loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)'

 
code:
# Test the forward pass with dummy data
out = model(torch.randn(2, 1, 28, 28))
print(""Output shape:"", out.size())
print(f""Output logits:\{out.detach().numpy()}"")
print(f""Output probabilities:\{out.softmax(1).detach().numpy()}"")'

 
markdown:
# Train network'",0.5149657726287842,notebook 7_2,12.0,"code:
#plot a few MNIST examples
f, axarr = plt.subplots(4, 16, figsize=(16, 4))

# Load a batch of images into memory
images, labels = next(iter(train_loader))

for i, ax in enumerate(axarr.flat):
    ax.imshow(images[i].view(28, 28), cmap=""binary_r"")', ""    ax.axis('off')"", '    ', ""plt.suptitle('MNIST handwritten digits')"", 'plt.show()'

 
markdown:
## Building the model
When defining the model the latent layer must act as a bottleneck of information, so that we ensure that we find a strong internal representation. We initialize the VAE with 1 hidden layer in the encoder and decoder using relu units as non-linearity.'

 
code:
class VariationalAutoencoder(nn.Module):
    """"""A Variational Autoencoder with
    * a Bernoulli observation model `p_\\theta(x | z) = B(x | g_\\theta(z))`
    * a Gaussian prior `p(z) = N(z | 0, I)`
    * a Gaussian posterior `q_\\phi(z|x) = N(z | \\mu(x), \\sigma(x))`
    """"""
    
    def __init__(self, input_shape:torch.Size, latent_features:int) -> None:
        super(VariationalAutoencoder, self).__init__()
        
        self.input_shape = input_shape
        self.latent_features = latent_features
        self.observation_features = np.prod(input_shape)",0.5473443269729614,notebook 3_4,1.0,"code:
# plot a few MNIST examples
idx, dim, classes = 0, 28, 10
# create empty canvas
canvas = np.zeros((dim*classes, classes*dim))

# fill with tensors
for i in range(classes):
    for j in range(classes):
        canvas[i*dim:(i+1)*dim, j*dim:(j+1)*dim] = x_train[idx].reshape((dim, dim))
        idx += 1

# visualize matrix of tensors as gray scale image
plt.figure(figsize=(4, 4))', ""plt.axis('off')"", ""plt.imshow(canvas, cmap='gray')"", ""plt.title('MNIST handwritten digits')"", 'plt.show()'

 
markdown:
## Model

One of the large challenges in deep learning is the amount of hyperparameters that needs to be selected, and the lack of a good principled way of selecting them.
Hyperparameters can be found by experience (guessing) or some search procedure (often quite slow).
Random search is easy to implement and performs decent: http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf . 
More advanced search procedures include [Spearmint](https://github.com/JasperSnoek/spearmint) and many others.

**In practice a lot of trial and error is almost always involved.** This can be frustrating and time consuming, but the best thing to do is to think as a scientist, and go about it in a ordered manner --> monitor as much as you can, take notes, and be deliberate!

Below are some guidelines that you can use as a starting point to some of the most important hyperparameters. 
(*regularization* is also very important, but will be covered later.)


### Ballpark estimates of hyperparameters
__Number of hidden units and network structure:__', ""You'll have to experiment. One rarely goes below 512 units for feedforward networks (unless your are training on CPU...)."", ""There's some research into stochastic depth networks: https://arxiv.org/pdf/1603.09382v2.pdf, but in general this is trial and error."", '
__Parameter initialization:__
Parameter initialization is extremely important.
PyTorch has a lot of different initializers, check the [PyTorch API](http://pytorch.org/docs/master/nn.html#torch-nn-init). Often used initializer are
1. Kaiming He
2. Xavier Glorot
3. Uniform or Normal with small scale (0.1 - 0.01)
4. Orthogonal (this usually works very well for RNNs)

Bias is nearly always initialized to zero using the [torch.nn.init.constant(tensor, val)](http://pytorch.org/docs/master/nn.html#torch.nn.init.constant)

__Mini-batch size:__
Usually people use 16-256. Bigger is not allways better. With smaller mini-batch size you get more updates and your model might converge faster. Also small batch sizes use less memory, which means you can train a model with more parameters.",0.5880793333053589,notebook 3_4,0.0,"markdown:
# Credits
> This code is a slight modification to a translation (TensorFlow --> PyTorch) of a previous version of the [02456](http://kurser.dtu.dk/course/02456) course material. 
> [Original repo link (TensorFlow)](https://github.com/DeepLearningDTU/02456-deep-learning).
> [Translated repo link (PyTorch)](https://github.com/munkai/pytorch-tutorial/tree/master/2_intermediate).'

 
code:
import torch
from torch import nn
import torch.nn.functional as F
import torch.optim as optim
import torch.nn.init as init

%matplotlib inline
import matplotlib
import numpy as np
import matplotlib.pyplot as plt

from torch.nn.parameter import Parameter
from torchvision.datasets import MNIST'

 
markdown:
# MNIST dataset
MNIST is a dataset that is often used for benchmarking. The MNIST dataset consists of 70,000 images of handwritten digits from 0-9. The dataset is split into a 50,000 images training set, 10,000 images validation set and 10,000 images test set. The images are 28x28 pixels, where each pixel represents a normalised value between 0-255 (0=black and 255=white).

![MNIST.Exampel](../static_files/mnist.png)


## Primer', ""We use a feedforward neural network to classify the 28x28 mnist images. `num_features` is therefore $28 * 28=784$, i.e. we represent each image as a vector. The ordering of the pixels in the vector does not matter, so we could permutate all images using the same permutation and still get the same performance. (You are of course encouraged to try this using ``numpy.random.permutation`` to get a random permutation. This task is therefore called the _permutation invariant_ MNIST. Obviously this throws away a lot of structure in the data. In the next module we'll fix this with the convolutional neural network wich encodes prior knowledgde about data that has either spatial or temporal structure.  ""]'

 
markdown:
## MNIST', ""First let's load the MNIST dataset and plot a few examples:""]'

 
code:
mnist_trainset = MNIST(""./temp/"", train=True, download=True)
mnist_testset = MNIST(""./temp/"", train=False, download=True)'

 
code:
# To speed up training we'll only work on a subset of the data"", 'x_train = mnist_trainset.data[:1000].view(-1, 784).float()
targets_train = mnist_trainset.targets[:1000]

x_valid = mnist_trainset.data[1000:1500].view(-1, 784).float()
targets_valid = mnist_trainset.targets[1000:1500]

x_test = mnist_testset.data[:500].view(-1, 784).float()
targets_test = mnist_testset.targets[:500]

print(""Information on dataset"")
print(""x_train"", x_train.shape)
print(""targets_train"", targets_train.shape)
print(""x_valid"", x_valid.shape)
print(""targets_valid"", targets_valid.shape)
print(""x_test"", x_test.shape)
print(""targets_test"", targets_test.shape)'",0.59264075756073,notebook 5_1,11.0,"code:
max_dataset_size = 1000 # let's use a small subset for now,"", 'max_seq_size = 10 # and very short sequences

# load and tokenizer the dataset
def batch_tokenize(batch: List[Dict[str, Any]], max_length=max_seq_size, tokenizer: tokenizers.Tokenizer = None, key:str=""text"") -> torch.Tensor:
    texts = batch[key]
    encodings = tokenizer.encode_batch(texts)
    return {""token_ids"": [x.ids[:max_length] for x in encodings]}

# load AG News, take a subset of `max_dataset_size` rows and tokenize
dataset = datasets.load_dataset(""ag_news"")
dataset = datasets.DatasetDict({split: dset.select(range(max_dataset_size)) if len(dset) > max_dataset_size else dset for split, dset in dataset.items()})
dataset = dataset.map(partial(batch_tokenize, tokenizer=glove_tokenizer), batched=True, num_proc=2, batch_size=10)
rich.print(dataset)'

 
code:
class RNNLM(torch.nn.Module):
    """"""A simple implementation of a language model using RNNs.""""""
    def __init__(self, vectors:torch.Tensor):
        super().__init__()
        # register the embeddings
        self.embeddings = torch.nn.Embedding(*glove_vectors.shape)
        self.embeddings.weight.data = glove_vectors

        # register the LSTM
        self.rnn = torch.nn.LSTM(
            input_size=glove_vectors.shape[1],
            hidden_size=glove_vectors.shape[1],
            num_layers=1,
            batch_first=True,
        )

        # project the output of the LSTM (hidden state) back to the vocabulary space
        self.proj = nn.Linear(glove_vectors.shape[1], glove_vectors.shape[0], bias=False)
        # init the projection using the embeddings weights
        self.proj.weight.data = glove_vectors

    def forward(self, token_ids: torch.Tensor, retain_ws:bool=False) -> torch.Tensor:
        # convert the tokens into vectors
        ws = self.embeddings(token_ids)

        # store the word vectors for debugging
        if retain_ws:
          ws.retain_grad()
          self.ws = ws

        # shift the input `ws` right
        w0 = torch.zeros((ws.shape[0], 1, self.embeddings.weight.shape[1]),
                         device=self.embeddings.weight.device, dtype=torch.long)
        ws_shifted = torch.cat([w0, ws[:, :-1]], dim=1)

        # call the RNN: w_{-1:T-1} -> h{1:T}
        hidden_states, _ = self.rnn(ws_shifted)

        # project the hidden state to the vocabulary space
        logits = self.proj(hidden_states)
        return logits",0.7188124656677246,notebook 7_4,5.0,"|-|Autoregressive|Variational Autoencoders|Generative Adversarial Networks|Flows|
|-|--------------|---|---|---|
|Objective|log-likelihood (stable)|doubly stochastic ELBO (stable)|approximate adversarial loss (unstable)|log-likelihood (stable)|
|Latent space|None|dimension collapsing|low dimensional|high-dimensional|
|Architecture|requires ordering, arbitrary data|arbitrary|arbitrary, continuous data|requires partitioning (NVP), continuous data|'

 
code:
'[]'",0.7202327251434326,notebook 7_3,0.0,"markdown:
<div class=""alert alert-danger"">
It is recommended to run this notebook on a GPU
</div>'

 
code:
import matplotlib.pyplot as plt
from IPython.display import Image, display, clear_output
import numpy as np
%matplotlib nbagg
%matplotlib inline
plt.style.use([""seaborn-deep"", ""seaborn-whitegrid""])'

 
markdown:
# Generative Adversarial Networks

Generative Adversarial Networks (GAN) [[Goodfellow, 2014]](https://arxiv.org/abs/1406.2661) have recently become a popular alternative to variational autoencoders for generative modelling and to a lesser extend semi-supervised learning. They also represent the state-of-the-art in modelling of realistic images and video just four years after their introduction. Below you can see a comparison of the development in GANs for generation of realistic faces from 2014 until today.

<img src=""../static_files/GAN-celebA.jpg"" alt=""GAN performance over the years"" width=""600px""/>

Different variants of GANs have also proven to perform well on tasks such inpainting, super-resolution and image-to-image translation. In this notebook we will again work with a subset of the MNIST-dataset in order to compare with VAEs.'

 
code:
import torch
cuda = torch.cuda.is_available()
device = torch.device(""cuda:0"" if cuda else ""cpu"")

from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor
from functools import reduce

# The digit classes to use, these need to be in order because
# we are using one-hot representation
classes = np.arange(2)

def one_hot(labels):
    y = torch.eye(len(classes)) 
    return y[labels]

# Define the train and test sets
dset_train = MNIST(""./"", train=True, download=True, transform=ToTensor(), target_transform=one_hot)
dset_test  = MNIST(""./"", train=False, transform=ToTensor(), target_transform=one_hot)

def stratified_sampler(labels):
    """"""Sampler that only picks datapoints corresponding to the specified classes""""""
    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))
    indices = torch.from_numpy(indices)
    return SubsetRandomSampler(indices)


batch_size = 64
# The loaders perform the actual work
train_loader = DataLoader(dset_train, batch_size=batch_size,
                          sampler=stratified_sampler(dset_train.train_labels), pin_memory=cuda)
test_loader  = DataLoader(dset_test, batch_size=batch_size, 
                          sampler=stratified_sampler(dset_test.test_labels), pin_memory=cuda)'

 
markdown:
# Adversarial learning",0.7204737663269043,CourseOutline.txt,0.0,"The purpose of this course is to give the student a detailed understanding of the deep artificial neural network models, their training, computational frameworks for deployment on fast graphical processing units, their limitations and how to formulate learning in a diverse range of settings. These settings include classification, regression, sequences and other types of structured input and outputs and for reasoning in complex environments.

The course outline is:
1. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part I do it yourself on pen and paper.
2. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part II do it yourself in NumPy.
3. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part III PyTorch.
4. Convolutional neural networks (CNN) + presentation of student projects.
5. Sequence modelling for text data with Transformers.
6. Tricks of the trade and data science with PyTorch + Start of student projects.
7. Variational learning and generative adversarial networks for unsupervised and semi-supervised learning.
8. Reinforcement learning - policy gradient and deep Q-learning.

Starting from week 6 and full time from week 9 and the rest of the term will be spent on tutored project work.",0.7215696573257446,notebook 3_3,1.0,"code:
# Generate a dataset and plot it
np.random.seed(0)
num_samples = 300

X, y = sklearn.datasets.make_moons(num_samples, noise=0.20)

# define train, validation, and test sets', ""X_tr = X[:100].astype('float32')"", ""X_val = X[100:200].astype('float32')"", ""X_te = X[200:].astype('float32')"", '
# and labels', ""y_tr = y[:100].astype('int32')"", ""y_val = y[100:200].astype('int32')"", ""y_te = y[200:].astype('int32')"", '
plt.scatter(X_tr[:,0], X_tr[:,1], s=40, c=y_tr, cmap=plt.cm.Spectral)

print(X.shape, y.shape)

num_features = X_tr.shape[-1]
num_output = 2'

 
markdown:
# From Logistic Regression to ""Deep Learning""
The code implements logistic regression. In section [__Assignments Half Moon__](#Assignments-Half-Moon) (bottom of this notebook) you are asked to modify the code into a neural network.

The standard building block for neural networks are layers, the simplest of which is called a *fully-connected layer* or *dense feed forward layer*, and it is computed as follows:

$$y = g(W^{\\top} x + b)$$

where $x$ is the input vector, $y$ is the output vector, $W, b$ are the weights and biases (a matrix and vector respectively) and $g$ is a non-linear function, called *activation function*.
The *dense* part of the name comes from the fact that every element of $x$ contributes to every element of $y$.
And the *feed forward* part of the name means that the layer processes each input independently. 
If we were to draw the layer it would be acyclical.
Later we will see layers that break from both of these conventions.'

 
markdown:
- $x$ has shape `[batch_size, num_features]`,
- $W$ has shape `[num_units, num_features]`,
- $b$ has `[num_units]`, and
- $y$ has then `[batch_size, num_units]`'

 
markdown:
## PyTorch 101

In this first exercise we will use basic PyTorch functions so that you can learn how to build it from scratch. This will help you later if you want to build your own custom operations.'

 
code:
import torch
from torch import nn
import torch.nn.functional as F'",0.7482491135597229,0.0,0.0,0.0,1.0,2.0,2.0,2.0,2.0,2.0,2.0
Which optimizers are mentioned in the exercise notebook?,"Optimizer and learning rate:
SGD + Momentum: learning rate 0.01 - 0.1
ADAM: learning rate 3e-4 - 1e-5
RMSPROP: somewhere between SGD and ADAM",notebook 3_4,notebook 8_3,1.0,"markdown:
*Note: For simple reinforcement learning problems (like the one we will address in this exercise) there are simpler methods that work just fine. However, the Policy Gradient method (with some extensions) has been shown to also work well for complex problems with high dimensional inputs and many parameters, where simple methods become inadequate.*'

 
markdown:
## Policy gradient'

 
code:
# Install colabgymrender to display gym environments in Colab
!pip install gym[classic_control] > /dev/null 2>&1
!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1
!pip install colabgymrender > /dev/null 2>&1
!pip install imageio==2.4.1 > /dev/null 2>&1'

 
code:
%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import gym
from gym import wrappers
from colabgymrender.recorder import Recorder'

 
markdown:
First we create the environment:'

 
code:
env = gym.make('CartPole-v0') # Create environment""]'

 
markdown:
A state in this environment is four numbers describing the position and speed of the cart along with the angle and angular speed of the pole.

There are two available actions: push the cart *left* or *right* encoded as 0 and 1.'

 
code:
s = env.reset()
a = env.action_space.sample()', ""print('sample state:', s)"", ""print('sample action:', a )""]'

 
markdown:
Let us see how the environment looks when we just take random actions. Note that the episode ends when the pole either 1) is more than 15 degrees from vertical, 2) more outside of the frame or 3) the pole is successfully balanced for some fixed duration.'

 
code:
env = gym.make('CartPole-v0') # Create environment"", 'env = Recorder(env, ""./video"") # To display environment in Colab
env.reset() # Reset environment

# Run environment
while True:
    action = env.action_space.sample() # Get a random action
    _, _, done, _ = env.step(action) # Take a step
    if done: break # Break if environment is done

env.close() # Close environment
env.play()'

 
markdown:
Taking random actions does not do a very good job at balancing the pole. Let us now apply the Policy Gradient method described above to solve this task!
', ""Let's first define our network and helper functions.""]'

 
code:
class PolicyNet(nn.Module):
    """"""Policy network""""""

    def __init__(self, n_inputs, n_hidden, n_outputs, learning_rate):
        super(PolicyNet, self).__init__()
        # network
        self.hidden = nn.Linear(n_inputs, n_hidden)
        self.out = nn.Linear(n_hidden, n_outputs)
        # training
        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)",0.6639323234558105,notebook 5_2,19.0,"# Define a loss function and optimizer for this problem
# YOUR CODE HERE!
criterion = 
optimizer = 

# Track loss
training_loss, validation_loss = [], []

# For each epoch
for i in range(num_epochs):
    
    # Track loss
    epoch_training_loss = 0
    epoch_validation_loss = 0
    
    net.eval()
        
    # For each sentence in validation set
    for inputs, targets in validation_set:
        
        # One-hot encode input and target sequence
        inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
        targets_idx = [word_to_idx[word] for word in targets]
        
        # Convert input to tensor
        inputs_one_hot = torch.Tensor(inputs_one_hot)
        inputs_one_hot = inputs_one_hot.permute(0, 2, 1)
        
        # Convert target to tensor
        targets_idx = torch.LongTensor(targets_idx)
        
        # Forward pass
        # YOUR CODE HERE!
        outputs = 
        
        # Compute loss
        # YOUR CODE HERE!
        loss = 
        
        # Update loss
        epoch_validation_loss += loss.detach().numpy()
    
    net.train()
    
    # For each sentence in training set
    for inputs, targets in training_set:
        
        # One-hot encode input and target sequence
        inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
        targets_idx = [word_to_idx[word] for word in targets]
        
        # Convert input to tensor
        inputs_one_hot = torch.Tensor(inputs_one_hot)
        inputs_one_hot = inputs_one_hot.permute(0, 2, 1)
        
        # Convert target to tensor
        targets_idx = torch.LongTensor(targets_idx)
        
        # Forward pass
        # YOUR CODE HERE!
        outputs = 
        
        # Compute loss
        # YOUR CODE HERE!
        loss = 
        
        # Backward pass
        # YOUR CODE HERE!
        # zero grad, backward, step...
        
        # Update loss
        epoch_training_loss += loss.detach().numpy()
        
    # Save loss for plot
    training_loss.append(epoch_training_loss/len(training_set))
    validation_loss.append(epoch_validation_loss/len(validation_set))

    # Print loss every 10 epochs
    if i % 10 == 0:', ""        print(f'Epoch {i}, training loss: {training_loss[-1]}, validation loss: {validation_loss[-1]}')"", '
        
# Get first sentence in test set
inputs, targets = test_set[1]

# One-hot encode input and target sequence
inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
targets_idx = [word_to_idx[word] for word in targets]

# Convert input to tensor
inputs_one_hot = torch.Tensor(inputs_one_hot)
inputs_one_hot = inputs_one_hot.permute(0, 2, 1)

# Convert target to tensor
targets_idx = torch.LongTensor(targets_idx)

# Forward pass
outputs = net.forward(inputs_one_hot).data.numpy()
', ""print('\Input sequence:')"", 'print(inputs)
', ""print('\Target sequence:')"", 'print(targets)
', ""print('\Predicted sequence:')"", 'print([idx_to_word[np.argmax(output)] for output in outputs])",0.6675502061843872,notebook 7_1,2.0,"<img src=""static/autoencoder.png"" />

*The exercises are found at the bottom of the notebook*'

 
markdown:
## MNIST
First let us load the MNIST dataset and plot a few examples. In this notebook we will use the *dataloaders* and *datasets* provided by PyTorch. Defining the loading of datasets using a dataloader has the advantage that it only load the data that is *neccessary* into memory, which enables us to use very large scale datasets.

We only load a limited amount of classes defined by the `classes` variable to speed up training.'

 
code:
import torch
cuda = torch.cuda.is_available()

from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor

# Flatten the 2d-array image into a vector
flatten = lambda x: ToTensor()(x).view(28**2)

# Define the train and test sets
dset_train = MNIST(""./"", train=True,  transform=flatten, download=True)
dset_test  = MNIST(""./"", train=False, transform=flatten)

# The digit classes to use
classes = [3, 7]

def stratified_sampler(labels, classes):
    """"""Sampler that only picks datapoints corresponding to the specified classes""""""
    from functools import reduce
    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))
    indices = torch.from_numpy(indices)
    return SubsetRandomSampler(indices)


# The loaders perform the actual work
batch_size = 64
train_loader = DataLoader(dset_train, batch_size=batch_size,
                          sampler=stratified_sampler(dset_train.targets, classes), pin_memory=cuda)
test_loader  = DataLoader(dset_test, batch_size=batch_size, 
                          sampler=stratified_sampler(dset_test.targets, classes), pin_memory=cuda)'

 
code:
# Plot a batch of MNIST examples
f, axarr = plt.subplots(4, 16, figsize=(16, 4))

# Load a batch of images into memory
images, labels = next(iter(train_loader))

for i, ax in enumerate(axarr.flat):
    ax.imshow(images[i].view(28, 28), cmap=""binary_r"")', ""    ax.axis('off')"", '    ', ""plt.suptitle('MNIST handwritten digits')"", 'plt.show()'

 
markdown:
### Building the model
When defining the model the latent layer $z$ must act as a bottleneck of information. We initialize the AE with 1 hidden layer in the encoder and decoder using ReLU units as nonlinearities. The latent layer has a dimensionality of 2 in order to make it easy to visualise. Since $x$ are pixel intensities that are normalized between 0 and 1, we use the sigmoid nonlinearity to model the reconstruction.'

 
code:
import torch.nn as nn

# define size variables
num_features = 28*28",0.6801867485046387,notebook 8_3,0.0,"markdown:
# Solve cartpole with REINFORCE

> By Jonas Busk ([jbusk@dtu.dk](mailto:jbusk@dtu.dk))

**2019 update:** Changes have been made to the display of environments due to the previous `viewer` being incompatible with newer versions of Gym.

**2022 update:** Rendering was disabled, and the notebook now uses the `colabgymrender` package to render a video.

In this part, we will create an agent that can learn to solve the [cartpole problem](https://gym.openai.com/envs/CartPole-v0/) from OpenAI Gym by applying a simple policy gradient method called REINFORCE.
In the cartpole problem, we need to balance a pole on a cart that moves along a track by applying left and right forces to the cart.

We will implement a probabilistic policy, that given a state of the environment, $s$, outputs a probability distribution over available actions, $a$:

$$
p_\\theta(a|s)
$$

The policy is a neural network with parameters $\\theta$ that can be trained with gradient descent.
When the set of available actions is discrete, we can use a network with softmax output do describe the distribution.
The core idea of training the policy network is quite simple: *we want to maximize the expected total reward by increasing the probability of good actions and decreasing the probability of bad actions*. 

To achieve this, we apply the gradient of the expected discounted total reward (return):

$$
\\begin{align}
\abla_\\theta \\mathbb{E}[R|\\theta] &= \abla_\\theta \\int p_\\theta(a|s) R({a}) \\, da \\\\
&= \\int \abla_\\theta p_\\theta(a|s) R(a)  \\, da \\\\
&= \\int p_\\theta(a|s) \abla_\\theta \\log p_\\theta(a|s) R(a) \\, da \\\\
&= \\mathbb{E}[\abla_\\theta \\log p_\\theta(a|s) R(a)]
\\end{align}
$$

by definition of expectation and using the identity 

$$
\abla_\\theta p_\\theta(a|s) = p_\\theta(a|s) \abla_\\theta \\log p_\\theta(a|s) \\ .
$$

The expectation cannot be evaluated analytically, but we have an environment simulator that when supplied with our current policy $p_\\theta(a|s)$ can return a sequence of *actions*, *states* and *rewards*. This allows us to replace the integral with a Monte Carlo average:

$$
\abla_\\theta \\mathbb{E}[R|\\theta] \\approx \\frac{1}{T} \\sum_{t=0}^T \abla_\\theta \\log p_\\theta(a_t|s_t) R_t \\ ,
$$

which is our final gradient estimator, also known as REINFORCE. In the Monte Carlo estimator we run the environment simulator for a predefined number of steps with actions chosen stochastically according to the current stochastic action network $p_\\theta(a|s)$.'",0.6804074048995972,notebook 3_3,4.0,"markdown:
To train our neural network we need to update the parameters in the direction of the negative gradient w.r.t the cost function we defined earlier.
We can use [`torch.optim`](http://pytorch.org/docs/master/optim.html) to get the gradients with some update rule for all parameters in the network.

Heres a small animation of gradient descent: http://imgur.com/a/Hqolp, which also illustrates which challenges optimizers might face, e.g. saddle points.'

 
code:
import torch.optim as optim

optimizer = optim.SGD(net.parameters(), lr=0.01)'

 
markdown:
Next, we make the prediction functions, such that we can get an accuracy measure over a batch'

 
code:
def accuracy(ys, ts):
    # making a one-hot encoded vector of correct (1) and incorrect (0) predictions
    correct_prediction = torch.eq(torch.max(ys, 1)[1], torch.max(ts, 1)[1])
    # averaging the one-hot encoded vector
    return torch.mean(correct_prediction.float())'

 
markdown:
The next step is to utilize our `optimizer` repeatedly in order to optimize our weights `W_1` and `b_1` to make the best possible linear seperation of the half moon dataset.'

 
code:
# number of training passses
num_epochs = 1000
# store loss and accuracy for information
train_losses, val_losses, train_accs, val_accs = [], [], [], []

def pred(X):
    """""" Compute graph\'s prediction and return numpy array
    
    Parameters
    ----------
    X : numpy.ndarray
    
    Returns
    -------
    numpy.ndarray
    """"""
    X = torch.from_numpy(X)
    y = net(X)
    return y.data.numpy()

# plot boundary on testset before training session
plot_decision_boundary(lambda x: pred(x), X_te, y_te)
plt.title(""Untrained Classifier"")",0.6819003224372864,notebook 3_4,2.0,"__Nonlinearity:__ [The most commonly used nonliearities are](http://pytorch.org/docs/master/nn.html#non-linear-activations)
1. ReLU
2. Leaky ReLU
3. ELU
3. Sigmoid (rarely, if ever, used in hidden layers anymore, squashes the output to the interval [0, 1] - appropriate if the targets are binary.
4. Tanh is similar to the sigmoid, but squashes to [-1, 1]. Rarely used any more.
4. Softmax normalizes the output to 1, usrful if you have a multi-class classification problem.

See the plot below.

__Optimizer and learning rate:__
1. SGD + Momentum: learning rate 0.01 - 0.1 
2. ADAM: learning rate 3e-4 - 1e-5
3. RMSPROP: somewhere between SGD and ADAM'

 
code:
# Illustrate different output units
x = np.linspace(-6, 6, 100)
units = {
    ""ReLU"": lambda x: np.maximum(0, x),
    ""Leaky ReLU"": lambda x: np.maximum(0, x) + 0.1 * np.minimum(0, x),
    ""Elu"": lambda x: (x > 0) * x + (1 - (x > 0)) * (np.exp(x) - 1),
    ""Sigmoid"": lambda x: (1 + np.exp(-x))**(-1),
    ""tanh"": lambda x: (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))
}

plt.figure(figsize=(5, 5))
[plt.plot(x, unit(x), label=unit_name, lw=2) for unit_name, unit in units.items()]
plt.legend(loc=2, fontsize=16)', ""plt.title('Non-linearities', fontsize=20)"", 'plt.ylim([-2, 5])
plt.xlim([-6, 6])

# assert that all class probablities sum to one
softmax = lambda x: np.exp(x) / np.sum(np.exp(x))
print(""softmax should sum to one (approxiamtely):"", np.sum(softmax(x)))'

 
code:
#Hyperparameters
num_classes = 10
num_l1 = 512
num_features = x_train.shape[1]

# define network
class Net(nn.Module):

    def __init__(self, num_features, num_hidden, num_output):
        super(Net, self).__init__()  
        # input layer
        self.W_1 = Parameter(init.xavier_normal_(torch.Tensor(num_hidden, num_features)))
        self.b_1 = Parameter(init.constant_(torch.Tensor(num_hidden), 0))
        # hidden layer
        self.W_2 = Parameter(init.xavier_normal_(torch.Tensor(num_output, num_hidden)))
        self.b_2 = Parameter(init.constant_(torch.Tensor(num_output), 0))
        # define activation function in constructor
        self.activation = torch.nn.ELU()",0.6831387281417847,CoursePlan.txt,3.0,"Week 1 computer exercise. Deadline: Monday week 2.
    Week 2 computer exercise. Deadline: Monday week 3.
    Week 3 computer exercise and 1 exercise of your own choice from course material week 1. Deadline: Monday week 4
    Week 4 computer exercise  and 1 exercise of your own choice from course material week 1-2. Deadline: Monday week 5.
    Week 5 computer exercise. Deadline: Monday week 6.
    Week 6 computer exercise. Deadline: Monday week 7.
    Week 7 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 8
    Week 8 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 9.
    Project selection. Deadline Friday, Oct 20th 2023 at 23.59.
    Link to 2023 project selection sheet
    Project synopsis. Deadline: Monday week 9 at 23:59. The synopsis should be approximately half a page and maximum one page with a project title, motivation, background, milestones and references. It is important that the plan is realistic. The main purposes of the synopsis are to make sure the project size is well-calibrated and is concrete enough to start working from day one. The synopsis will not be used in the evaluation. The synopsis should be sent to your project supervisor.
    Project poster session. PhD students taking the course as part of their PhD will not have to make a poster and take part of the poster session. In mixed groups of PhD and non-PhD students, only the non-PhD students have to take part in the poster session. The exam date is December 7th from 9 to 17. We divide the day into half hour slots and your group will later be given the possibility to register for a slot. A link to sign up for the poster session will appear here in due time. So having another exam on the same day should not be a problem. We will also organise an extra exam date for those of you who cannot make it on the date. It will be group poster presentations. We will invite outside guests and we will walk around and ask questions to all groups. We will make a schedule for when the teachers visit your poster. Plan for a 2 minute presentation per group member and 1-2 minutes for questions. The remainder of the time you can either present your poster to other students and guests or go visit other posters. Remember that it is important for the overall impression that you divide the presentation and answering of the questions more or less equally between you. The poster should be in A1 format. Remember to put both your names and student numbers under title. Here and here are links to examples using the latex template and here is one in powerpoint. You do not have to use that. The DTU library offers poster printing for a not too high price.",0.7109591364860535,notebook 8_3,5.0,"*Hint: See introdution notebook.*

**Answer:**

*Answer here...*

### Exercise 3

*In the training output, you will sometimes observe the validation reward starts out lower than the training reward but as training progresses they cross over and the validation reward becomes higher than the training reward. How can you explain this behavior?*

*Hint: Do we use the policy network in the same way during training and validation?*

**Answer:**

*Answer here...*

### Exercise 4

*How does the policy gradient method we have used address the exploration-exploitation dilemma?*

*Hint: See the introduction notebook about exploration-exploitation.*

**Answer:**

*Answer here...*

### Exercise 5 [optional]

Extend the code above to reduce variance of the gradient estimator by computing and subtracting the baseline estimate. 

*Hint: You need to sample a batch of rollouts (now we sample just one) for each update in order to compute the baseline, $b_t$.*'",0.7130841612815857,notebook 4_3,3.0,"code:
num_epochs = 10
validation_every_steps = 50

step = 0
model.train()

train_accuracies = []
valid_accuracies = []
        
for epoch in range(num_epochs):
    
    train_accuracies_batches = []
    
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        
        # Forward pass.
        output = model(inputs)
        
        # Compute loss.
        loss = loss_fn(output, targets)
        
        # Clean up gradients from the model.
        optimizer.zero_grad()
        
        # Compute gradients based on the loss from the current batch (backpropagation).
        loss.backward()
        
        # Take one optimizer step using the gradients computed in the previous step.
        optimizer.step()
        
        step += 1
        
        # Compute accuracy.
        predictions = output.max(1)[1]
        train_accuracies_batches.append(accuracy(targets, predictions))
        
        if step % validation_every_steps == 0:
            
            # Append average training accuracy to list.
            train_accuracies.append(np.mean(train_accuracies_batches))
            
            train_accuracies_batches = []
        
            # Compute accuracies on validation set.
            valid_accuracies_batches = []
            with torch.no_grad():
                model.eval()
                for inputs, targets in test_loader:
                    inputs, targets = inputs.to(device), targets.to(device)
                    output = model(inputs)
                    loss = loss_fn(output, targets)

                    predictions = output.max(1)[1]

                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).
                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))

                model.train()
                
            # Append average validation accuracy to list.
            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))
     
            print(f""Step {step:<5}   training accuracy: {train_accuracies[-1]}"")
            print(f""             test accuracy: {valid_accuracies[-1]}"")

print(""Finished training."")'

 
markdown:
## Test the network on the test data'

 
code:
# Evaluate test set
with torch.no_grad():
    model.eval()
    test_accuracies = []
    for inputs, targets in test_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        output = model(inputs)
        loss = loss_fn(output, targets)

        predictions = output.max(1)[1]

        # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=True).
        test_accuracies.append(accuracy(targets, predictions) * len(inputs))

    test_accuracy = np.sum(test_accuracies) / len(test_set)
    print(f""Test accuracy: {test_accuracy:.3f}"")
    
    model.train()'

 
markdown:
## Using a pre-trained model

Here we will load a ResNet34 that was pre-trained on ImageNet. We then discard the linear classifier at the end of the network (the ""head"" of the network) and replace it with a new one that outputs the desired number of logits for classification. To get a rough idea of the structure of the model, we print it below.",0.715474009513855,notebook 7_2,6.0,"with $\\tilde{\\mathbf{z}} := g_{\\boldsymbol{\\phi}}\\left(\\boldsymbol{\\epsilon},\\mathbf{x} \\right), \\epsilon \\sim p(\\epsilon) \\text{ and } f_{\\theta, \\phi}(\\mathbf{z}, \\mathbf{x}) := \\log \\frac{p_\\theta(\\mathbf{x}, \\mathbf{z})}{q_\\phi(\\mathbf{z}|\\mathbf{x})}$ .


#### Choice of Reparameterization

A common choice of parameterization is to choose $p(\\epsilon) = \\mathcal{N} (0, I)$ and parameterize a mean vector and a diagonal covariance matrix using neural networks $\\{\\mu_\\phi, \\sigma_\\phi\\}$:

$$\\mathbf{z} = \\mu_\\phi(\\mathbf{x}) + \\sigma_\\phi(\\mathbf{x})  \\odot \\epsilon \\ \\text{   with   }  \\epsilon \\sim \\mathcal{N} (0, I) \\ . $$

### Why a VAE learns a good approximate posterior $q_\\phi(\\mathbf{z} | \\mathbf{x}) \\approx p_\\theta(\\mathbf{z} | \\mathbf{x})$

We have seen how to estimate the parameter $\\phi$ thanks to the reparameterization. Maximizing the ELBO will
maximize its upper bound $\\log p_\\theta(\\mathbf{x})$. Yet, maximizing $\\log p_\\theta(\\mathbf{x})$ does not guarantee a good approximation
$q_\\phi(\\mathbf{z} | \\mathbf{x}) \\approx p_\\theta(\\mathbf{z} | \\mathbf{x})$, and a poor approximation leads to a low-accuracy estimate of $\\log p_\\theta(\\mathbf{x})$.

At the end of the note book, we show that the following identity holds:

$$\\log p_\\theta(\\mathbf{x}) = \\mathcal{D}_{\\operatorname{KL}}(q_\\phi(\\mathbf{z} | \\mathbf{x}) | p_\\theta(\\mathbf{z}| \\mathbf{x})) + \\mathcal{L}(\\mathbf{x}) \\geq \\mathcal{L}(\\mathbf{x})$$

Hence maximizing the ELBO also guarantees to push the approximate posterior $q_\\phi(\\mathbf{z}| \\mathbf{x})$ to be similar to the true posterior  $p_\\theta(\\mathbf{z}| \\mathbf{x})$ because $\\mathcal{D}_{\\operatorname{KL}}(q_\\phi(\\mathbf{z} | \\mathbf{x}) | p_\\theta(\\mathbf{z}| \\mathbf{x}))$ is minimized as $\\mathcal{L}$ is maximized.

## 4. Interpreting VAEs as Autoencoders",0.7216110229492188,0.0,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0
Describe the model given in the exercise notebook?,"The provided code defines a PyTorch neural network for a classification task with the following characteristics:

It has two layers: an input layer and a hidden layer.
The activation function used is Exponential Linear Unit (ELU).
The network is designed for a classification task with 10 output classes.
The number of hidden units in the hidden layer is 512.
The number of input features is determined based on the shape of the input data .
The forward method defines how data flows through the network by applying linear transformations followed by ELU activation.",notebook 3_3,CoursePlan.txt,3.0,"Week 1 computer exercise. Deadline: Monday week 2.
    Week 2 computer exercise. Deadline: Monday week 3.
    Week 3 computer exercise and 1 exercise of your own choice from course material week 1. Deadline: Monday week 4
    Week 4 computer exercise  and 1 exercise of your own choice from course material week 1-2. Deadline: Monday week 5.
    Week 5 computer exercise. Deadline: Monday week 6.
    Week 6 computer exercise. Deadline: Monday week 7.
    Week 7 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 8
    Week 8 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 9.
    Project selection. Deadline Friday, Oct 20th 2023 at 23.59.
    Link to 2023 project selection sheet
    Project synopsis. Deadline: Monday week 9 at 23:59. The synopsis should be approximately half a page and maximum one page with a project title, motivation, background, milestones and references. It is important that the plan is realistic. The main purposes of the synopsis are to make sure the project size is well-calibrated and is concrete enough to start working from day one. The synopsis will not be used in the evaluation. The synopsis should be sent to your project supervisor.
    Project poster session. PhD students taking the course as part of their PhD will not have to make a poster and take part of the poster session. In mixed groups of PhD and non-PhD students, only the non-PhD students have to take part in the poster session. The exam date is December 7th from 9 to 17. We divide the day into half hour slots and your group will later be given the possibility to register for a slot. A link to sign up for the poster session will appear here in due time. So having another exam on the same day should not be a problem. We will also organise an extra exam date for those of you who cannot make it on the date. It will be group poster presentations. We will invite outside guests and we will walk around and ask questions to all groups. We will make a schedule for when the teachers visit your poster. Plan for a 2 minute presentation per group member and 1-2 minutes for questions. The remainder of the time you can either present your poster to other students and guests or go visit other posters. Remember that it is important for the overall impression that you divide the presentation and answering of the questions more or less equally between you. The poster should be in A1 format. Remember to put both your names and student numbers under title. Here and here are links to examples using the latex template and here is one in powerpoint. You do not have to use that. The DTU library offers poster printing for a not too high price.",0.5602099299430847,LearningObjectives.txt,0.0,"Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.

Understand and explain the choices and limitations of a model for a given setting.

Apply and analyze results from deep learning models in exercises and own project work.

Plan, delimit and carry out an applied or methods-oriented project in collaboration with fellow students and project supervisor.

Assess and summarize the project results in relation to aims, methods and available data.

Carry out the project and interpret results by use of computational framework for GPU programming such as PyTorch.

Structure and write a final short technical report including problem formulation, description of methods, experiments, evaluation and conclusion.

Organize and present project results at the final project presentation and in report.

Read, evaluate and give feedback to work of other students.",0.5614992380142212,notebook 8_3,4.0,"code:
# plot results
def moving_average(a, n=10) :
    ret = np.cumsum(a, dtype=float)
    ret[n:] = ret[n:] - ret[:-n]
    return ret / n

plt.figure(figsize=(16,6))
plt.subplot(211)', ""plt.plot(range(1, len(training_rewards)+1), training_rewards, label='training reward')"", 'plt.plot(moving_average(training_rewards))', ""plt.xlabel('episode'); plt.ylabel('reward')"", 'plt.xlim((0, len(training_rewards)))
plt.legend(loc=4); plt.grid()
plt.subplot(212)', ""plt.plot(range(1, len(losses)+1), losses, label='loss')"", 'plt.plot(moving_average(losses))', ""plt.xlabel('episode'); plt.ylabel('loss')"", 'plt.xlim((0, len(losses)))
plt.legend(loc=4); plt.grid()
plt.tight_layout(); plt.show()'

 
markdown:
Now let's review the solution!""]'

 
code:
env = Recorder(env, ""./gym-results"") # wrappers.Monitor(env, ""./gym-results"", force=True) # Create wrapper to display environment
s = env.reset()

for _ in range(500):
    a = policy(torch.from_numpy(np.atleast_2d(s)).float()).argmax().item()
    s, r, done, _ = env.step(a)
    if done: break
    
# env.close()
env.play()'

 
markdown:
## Reducing variance

By default, this gradient estimator has high variance and therefore variance reduction becomes important to learn more complex tasks.
We can reduce variance by subtracting a baseline from the returns, which is unbiased in expectation:

$$
\abla_\\theta \\mathbb{E}[R|\\theta] \\approx \\frac{1}{T} \\sum_{t=0}^T \abla_\\theta \\log p_\\theta(a_t|s_t) (R_t-b_t) \\ ,
$$

where the baseline, $b_t$, is estimated by the return a timestep $t$ averaged over $V$ rollouts.

$$
b_t = \\frac{1}{V} \\sum_{v=1}^V R_t^{(v)} \\ .
$$'

 
markdown:
## Exercises

Now it is your turn! Make sure you read and understand the code, then play around with it and try to make it learn better and faster.

Experiment with the:

* number of episodes
* discount factor
* learning rate
* network layers


### Exercise 1 

*Describe any changes you made to the code and why you think they improve the agent. Are you able to get solutions consistently?*

**Answer:**

*Answer here...*

### Exercise 2 

*Consider the following sequence of rewards produced by an agent interacting with an environment for 10 timesteps:*

[0, 1, 1, 1, 0, 1, 1, 0, 0, 0]

* *What is the total reward?*
* *What is the total future reward in each timestep?*
* *What is the discounted future reward in each timestep if $\\gamma = 0.9$?*

*Hint: See introdution notebook.*",0.5700699090957642,notebook 8_4_Q,2.0,"code:
# plot results

def moving_average(a, n=10) :
    ret = np.cumsum(a, dtype=float)
    ret[n:] = ret[n:] - ret[:-n]
    return ret / n

plt.figure(figsize=(16, 9))
plt.subplot(411)', ""plt.title('training rewards')"", 'plt.plot(range(1, num_episodes+1), rewards)
plt.plot(range(1, num_episodes+1), moving_average(rewards))
plt.xlim([0, num_episodes])
plt.subplot(412)', ""plt.title('training lengths')"", 'plt.plot(range(1, num_episodes+1), lengths)
plt.plot(range(1, num_episodes+1), moving_average(lengths))
plt.xlim([0, num_episodes])
plt.subplot(413)', ""plt.title('training loss')"", 'plt.plot(range(1, num_episodes+1), losses)
plt.plot(range(1, num_episodes+1), moving_average(losses))
plt.xlim([0, num_episodes])
plt.subplot(414)', ""plt.title('epsilon')"", 'plt.plot(range(1, num_episodes+1), epsilons)
plt.xlim([0, num_episodes])
plt.tight_layout(); plt.show()'

 
markdown:
Now let's review the solution! You can run the cell multiple times to see the behavior of the Q-network.""]'

 
code:
s = env.reset()
env.render()
for _ in range(100):
    a = qnet(torch.from_numpy(one_hot([s], n_inputs)).float()).argmax().item()
    s, r, done, _ = env.step(a)
    env.render()
    if done: break'

 
markdown:
## Exercises

Read and understand the code, then play around with it and try to make it learn better and faster.

Experiment with the:

* number of episodes
* discount factor
* learning rate
* network layers


### Exercise 1 

*Describe any changes you made to the code and why you think they improve the agent.*

**Answer:**

*Answer here...*

### Exercise 2

*How high mean training a reward is your solution able to achieve? Do you think it is possible to go even higher? Why/why not?*

**Answer:**

*Answer here...*

### Exercise 3

*What role does epsilon play in the code above? Try and change the epsilon start value or the line of code that decreases eplison every update step. How does it affect learning?*

**Answer:**

*Answer here...*'",0.5781417489051819,notebook 5_3,19.0,"Feel free to dive into the code to get a better intuition of what is going on -- otherwise you can jump straight to the training loop.'

 
code:
def backward(z, f, i, g, C, o, h, v, outputs, targets, p = params):
    """"""
    Arguments:
    z -- your concatenated input data  as a list of size m.
    f -- your forget gate computations as a list of size m.
    i -- your input gate computations as a list of size m.
    g -- your candidate computations as a list of size m.
    C -- your Cell states as a list of size m+1.
    o -- your output gate computations as a list of size m.
    h -- your Hidden state computations as a list of size m+1.
    v -- your logit computations as a list of size m.
    outputs -- your outputs as a list of size m.
    targets -- your targets as a list of size m.
    p -- python list containing:
                        W_f -- Weight matrix of the forget gate, numpy array of shape (n_a, n_a + n_x)
                        b_f -- Bias of the forget gate, numpy array of shape (n_a, 1)
                        W_i -- Weight matrix of the update gate, numpy array of shape (n_a, n_a + n_x)
                        b_i -- Bias of the update gate, numpy array of shape (n_a, 1)
                        W_g -- Weight matrix of the first ""tanh"", numpy array of shape (n_a, n_a + n_x)
                        b_g --  Bias of the first ""tanh"", numpy array of shape (n_a, 1)
                        W_o -- Weight matrix of the output gate, numpy array of shape (n_a, n_a + n_x)
                        b_o --  Bias of the output gate, numpy array of shape (n_a, 1)
                        W_v -- Weight matrix relating the hidden-state to the output, numpy array of shape (n_v, n_a)
                        b_v -- Bias relating the hidden-state to the output, numpy array of shape (n_v, 1)
    Returns:
    loss -- crossentropy loss for all elements in output
    grads -- lists of gradients of every element in p
    """"""

    # Unpack parameters
    W_f, W_i, W_g, W_o, W_v, b_f, b_i, b_g, b_o, b_v = p

    # Initialize gradients as zero
    W_f_d = np.zeros_like(W_f)
    b_f_d = np.zeros_like(b_f)

    W_i_d = np.zeros_like(W_i)
    b_i_d = np.zeros_like(b_i)

    W_g_d = np.zeros_like(W_g)
    b_g_d = np.zeros_like(b_g)

    W_o_d = np.zeros_like(W_o)
    b_o_d = np.zeros_like(b_o)",0.5882164835929871,notebook 5_3,13.0,"# Plot training and validation loss
epoch = np.arange(len(training_loss))
plt.figure()', ""plt.plot(epoch, training_loss, 'r', label='Training loss',)"", ""plt.plot(epoch, validation_loss, 'b', label='Validation loss')"", 'plt.legend()', ""plt.xlabel('Epoch'), plt.ylabel('NLL')"", 'plt.show()'

 
markdown:
## Exercise E:'

 
markdown:
Complete the training loop above and run the training. You can leave the hyper-parameters and network size unchanged.

A correct implementation should yield a loss of around **1** (using mean CE) or around **4** (using sum CE) after 1000 epochs. Does it work? If not, try to identify the issue -- perhaps something in the backward pass is not right?'

 
markdown:
## Extrapolation'

 
markdown:
Now that we have trained an RNN, it's time to put it to test. We will provide the network with a starting sentence and let it `freestyle` from there!""]'

 
code:
def freestyle(params, sentence='', num_generate=10):"", '    """"""
    Takes in a sentence as a string and outputs a sequence
    based on the predictions of the RNN.
    
    Args:
     `params`: the parameters of the network
     `sentence`: string with whitespace-separated tokens
     `num_generate`: the number of tokens to generate
    """"""', ""    sentence = sentence.split(' ')"", '    
    sentence_one_hot = one_hot_encode_sequence(sentence, vocab_size)
    
    # Initialize hidden state as zeros
    hidden_state = np.zeros((hidden_size, 1))

    # Generate hidden state for sentence
    outputs, hidden_states = forward_pass(sentence_one_hot, hidden_state, params)
    
    # Output sentence
    output_sentence = sentence
    
    # Append first prediction
    word = idx_to_word[np.argmax(outputs[-1])]    
    output_sentence.append(word)
    
    # Forward pass
    for i in range(num_generate):

        # Get the latest prediction and latest hidden state
        output = outputs[-1]
        hidden_state = hidden_states[-1]
    
        # Reshape our output to match the input shape of our forward pass
        output = output.reshape(1, output.shape[0], output.shape[1])
    
        # Forward pass
        outputs, hidden_states = forward_pass(output, hidden_state, params)
        
        # Compute the index of the most likely word and look up the corresponding word
        word = idx_to_word[np.argmax(outputs)]
        
        output_sentence.append(word)
        ', ""        if word == 'EOS':"", '            break
        
    return output_sentence


# Perform freestyle (extrapolation)', ""test_examples = ['a a b
a a a a b
a a a a a a b
a
r n n']"", 'for i, test_example in enumerate(test_examples):', ""    print(f'Example {i}:', test_example)"", ""    print('Predicted sequence:', freestyle(params, sentence=test_example), end='\\')""]'

 
markdown:
## Exercise F:

How well does your RNN extrapolate -- does it work as expected? Are there any imperfections? If yes, why could that be?'

 
markdown:
## Exercise G (optional):'",0.6061528921127319,notebook 7_2,16.0,"# define dictionary to store the training curves
training_data = defaultdict(list)
validation_data = defaultdict(list)

epoch = 0'

 
markdown:
### Training Loop

**plotting guide**:

* 1st row: Reproducing the figure from the begining of the Notebook.
    * (Left) Data. 
    * (Middle) Latent space: the large gray disk reprensents the prior (radius = $2\\sigma$), each point represents a latent sample $\\mathbf{z}$. The smaller ellipses represent the distributions $q_\\phi(\\mathbf{z} | \\mathbf{x})$  (radius = $2\\sigma$). When using $\\geq 2$ latent features, dimensionality reduction is applied using t-SNE and only samples $\\mathbf{z} \\sim q_\\phi(\\mathbf{z} | \\mathbf{x})$ are displayed. 
    * (Right) samples from $p_\\theta(\\mathbf{x} | \\mathbf{z})$.

* 2nd row: Training curves

* 2rd row: Latent samples. 
    * (Left) Prior samples $\\mathbf{x} \\sim p_\\theta(\\mathbf{x} | \\mathbf{z}), \\mathbf{z} \\sim p(\\mathbf{z})$ 
    * (Middle) Latent Interpolations. For each row: $\\mathbf{x} \\sim p_\\theta(\\mathbf{x} | t \\cdot \\mathbf{z}_1 + (1-t) \\cdot \\mathbf{z}_2), \\mathbf{z}_1, \\mathbf{z}_2 \\sim p(\\mathbf{z}), t=0 \\dots 1$. 
    * (Right): Sampling $\\mathbf{z}$ from a grid [-3:3, -3:3] $\\mathbf{x} \\sim p_\\theta(\\mathbf{x} | \\mathbf{z}), \\mathbf{z} \\sim \\operatorname{grid}(-3:3, -3:3)$ (only available for 2d latent space).

**NOTE** this will take a while on CPU.'

 
code:
num_epochs = 100

device = torch.device(""cuda:0"" if torch.cuda.is_available() else ""cpu"")
print(f"">> Using device: {device}"")

# move the model to the device
vae = vae.to(device)

# training..
while epoch < num_epochs:
    epoch+= 1
    training_epoch_data = defaultdict(list)
    vae.train()
    
    # Go through each batch in the training dataset using the loader
    # Note that y is not necessarily known as it is here
    for x, y in train_loader:
        x = x.to(device)
        
        # perform a forward pass through the model and compute the ELBO
        loss, diagnostics, outputs = vi(vae, x)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # gather data for the current bach
        for k, v in diagnostics.items():
            training_epoch_data[k] += [v.mean().item()]",0.6120783090591431,notebook 4_3,3.0,"code:
num_epochs = 10
validation_every_steps = 50

step = 0
model.train()

train_accuracies = []
valid_accuracies = []
        
for epoch in range(num_epochs):
    
    train_accuracies_batches = []
    
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        
        # Forward pass.
        output = model(inputs)
        
        # Compute loss.
        loss = loss_fn(output, targets)
        
        # Clean up gradients from the model.
        optimizer.zero_grad()
        
        # Compute gradients based on the loss from the current batch (backpropagation).
        loss.backward()
        
        # Take one optimizer step using the gradients computed in the previous step.
        optimizer.step()
        
        step += 1
        
        # Compute accuracy.
        predictions = output.max(1)[1]
        train_accuracies_batches.append(accuracy(targets, predictions))
        
        if step % validation_every_steps == 0:
            
            # Append average training accuracy to list.
            train_accuracies.append(np.mean(train_accuracies_batches))
            
            train_accuracies_batches = []
        
            # Compute accuracies on validation set.
            valid_accuracies_batches = []
            with torch.no_grad():
                model.eval()
                for inputs, targets in test_loader:
                    inputs, targets = inputs.to(device), targets.to(device)
                    output = model(inputs)
                    loss = loss_fn(output, targets)

                    predictions = output.max(1)[1]

                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).
                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))

                model.train()
                
            # Append average validation accuracy to list.
            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))
     
            print(f""Step {step:<5}   training accuracy: {train_accuracies[-1]}"")
            print(f""             test accuracy: {valid_accuracies[-1]}"")

print(""Finished training."")'

 
markdown:
## Test the network on the test data'

 
code:
# Evaluate test set
with torch.no_grad():
    model.eval()
    test_accuracies = []
    for inputs, targets in test_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        output = model(inputs)
        loss = loss_fn(output, targets)

        predictions = output.max(1)[1]

        # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=True).
        test_accuracies.append(accuracy(targets, predictions) * len(inputs))

    test_accuracy = np.sum(test_accuracies) / len(test_set)
    print(f""Test accuracy: {test_accuracy:.3f}"")
    
    model.train()'

 
markdown:
## Using a pre-trained model

Here we will load a ResNet34 that was pre-trained on ImageNet. We then discard the linear classifier at the end of the network (the ""head"" of the network) and replace it with a new one that outputs the desired number of logits for classification. To get a rough idea of the structure of the model, we print it below.",0.6122664213180542,notebook 4_2,1.0,"print(""\Test data"")
print(""Number of points:"", len(test_set))
x, y = next(iter(test_loader))
print(""Batch dimension (B x C x H x W):"", x.shape)
print(f""Number of distinct labels: {len(set(test_set.targets))} (unique labels: {set(test_set.targets)})"")

n_classes = len(set(test_set.targets))'

 
markdown:
### Show example images

Run multiple times to see different examples.'

 
code:
# Get random training images and show them.
images, labels = next(iter(train_loader))
show_image(torchvision.utils.make_grid(images))'

 
markdown:
## Define a convolutional neural network


**Assignment 1:** Define a convolutional neural network. 
You may use the code from previous notebooks.
We suggest that you start with a small network, and make sure that everything is working.
Once you can train successfully, come back and improve the architecture.'

 
code:
class PrintSize(nn.Module):
    """"""Utility module to print current shape of a Tensor in Sequential, only at the first pass.""""""
    
    first = True
    
    def forward(self, x):
        if self.first:
            print(f""Size: {x.size()}"")
            self.first = False
        return x


class Model(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.num_classes = num_classes
        # Your code here!

    def forward(self, x):
        # Your code here!
        return x


model = Model(n_classes)', ""device = torch.device('cpu')  # use cuda or cpu"", 'model.to(device)
print(model)'

 
markdown:
## Define a loss function and optimizer

**Assignment 2:** Define the loss function and optimizer.
You might need to experiment a bit with the learning rate.'

 
code:
loss_fn = None  # Your code here!
optimizer = None  # Your code here!'

 
markdown:
## Train the network

**Assignment 3:** Finish the training loop below. 
Start by using a small number of epochs (e.g. 2).
Even with a low number of epochs you should be able to see results that are better than chance.
When everything is working increase the number of epochs to find out how good your network really is.'

 
code:
# Test the forward pass with dummy data
out = model(torch.randn(2, 3, 32, 32, device=device))
print(""Output shape:"", out.size())
print(f""Output logits:\{out.detach().cpu().numpy()}"")
print(f""Output probabilities:\{out.softmax(1).detach().cpu().numpy()}"")'

 
code:
batch_size = 64
num_epochs = 2
validation_every_steps = 500

step = 0
model.train()",0.6166918277740479,notebook 4_2,2.0,"code:
batch_size = 64
num_epochs = 2
validation_every_steps = 500

step = 0
model.train()

train_accuracies = []
valid_accuracies = []
        
for epoch in range(num_epochs):
    
    train_accuracies_batches = []
    
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        
        # Forward pass, compute gradients, perform one training step.
        # Your code here!
        
        # Increment step counter
        step += 1
        
        # Compute accuracy.
        predictions = output.max(1)[1]
        train_accuracies_batches.append(accuracy(targets, predictions))
        
        if step % validation_every_steps == 0:
            
            # Append average training accuracy to list.
            train_accuracies.append(np.mean(train_accuracies_batches))
            
            train_accuracies_batches = []
        
            # Compute accuracies on validation set.
            valid_accuracies_batches = []
            with torch.no_grad():
                model.eval()
                for inputs, targets in test_loader:
                    inputs, targets = inputs.to(device), targets.to(device)
                    output = model(inputs)
                    loss = loss_fn(output, targets)

                    predictions = output.max(1)[1]

                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).
                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))

                model.train()
                
            # Append average validation accuracy to list.
            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))
     
            print(f""Step {step:<5}   training accuracy: {train_accuracies[-1]}"")
            print(f""             test accuracy: {valid_accuracies[-1]}"")

print(""Finished training."")'

 
markdown:
## Test the network

Now we show a batch of test images and generate a table below with the true and predicted class for each of these images.'

 
code:
inputs, targets = next(iter(test_loader))
inputs, targets = inputs.to(device), targets.to(device)
show_image(make_grid(inputs))
plt.show()

outputs = model(inputs)
_, predicted = torch.max(outputs.data, 1)

print(""    TRUE        PREDICTED"")
print(""-----------------------------"")
for target, pred in zip(targets, predicted):
    print(f""{classes[target.item()]:^13} {classes[pred.item()]:^13}"")'

 
markdown:
We now evaluate the network as above, but on the entire test set.'

 
code:
# Evaluate test set
confusion_matrix = np.zeros((n_classes, n_classes))
with torch.no_grad():
    model.eval()
    test_accuracies = []
    for inputs, targets in test_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        output = model(inputs)
        loss = loss_fn(output, targets)

        predictions = output.max(1)[1]

        # Multiply by len(inputs) because the final batch of DataLoader may be smaller (drop_last=True).
        test_accuracies.append(accuracy(targets, predictions) * len(inputs))
        
        confusion_matrix += compute_confusion_matrix(targets, predictions)

    test_accuracy = np.sum(test_accuracies) / len(test_set)
    
    model.train()'",0.6183809041976929,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
"What is the initial assignment in exercise notebook 3.4-EXE-FFN-MNIST.ipynb, and what are the steps to execute it?","The first task is to use Kaiming He initialization instead of Xavier Glorot.
In order to implement this task:
We replace the Xavier initialization for self.W_1 and self.W_2 with init.kaiming_normal_, which initializes the weight matrices using the Kaiming He initialization method suitable for ReLU activation.
Code:
<code>",notebook 3_4,notebook 8_5_Deep,1.0,"code:
# initialize environment', ""env = gym.make('FrozenLake-v0')""]'

 
code:
# show initial state
s = env.reset()
env.render()'

 
markdown:
Let's define an experience replay memory that can be used to store new transitions and sample mini-batches of previous transitions. ""]'

 
code:
class ReplayMemory(object):
    """"""Experience Replay Memory""""""
    
    def __init__(self, capacity):
        #self.size = size
        self.memory = deque(maxlen=capacity)
    
    def add(self, *args):
        """"""Add experience to memory.""""""
        self.memory.append([*args])
    
    def sample(self, batch_size):
        """"""Sample batch of experiences from memory with replacement.""""""
        return random.sample(self.memory, batch_size)
    
    def count(self):
        return len(self.memory)'

 
markdown:
The Q-network is very similar to the one we have seen previously, but we add the possibility to update the parameters, so the same class can also be used as a target network.  '

 
code:
class DQN(nn.Module):
    """"""Deep Q-network with target network""""""
    
    def __init__(self, n_inputs, n_outputs, learning_rate):
        super(DQN, self).__init__()
        # network
        self.out = nn.Linear(n_inputs, n_outputs)
        # training
        self.optimizer = optim.SGD(self.parameters(), lr=learning_rate)
    
    def forward(self, x):
        return self.out(x)
    
    def loss(self, q_outputs, q_targets):
        return torch.sum(torch.pow(q_targets - q_outputs, 2))
    
    def update_params(self, new_params, tau):
        params = self.state_dict()
        for k in params.keys():
            params[k] = (1-tau) * params[k] + tau * new_params[k]
        self.load_state_dict(params)'

 
code:
# one-hot encoder for the states
def one_hot(i, l):
    a = np.zeros((len(i), l))
    a[range(len(i)), i] = 1
    return a'

 
markdown:
Before training, we create a policy network and copy its weight parameters to a target network, so they are initially the same. 
We also set up a replay memory and prefill it with random transitions sampled from the environment. '

 
code:
# train Deep Q-network

num_episodes = 1000
episode_limit = 100
batch_size = 64
learning_rate = 0.005
gamma = 0.99 # discount rate
tau = 0.01 # target network update rate
replay_memory_capacity = 10000
prefill_memory = True
val_freq = 100 # validation frequency

n_inputs = env.observation_space.n
n_outputs = env.action_space.n

# initialize DQN and replay memory
policy_dqn = DQN(n_inputs, n_outputs, learning_rate)
target_dqn = DQN(n_inputs, n_outputs, learning_rate)
target_dqn.load_state_dict(policy_dqn.state_dict())

replay_memory = ReplayMemory(replay_memory_capacity)",0.6364614963531494,CoursePlan.txt,3.0,"Week 1 computer exercise. Deadline: Monday week 2.
    Week 2 computer exercise. Deadline: Monday week 3.
    Week 3 computer exercise and 1 exercise of your own choice from course material week 1. Deadline: Monday week 4
    Week 4 computer exercise  and 1 exercise of your own choice from course material week 1-2. Deadline: Monday week 5.
    Week 5 computer exercise. Deadline: Monday week 6.
    Week 6 computer exercise. Deadline: Monday week 7.
    Week 7 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 8
    Week 8 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 9.
    Project selection. Deadline Friday, Oct 20th 2023 at 23.59.
    Link to 2023 project selection sheet
    Project synopsis. Deadline: Monday week 9 at 23:59. The synopsis should be approximately half a page and maximum one page with a project title, motivation, background, milestones and references. It is important that the plan is realistic. The main purposes of the synopsis are to make sure the project size is well-calibrated and is concrete enough to start working from day one. The synopsis will not be used in the evaluation. The synopsis should be sent to your project supervisor.
    Project poster session. PhD students taking the course as part of their PhD will not have to make a poster and take part of the poster session. In mixed groups of PhD and non-PhD students, only the non-PhD students have to take part in the poster session. The exam date is December 7th from 9 to 17. We divide the day into half hour slots and your group will later be given the possibility to register for a slot. A link to sign up for the poster session will appear here in due time. So having another exam on the same day should not be a problem. We will also organise an extra exam date for those of you who cannot make it on the date. It will be group poster presentations. We will invite outside guests and we will walk around and ask questions to all groups. We will make a schedule for when the teachers visit your poster. Plan for a 2 minute presentation per group member and 1-2 minutes for questions. The remainder of the time you can either present your poster to other students and guests or go visit other posters. Remember that it is important for the overall impression that you divide the presentation and answering of the questions more or less equally between you. The poster should be in A1 format. Remember to put both your names and student numbers under title. Here and here are links to examples using the latex template and here is one in powerpoint. You do not have to use that. The DTU library offers poster printing for a not too high price.",0.6491158604621887,notebook 7_1,2.0,"<img src=""static/autoencoder.png"" />

*The exercises are found at the bottom of the notebook*'

 
markdown:
## MNIST
First let us load the MNIST dataset and plot a few examples. In this notebook we will use the *dataloaders* and *datasets* provided by PyTorch. Defining the loading of datasets using a dataloader has the advantage that it only load the data that is *neccessary* into memory, which enables us to use very large scale datasets.

We only load a limited amount of classes defined by the `classes` variable to speed up training.'

 
code:
import torch
cuda = torch.cuda.is_available()

from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor

# Flatten the 2d-array image into a vector
flatten = lambda x: ToTensor()(x).view(28**2)

# Define the train and test sets
dset_train = MNIST(""./"", train=True,  transform=flatten, download=True)
dset_test  = MNIST(""./"", train=False, transform=flatten)

# The digit classes to use
classes = [3, 7]

def stratified_sampler(labels, classes):
    """"""Sampler that only picks datapoints corresponding to the specified classes""""""
    from functools import reduce
    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))
    indices = torch.from_numpy(indices)
    return SubsetRandomSampler(indices)


# The loaders perform the actual work
batch_size = 64
train_loader = DataLoader(dset_train, batch_size=batch_size,
                          sampler=stratified_sampler(dset_train.targets, classes), pin_memory=cuda)
test_loader  = DataLoader(dset_test, batch_size=batch_size, 
                          sampler=stratified_sampler(dset_test.targets, classes), pin_memory=cuda)'

 
code:
# Plot a batch of MNIST examples
f, axarr = plt.subplots(4, 16, figsize=(16, 4))

# Load a batch of images into memory
images, labels = next(iter(train_loader))

for i, ax in enumerate(axarr.flat):
    ax.imshow(images[i].view(28, 28), cmap=""binary_r"")', ""    ax.axis('off')"", '    ', ""plt.suptitle('MNIST handwritten digits')"", 'plt.show()'

 
markdown:
### Building the model
When defining the model the latent layer $z$ must act as a bottleneck of information. We initialize the AE with 1 hidden layer in the encoder and decoder using ReLU units as nonlinearities. The latent layer has a dimensionality of 2 in order to make it easy to visualise. Since $x$ are pixel intensities that are normalized between 0 and 1, we use the sigmoid nonlinearity to model the reconstruction.'

 
code:
import torch.nn as nn

# define size variables
num_features = 28*28",0.6544678211212158,notebook 5_3,18.0,"# First we unpack our parameters
    W_f, W_i, W_g, W_o, W_v, b_f, b_i, b_g, b_o, b_v = p
    
    # Save a list of computations for each of the components in the LSTM
    x_s, z_s, f_s, i_s,  = [], [] ,[], []
    g_s, C_s, o_s, h_s = [], [] ,[], []
    v_s, output_s =  [], [] 
    
    # Append the initial cell and hidden state to their respective lists
    h_s.append(h_prev)
    C_s.append(C_prev)
    
    for x in inputs:
        
        # Concatenate input and hidden state
        z = np.row_stack((h_prev, x))
        z_s.append(z)
        
        # Calculate forget gate
        # YOUR CODE HERE!
        f = 
        f_s.append(f)
        
        # Calculate input gate
        # YOUR CODE HERE!
        i = 
        i_s.append(i)
        
        # Calculate candidate
        g = tanh(np.dot(W_g, z) + b_g)
        g_s.append(g)
        
        # Calculate memory state
        # YOUR CODE HERE!
        C_prev = 
        C_s.append(C_prev)
        
        # Calculate output gate
        # YOUR CODE HERE!
        o = 
        o_s.append(o)
        
        # Calculate hidden state
        h_prev = o * tanh(C_prev)
        h_s.append(h_prev)

        # Calculate logits
        v = np.dot(W_v, h_prev) + b_v
        v_s.append(v)
        
        # Calculate softmax
        output = softmax(v)
        output_s.append(output)

    return z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, output_s


# Get first sentence in test set
inputs, targets = test_set[1]

# One-hot encode input and target sequence
inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
targets_one_hot = one_hot_encode_sequence(targets, vocab_size)

# Initialize hidden state as zeros
h = np.zeros((hidden_size, 1))
c = np.zeros((hidden_size, 1))

# Forward pass
z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs = forward(inputs_one_hot, h, c, params)

output_sentence = [idx_to_word[np.argmax(output)] for output in outputs]', ""print('Input sentence:')"", 'print(inputs)
', ""print('\Target sequence:')"", 'print(targets)
', ""print('\Predicted sequence:')"", 'print([idx_to_word[np.argmax(output)] for output in outputs])'

 
markdown:
## Exercise I:'

 
markdown:
Complete the implementation of the LSTM forward pass above. Refer to the equations and figures further up if you're in doubt.""]'

 
markdown:
## Backward pass'

 
markdown:
Similar to the RNN in numpy we also need to specify a backward pass. Fortunately, we have already done the work for you here :-)

Feel free to dive into the code to get a better intuition of what is going on -- otherwise you can jump straight to the training loop.'",0.6696693301200867,notebook 4_1,2.0,"code:
# Load the MNIST data. 

# Note that we reshape the data from:
#   (nsamples, num_features) = (nsamples, channels * height * width)
# to:
#   (nsamples, channels, height, width)
# in order to retain the spatial arrangements of the pixels.
', ""data = np.load('mnist.npz')"", 'channels, height, width = 1, 28, 28


def get_data(split, size):
    x = data[f""X_{split}""][:size].astype(\'float32\')
    x = x.reshape((-1, channels, height, width))
    targets = data[f""y_{split}""][:size].astype(\'int64\')
    return torch.from_numpy(x), torch.from_numpy(targets)

', ""x_train, targets_train = get_data('train', 50000)"", ""x_valid, targets_valid = get_data('valid', 2000)"", ""x_test, targets_test = get_data('test', 5000)"", '
num_classes = len(np.unique(targets_train))

print(""Information on dataset"")
print(""Shape of x_train:"", x_train.shape)
print(""Shape of targets_train:"", targets_train.shape)
print(""Shape of x_valid:"", x_valid.shape)
print(""Shape of targets_valid:"", targets_valid.shape)
print(""Shape of x_test:"", x_test.shape)
print(""Shape of targets_test:"", targets_test.shape)'

 
code:
# Plot a few MNIST examples
plt.figure(figsize=(7, 7))
plt.imshow(make_grid(x_train[:100], nrow=10).permute(1, 2, 0))', ""plt.axis('off')"", 'plt.show()'

 
markdown:
# Define a simple feed forward neural network'

 
code:
assert (channels, height, width) == x_train.shape[1:]
n_features = channels * height * width


class PrintSize(nn.Module):
    """"""Utility module to print current shape of a Tensor in Sequential, only at the first forward pass.""""""
    
    first = True
    
    def forward(self, x):
        if self.first:
            print(f""Size: {x.size()}"")
            self.first = False
        return x


class Model(nn.Module):

    def __init__(self):
        super(Model, self).__init__()
        activation_fn = nn.ReLU

        self.net = nn.Sequential(
            nn.Flatten(),  # from (1, channels, height, width) to (1, channels * height * width)
            nn.Linear(n_features, 128),
            activation_fn(),
            nn.Linear(128, 128),
            activation_fn(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.net(x)


model = Model()
print(model)

loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)'

 
code:
# Test the forward pass with dummy data
out = model(torch.randn(2, 1, 28, 28))
print(""Output shape:"", out.size())
print(f""Output logits:\{out.detach().numpy()}"")
print(f""Output probabilities:\{out.softmax(1).detach().numpy()}"")'

 
markdown:
# Train network'",0.671069324016571,notebook 3_3,3.0,"# list individual parameters by name', ""print('WEIGHTS')"", 'print(net.W_1)
print(net.W_1.size())', ""print('\BIAS')"", 'print(net.b_1)
print(net.b_1.size())'

 
markdown:
# Exploring Parameter
', ""Ok, let's investigate what a Parameter is""]'

 
code:
param = net.W_1
print(""## this is the tensor"")
print(param.data)
print(""\## this is the tensor\'s gradient"")
print(param.grad)
# notice, the gradient is undefined because we have not yet run a backward pass

print(""\## is it a leaf in the graph?"")
print(param.is_leaf)'

 
markdown:
## Excluding subgraphs from backward propagation
', ""To exclude part of your computational graph (i.e. a subgraph) from backward propagation, simply set the relevant tensors' attribute `requires_grad` to `False`."", '
If there’s a single input to an operation that requires gradient, its output will also require gradient. Conversely, only if all inputs don’t require gradient, the output also won’t require it. Backward computation is never performed in the subgraphs, where all Tensors didn’t require gradients.'

 
markdown:
# Test network
', ""To use our network we can simply call our graph, and it will dynamically be created. Here is an example of running the network's forward pass.""]'

 
code:
X = torch.randn(5, num_features)
# the net.__call__ runs some pre-defined functions
# both before and after running net.forward()
# see http://pytorch.org/docs/master/_modules/torch/nn/modules/module.html
', ""print('input')"", 'print(X)
', ""print('\output')"", 'print(net(X))'

 
markdown:
`Parameter`s are a special kind of `Tensor`'

 
code:
# let's take a look at the gradients"", 'for p in net.parameters():
    print(p.data)
    print(p.grad)
    print()'

 
code:
X = torch.randn(7, num_features)
out = net(X)
# we need to give a tensor of gradients to .backward,
# we give a dummy tensor
out.backward(torch.randn(7, num_output))'

 
markdown:
for details on `.backward()`, see http://pytorch.org/docs/master/autograd.html#torch.autograd.backward'

 
code:
# let's take a look at the gradients"", 'for p in net.parameters():
    print(p.data)
    print(p.grad)
    print()'

 
code:
# ok, let's try and zero the accumulated gradients"", 'net.zero_grad()
for p in net.parameters():
    print(p.data)
    print(p.grad)'

 
markdown:
# Loss function
', ""Let's define a custom loss function to compute how good our graph is doing.""]'

 
code:
def cross_entropy(ys, ts):
    # computing cross entropy per sample
    cross_entropy = -torch.sum(ts * torch.log(ys), dim=1, keepdim=False)
    # averaging over samples
    return torch.mean(cross_entropy)'",0.6715171337127686,notebook 8_3,4.0,"code:
# plot results
def moving_average(a, n=10) :
    ret = np.cumsum(a, dtype=float)
    ret[n:] = ret[n:] - ret[:-n]
    return ret / n

plt.figure(figsize=(16,6))
plt.subplot(211)', ""plt.plot(range(1, len(training_rewards)+1), training_rewards, label='training reward')"", 'plt.plot(moving_average(training_rewards))', ""plt.xlabel('episode'); plt.ylabel('reward')"", 'plt.xlim((0, len(training_rewards)))
plt.legend(loc=4); plt.grid()
plt.subplot(212)', ""plt.plot(range(1, len(losses)+1), losses, label='loss')"", 'plt.plot(moving_average(losses))', ""plt.xlabel('episode'); plt.ylabel('loss')"", 'plt.xlim((0, len(losses)))
plt.legend(loc=4); plt.grid()
plt.tight_layout(); plt.show()'

 
markdown:
Now let's review the solution!""]'

 
code:
env = Recorder(env, ""./gym-results"") # wrappers.Monitor(env, ""./gym-results"", force=True) # Create wrapper to display environment
s = env.reset()

for _ in range(500):
    a = policy(torch.from_numpy(np.atleast_2d(s)).float()).argmax().item()
    s, r, done, _ = env.step(a)
    if done: break
    
# env.close()
env.play()'

 
markdown:
## Reducing variance

By default, this gradient estimator has high variance and therefore variance reduction becomes important to learn more complex tasks.
We can reduce variance by subtracting a baseline from the returns, which is unbiased in expectation:

$$
\abla_\\theta \\mathbb{E}[R|\\theta] \\approx \\frac{1}{T} \\sum_{t=0}^T \abla_\\theta \\log p_\\theta(a_t|s_t) (R_t-b_t) \\ ,
$$

where the baseline, $b_t$, is estimated by the return a timestep $t$ averaged over $V$ rollouts.

$$
b_t = \\frac{1}{V} \\sum_{v=1}^V R_t^{(v)} \\ .
$$'

 
markdown:
## Exercises

Now it is your turn! Make sure you read and understand the code, then play around with it and try to make it learn better and faster.

Experiment with the:

* number of episodes
* discount factor
* learning rate
* network layers


### Exercise 1 

*Describe any changes you made to the code and why you think they improve the agent. Are you able to get solutions consistently?*

**Answer:**

*Answer here...*

### Exercise 2 

*Consider the following sequence of rewards produced by an agent interacting with an environment for 10 timesteps:*

[0, 1, 1, 1, 0, 1, 1, 0, 0, 0]

* *What is the total reward?*
* *What is the total future reward in each timestep?*
* *What is the discounted future reward in each timestep if $\\gamma = 0.9$?*

*Hint: See introdution notebook.*",0.6725883483886719,notebook 8_2_Prerequisites_ipynb,1.0,"# Run environment
while True:
    action = env.action_space.sample() # Get a random action
    _, _, done, _ = env.step(action) # Take a step
    if done: break # Break if environment is done

env.close() # Close environment
env.play() # Show the video'

 
markdown:
Hooray! You now have a working `Gym` environment that we can take actions in and render.'",0.6802330017089844,notebook 4_2,1.0,"print(""\Test data"")
print(""Number of points:"", len(test_set))
x, y = next(iter(test_loader))
print(""Batch dimension (B x C x H x W):"", x.shape)
print(f""Number of distinct labels: {len(set(test_set.targets))} (unique labels: {set(test_set.targets)})"")

n_classes = len(set(test_set.targets))'

 
markdown:
### Show example images

Run multiple times to see different examples.'

 
code:
# Get random training images and show them.
images, labels = next(iter(train_loader))
show_image(torchvision.utils.make_grid(images))'

 
markdown:
## Define a convolutional neural network


**Assignment 1:** Define a convolutional neural network. 
You may use the code from previous notebooks.
We suggest that you start with a small network, and make sure that everything is working.
Once you can train successfully, come back and improve the architecture.'

 
code:
class PrintSize(nn.Module):
    """"""Utility module to print current shape of a Tensor in Sequential, only at the first pass.""""""
    
    first = True
    
    def forward(self, x):
        if self.first:
            print(f""Size: {x.size()}"")
            self.first = False
        return x


class Model(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.num_classes = num_classes
        # Your code here!

    def forward(self, x):
        # Your code here!
        return x


model = Model(n_classes)', ""device = torch.device('cpu')  # use cuda or cpu"", 'model.to(device)
print(model)'

 
markdown:
## Define a loss function and optimizer

**Assignment 2:** Define the loss function and optimizer.
You might need to experiment a bit with the learning rate.'

 
code:
loss_fn = None  # Your code here!
optimizer = None  # Your code here!'

 
markdown:
## Train the network

**Assignment 3:** Finish the training loop below. 
Start by using a small number of epochs (e.g. 2).
Even with a low number of epochs you should be able to see results that are better than chance.
When everything is working increase the number of epochs to find out how good your network really is.'

 
code:
# Test the forward pass with dummy data
out = model(torch.randn(2, 3, 32, 32, device=device))
print(""Output shape:"", out.size())
print(f""Output logits:\{out.detach().cpu().numpy()}"")
print(f""Output probabilities:\{out.softmax(1).detach().cpu().numpy()}"")'

 
code:
batch_size = 64
num_epochs = 2
validation_every_steps = 500

step = 0
model.train()",0.688973605632782,notebook 4_2,2.0,"code:
batch_size = 64
num_epochs = 2
validation_every_steps = 500

step = 0
model.train()

train_accuracies = []
valid_accuracies = []
        
for epoch in range(num_epochs):
    
    train_accuracies_batches = []
    
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        
        # Forward pass, compute gradients, perform one training step.
        # Your code here!
        
        # Increment step counter
        step += 1
        
        # Compute accuracy.
        predictions = output.max(1)[1]
        train_accuracies_batches.append(accuracy(targets, predictions))
        
        if step % validation_every_steps == 0:
            
            # Append average training accuracy to list.
            train_accuracies.append(np.mean(train_accuracies_batches))
            
            train_accuracies_batches = []
        
            # Compute accuracies on validation set.
            valid_accuracies_batches = []
            with torch.no_grad():
                model.eval()
                for inputs, targets in test_loader:
                    inputs, targets = inputs.to(device), targets.to(device)
                    output = model(inputs)
                    loss = loss_fn(output, targets)

                    predictions = output.max(1)[1]

                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).
                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))

                model.train()
                
            # Append average validation accuracy to list.
            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))
     
            print(f""Step {step:<5}   training accuracy: {train_accuracies[-1]}"")
            print(f""             test accuracy: {valid_accuracies[-1]}"")

print(""Finished training."")'

 
markdown:
## Test the network

Now we show a batch of test images and generate a table below with the true and predicted class for each of these images.'

 
code:
inputs, targets = next(iter(test_loader))
inputs, targets = inputs.to(device), targets.to(device)
show_image(make_grid(inputs))
plt.show()

outputs = model(inputs)
_, predicted = torch.max(outputs.data, 1)

print(""    TRUE        PREDICTED"")
print(""-----------------------------"")
for target, pred in zip(targets, predicted):
    print(f""{classes[target.item()]:^13} {classes[pred.item()]:^13}"")'

 
markdown:
We now evaluate the network as above, but on the entire test set.'

 
code:
# Evaluate test set
confusion_matrix = np.zeros((n_classes, n_classes))
with torch.no_grad():
    model.eval()
    test_accuracies = []
    for inputs, targets in test_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        output = model(inputs)
        loss = loss_fn(output, targets)

        predictions = output.max(1)[1]

        # Multiply by len(inputs) because the final batch of DataLoader may be smaller (drop_last=True).
        test_accuracies.append(accuracy(targets, predictions) * len(inputs))
        
        confusion_matrix += compute_confusion_matrix(targets, predictions)

    test_accuracy = np.sum(test_accuracies) / len(test_set)
    
    model.train()'",0.6897542476654053,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
What do we expect to learn from week4?,"In this lab, we will learn how to create your own convolutional classifier for different datasets, and the technologies to improve the performance of your convolutional classifier. ","notebook 4_1, notebook 4_2",CoursePlan.txt,3.0,"Week 1 computer exercise. Deadline: Monday week 2.
    Week 2 computer exercise. Deadline: Monday week 3.
    Week 3 computer exercise and 1 exercise of your own choice from course material week 1. Deadline: Monday week 4
    Week 4 computer exercise  and 1 exercise of your own choice from course material week 1-2. Deadline: Monday week 5.
    Week 5 computer exercise. Deadline: Monday week 6.
    Week 6 computer exercise. Deadline: Monday week 7.
    Week 7 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 8
    Week 8 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 9.
    Project selection. Deadline Friday, Oct 20th 2023 at 23.59.
    Link to 2023 project selection sheet
    Project synopsis. Deadline: Monday week 9 at 23:59. The synopsis should be approximately half a page and maximum one page with a project title, motivation, background, milestones and references. It is important that the plan is realistic. The main purposes of the synopsis are to make sure the project size is well-calibrated and is concrete enough to start working from day one. The synopsis will not be used in the evaluation. The synopsis should be sent to your project supervisor.
    Project poster session. PhD students taking the course as part of their PhD will not have to make a poster and take part of the poster session. In mixed groups of PhD and non-PhD students, only the non-PhD students have to take part in the poster session. The exam date is December 7th from 9 to 17. We divide the day into half hour slots and your group will later be given the possibility to register for a slot. A link to sign up for the poster session will appear here in due time. So having another exam on the same day should not be a problem. We will also organise an extra exam date for those of you who cannot make it on the date. It will be group poster presentations. We will invite outside guests and we will walk around and ask questions to all groups. We will make a schedule for when the teachers visit your poster. Plan for a 2 minute presentation per group member and 1-2 minutes for questions. The remainder of the time you can either present your poster to other students and guests or go visit other posters. Remember that it is important for the overall impression that you divide the presentation and answering of the questions more or less equally between you. The poster should be in A1 format. Remember to put both your names and student numbers under title. Here and here are links to examples using the latex template and here is one in powerpoint. You do not have to use that. The DTU library offers poster printing for a not too high price.",0.7258585691452026,CoursePlan.txt,5.0,"Detailed content

Links to individual video lectures and lecture slides are given below. Here is a link to all 2016 video lectures as a playlist and a Google doc folder with all the lecture slides. More videos have been added over the years. They are all linked below. A very good alternative video resource is Hugo Larochelle’s YouTube playlist.
Week 1 - Feed-forward neural networks - do it yourself pen and paper

    During this week and the following two weeks watch video lectures: 

    Part 0 Overview
    Part 1 Deep learning
    Part 2.1 Feed-forward neural networks
    Part 2.2 Feed-forward neural networks
    Part 3 Error Backpropagation
    Part 4 Optimization

and take notes for at least 3 questions to ask. Link to lecture slides is here.

    During this week and the following two weeks read Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapters 1-3 (stop when reaching the section called Overfitting and regularization) and browse Chapter 4. Note that this is reading material for the first three weeks of the course. Also, in total six exercises of your own choice will be homework later in the course.
    Alternative textbooks: All topics are also covered in the deep learning book that may be read as a supplement. The book can also be bought from the DTU bookstore. You will get 10% discount with this link. Feed-forward neural networks are covered in this chapter. Chapter 1 gives an introduction to deep learning and Part II gives the necessary background on linear algebra, probability, numerical computation and machine learning. Alternative textbook 2: Chris Bishop, Pattern recognition and machine learning. If you need to up your game in mathematics, the book Mathematics for machine learning is an excellent resource and the note Mathematics for Machine Learning offers a concise and compressed collection of the mathematical concepts used in deep learning. These resources are freely available online and are very valuable sources of information.
    Install software on your laptop or go directly to Google CoLab (see above). Installation guide for laptop and cloud may be found here.
    Carry out computer exercises week 1. It is encouraged to work together with other students. Type in everything yourself. Code answers are fine not to differ much within the group and text answers should be in your own words. Note that the computer exercises may experience minor change up to 3 days before the actual session. The hand-in is the notebook with your modifications. It is only allowed to hand in .ipynb files. Each week you should only hand in one file. It is the file with EXE in its name. You hand in on peergrade.io. In order to be able to hand in on peergrade you can use this invitation link https://app.peergrade.io/join/JFFJBF or login into peergrade and use the invitation code JFFJBF. There you will receive information on handing in exercises and deadlines for activities. Some students have previously by accident signed up twice with different emails or forgotten the “student” in their DTU student mail address. If you then submit and check with different email addresses it will look as though you have not handed in.
    Peergrade exercise from three other students through peergrade.io. 

Week 2 - Feed-forward neural networks - do it yourself in NumPy",0.7574012279510498,CoursePlan.txt,8.0,"Week 7 - Un- and semi-supervised learning

    Watch week 5 video lectures

    02456week5 1 1 unsupervised learning
    02456week5 1 2 unsupervised learning latent variables
    02456week5 2 1 autoencoders
    02456week5 2 2 autoencoders layerwise pretraining
    02456week5 3 1 variational autoencoders
    02456week5 3 2 semi-supervised variational autoencoders 
    2017 Generative adversarial networks
    2020 Flows
    2020 Self-supervised learning
    2020 Self-training/noisy student
    2020 Distribution Augmentation
    2020 Flat minima

and take notes for at least 3 questions to ask. Link to lecture slides 2016 slides and 2017 slides and 2020 slides.

    Reading material DL Chapter 14 and 20.10.3. (Further learning a course dedicated to generative modelling.)
    One exercise from the book chapters.
    Carry out computer exercises week 7 on autoencoder un- and semi-supervised. Hand in and peergrade on peergrade.io like in previous weeks.
    Project selection deadline is this week (see above).

Week 8 - Reinforcement learning 

    Watch week 6 video lectures 

    02456week6 1 1 reinforcement learning
    02456week6 1 2 reinforcement learning approaches
    02456week6 2 1 AlphaGo policy and value networks
    02456week6 2 2 AlphaGo steps 1 to 4
    02456week6 3 policy gradients
    02456week6 4 a few last words
    2017 Deep Q learning
    2017 Evolutionary strategies

and take notes for at least 3 questions to ask. Link to lectures here and here for 2017 update.

    Reading: another nice blog post by Andrei Karpathy. Optional reading material on the connection between variational and reinforcement learning.
    One exercise from the book chapters. 
    Computer exercises on reinforcement learning methods (policy gradient, deep Q learning, evolutionary strategies) in the openAI Gym. Carry out exercises week 8. Hand in and peergrade on peergrade.io like in previous weeks.
    Project work.",0.760018527507782,LearningObjectives.txt,0.0,"Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.

Understand and explain the choices and limitations of a model for a given setting.

Apply and analyze results from deep learning models in exercises and own project work.

Plan, delimit and carry out an applied or methods-oriented project in collaboration with fellow students and project supervisor.

Assess and summarize the project results in relation to aims, methods and available data.

Carry out the project and interpret results by use of computational framework for GPU programming such as PyTorch.

Structure and write a final short technical report including problem formulation, description of methods, experiments, evaluation and conclusion.

Organize and present project results at the final project presentation and in report.

Read, evaluate and give feedback to work of other students.",0.7844336032867432,CoursePlan.txt,6.0,"Week 2 - Feed-forward neural networks - do it yourself in NumPy

    See 1. and 2. from Week 1.
    Carry out computer exercises week 2.
    Peergrade exercise from three other students through peergrade.io. 

Week 3 - Feed-forward neural networks in PyTorch

    See 1. and 2. from Week 1.
    Carry out computer exercises week 3.
    Peergrade exercise from three other students through peergrade.io.
    Hand in the notebook marked with EXE on peergrade.io. It should contain your added code in the exercises and the answer of one exercise from Michael Nielsen's book (see point 3. above). The answer to the book exercise should be in a markdown cell at the bottom of the notebook.
    Peergrade exercise from three other students through peergrade.io.  

Week 4 - Convolutional neural networks

    Watch week 2 video lectures  

    Part 1 Introduction to CNNs (PART 1/2)
    Part 1 Introduction to CNNs (PART 2/2)
    Part 2 CNNs the details (PART 1/2)
    Part 2 CNNs the details (PART 2/2)
    2017 CNN update
    2017 Activation functions update
    2017 Image segmentation

and take notes for at least 3 questions to ask. Link to lecture slides is here and here for 2017 updates.

    Reading material Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapter 6 (stop when reaching section called Other approaches to deep neural nets).
    Alternative textbook chapter in the deep learning book.
    One exercise from the book chapters.
    Carry out computer exercises week 4.
    Hand in the notebook marked with EXE on peergrade.io.
    Peergrade exercise from three other students through peergrade.io. You will receive instructions about this from peergrade.io.

Week 5 - Transformers and recurrent neural networks

    Watch week 3 video lectures

    02456week3 1 RNN (PART 1 of 3)
    02456week3 1 RNN (PART 2 of 3)
    02456week3 1 RNN (PART 3 of 3)
    02456week3.2_RNN_training (PART 1 of 3)
    02456week3.2_RNN_training (PART 2 of 3)
    02456week3 2 RNN training (PART 3 of 3)
    02456week3 3 Attention (PART 1 of 2)
    02456week3 3 Attention (PART 2 of 2)
    02456week3 4 Supervised learning recap
    2017 Quasi RNN
    2017 Non-recurrent sequence to sequence models
    2017 Text summarization
    2020 Transformers (PART 1 of 2)
    2020 Transformers (PART 2 of 2)
    2020 Language modelling - GPT-2 and 3
    2020 BERT

and take notes for at least 3 questions to ask. Link to: 2016 lectures, 2017 lecture updates and 2020 lecture updates.",0.8110289573669434,CoursePlan.txt,4.0,"Final report deadline December 21st at 23:59. [Note this was earlier set to a later date but according to DTU rules, the latest allowed deadline is December 21st.] The report should be a maximum 6 pages plus references using this conference paper format. The report should also contain a link to your project code Github repository. Among the files in the repository should be a jupyter notebook that ideally should recreate the main results of your report. If some of your data is confidential then use some shareable data instead. For MSc students, please also include your poster in the submission.",0.8168200254440308,CoursePlan.txt,7.0,"and take notes for at least 3 questions to ask. Link to: 2016 lectures, 2017 lecture updates and 2020 lecture updates.

    Reading material Alex Graves book, Supervised Sequence Labelling with Recurrent Neural Networks Chapters 3.1, 3.2 and 4. Browse Michael Nielsen, Neural networks and deep learning Chapter 6 section Other approaches to deep neural nets) and onwards. A good introduction to Transformers is The Illustrated Transformer. New tutorial on Transformers https://aman.ai/primers/ai/transformers/#one-hot-encoding
    Alternative textbook chapter in the deep learning book. Andrej Karpathy has a nice blogpost that gives a good flavour of the whats and hows of RNNs.
    Carry out computer exercises week 5
    Hand in and peergrade on peergrade.io like in previous week.

Week 6 - Tricks of the trade and data science challenge

    Watch week 4 video lectures 

    02456week4 1 1 Initialization and gradient clipping 
    02456week4 1 2 batch normalization
    02456week4 2 1 regularization
    02456week4 2 2 regularization methods
    02456week4 2 3 data augmentation
    02456week4 2 4 ensemble methods and dropout
    02456week4 3 recap
    2017 37 reasons your nn working (part 1 of 2) Walk through of the 37 reasons why your neural network is not working blog post.
    2017 37 reasons you not working (part 2 of 2)
    2020 Recipe to training neural networks - become one with data (part 1 of 3).
    2020 Recipe to training neural networks - baselines (part 2 of 3).
    2020 Recipe to training neural networks - overfit, tune and tune some more (part 3 of 3).

and take notes for at least 3 questions to ask. Link to lecture slides 2016 lecture slides, 2017 blog post and 2020 lecture slides.  

    Reading material Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapter 3 from section Overfitting and regularization and Chapter 5.
    Alternative textbook chapters on regularization, optimization, deep learning practice and applications from the deep learning book.  
    Additional material: Andrei Karpathy blogpost on how to approach a data science problem with deep learning, blogpost on things that can go wrong in neural network training and interactive initialization demo.
    Computer exercises week 6 using PyTorch on the Kaggle competition leaf classification. Hand in and peergrade on peergrade.io like in previous weeks.

Week 7 - Un- and semi-supervised learning

    Watch week 5 video lectures",0.8267421722412109,CoursePlan.txt,0.0,"02456 Deep learning 2023 - course plan and information

Time: Mondays at 13:00-17:00 (first session is August 28th, 2023)

Locations: We will use the following rooms - building/room - (Campus map):

B303A-A042

B303A-046

B303A-047

B303A-048

B303A-HOEST

Zoom (You need to sign-in with you DTU account)

We use flipped classroom teaching. During the weeks with labs, the teachers and teaching assistants will circulate between the rooms so there will be opportunity to meet all. Any short lectures/instructions will be repeated in all rooms. You are free to choose whatever room you prefer of course respecting the limits on room capacity. During the weeks with project work each room will cover specific topics.

If you are not able to be on campus or prefer to work remotely you will be able to participate through Zoom. One teaching assistant will be dedicated to the Zoom channel: Zoom.

We also use Slack for communication: We will make dedicated channels for labs and projects. Here is a Slack invite link. (In Slack you can add channels from the list of channels by clicking the “+” next to Channels in the left panel and click “Browse channels” to choose.)

Bring a laptop.

The first eight weeks of the course will be dedicated to lab work. There will be a brief introduction to the course at the first session and a number of dedicated meetings online or in person with project supervisors.

Teachers

    Ole Winther
    Jes Frellsen

Teaching assistants

    Aleksander Nagaj
    Anders Christensen
    Anna Maria Clara Schibelle
    Anshuk Uppal
    Beatrix Miranda Ginn Nielsen
    Bo Li
    Kenny Olsen
    Marco Miani
    Nina Weng
    Paul Jeha
    Pawel Tomasz Pieta
    Raul Ortega Ochoa
    Teresa Karen Scheidt
    Thea Brüsch

Google CoLab

Google CoLab is a free cloud based Jupyter notebook platform with collaboration functionality. It even has GPUs and you don't need any credits, just log in with your Google account. To start, import a notebook using a github link or upload it from your pc: https://colab.research.google.com/. Setting up is quite straightforward. If you need to install libraries you can add that in a code cell with `! pip install <library name>`. You can upload some extra files (such as additional py scripts) that your jupyter notebook will use.
Other free GPU compute resources

It might be that Google CoLab will start putting restrictions if you use it too much. But there are alternatives:
DTU HPC

Nicklas Hansen and Aleksander Nagaj and Anna Schibelle (2023 update) have made this guide.
Google cloud platform (GCP)

You can also sign up to Google cloud (GCP) and get free credits there. Here are instructions on how to set up GPU computation on Google cloud. Follow the instructions until Optional.
Topics in the first eight weeks",0.8319224119186401,notebook 8_3,2.0,"def forward(self, x):
        x = self.hidden(x)
        x = F.relu(x)
        x = self.out(x)
        return F.softmax(x, dim=1)
    
    def loss(self, action_probabilities, returns):
        return -torch.mean(torch.mul(torch.log(action_probabilities), returns))'

 
code:
def compute_returns(rewards, discount_factor):
    """"""Compute discounted returns.""""""
    returns = np.zeros(len(rewards))
    returns[-1] = rewards[-1]
    for t in reversed(range(len(rewards)-1)):
        returns[t] = rewards[t] + discount_factor * returns[t+1]
    return returns'

 
markdown:
To start with, our policy will be a rather simple neural network with one hidden layer. We can retrieve the shape of the state space (input) and action space (output) from the environment.'

 
code:
n_inputs = env.observation_space.shape[0]
n_hidden = 20
n_outputs = env.action_space.n
', ""print('state shape:', n_inputs)"", ""print('action shape:', n_outputs)""]'

 
code:
# training settings

num_episodes = 800
rollout_limit = 500 # max rollout length
discount_factor = 1.0 # reward discount factor (gamma), 1.0 = no discount
learning_rate = 0.001 # you know this by now
val_freq = 100 # validation frequency

# setup policy network

policy = PolicyNet(n_inputs, n_hidden, n_outputs, learning_rate)

# train policy network",0.83990079164505,notebook 5_3,0.0,"markdown:
# Week 5 - Recurrent Neural Networks

In this lab, we will introduce different ways of learning from sequential data.

As a recurring example, we will train neural networks to do language modelling, i.e. predict the next token in a sentence. In the context of natural language processing a token could be a character or a word, but mind you that the concepts introduced here apply to all kinds of sequential data, such as e.g. protein sequences, weather measurements, audio signals, or videos, just to name a few.
', ""To really get a grasp of what is going on inside a recurrent neural network (RNN), we will carry out a substantial part of this exercise in NumPy rather than PyTorch. We start off with a simple toy problem, build an RNN using NumPy, train and it, and see for ourselves that it really works. Once we're convinced, we proceed to build and train a Long Short-Term Memory (LSTM) cell, also in NumPy. This is *not* simply to cause you frustration, but rather to provide you with a deeper understanding of the recurrence in RNNs, which will become very beneficial to you in the following weeks. Once you understand the inner workings of an RNN, we will proceed to a PyTorch implementation that you may use for the remainder of the course and in your projects."", '
To summarize, in this notebook we will show you:
* How to represent sequences of categorical variables
* How to build and train an RNN in NumPy
* How to build and train an LSTM network in NumPy
* How to build and train an LSTM network in PyTorch'

 
markdown:
## Representing tokens or text

In previous labs we mainly considered data $x \\in \\mathrm{R}^d$, where $d$ is the feature space dimension.
With time sequences our data can be represented as $x \\in \\mathrm{R}^{t \\, \\times \\, d}$, where $t$ is the sequence length. 
This emphasises sequence dependence and that the samples along the sequence are not independent and identically distributed (i.i.d.).
We will model functions as $\\mathrm{R}^{t \\, \\times \\, d} \\rightarrow \\mathrm{R}^c$, where $c$ is the amount of classes in the output.

There are several ways to represent sequences. With text, the challenge is how to represent a word as a feature vector in $d$ dimensions, as we are required to represent text with decimal numbers in order to apply neural networks to it.

In this exercise we will use a simple one-hot encoding but for categorical variables that can take on many values (e.g. words in the English language) this may be infeasible. For such scenarios, you can project the encodings into a smaller space by use of embeddings. If you want to learn more about tokens, encodings and embeddings than what is covered in this exercise, we highly recommend [this lecture](https://www.youtube.com/watch?v=kEMJRjEdNzM&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z).'

 
markdown:
### One-hot encoding over vocabulary",0.8438917994499207,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
What is CIFAR-10 dataset?,The images in CIFAR-10 are RGB images (3 channels) with size 32x32 (so they have size 3x32x32). There are 10 different classes.,notebook 4_2,notebook 4_2,0.0,"markdown:
# CNN on CIFAR-10

In this notebook you need to put what you have learned into practice, and create your own convolutional classifier for the CIFAR-10 dataset.

The images in CIFAR-10 are RGB images (3 channels) with size 32x32 (so they have size 3x32x32). There are 10 different classes. See examples below.

![cifar10](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/static_files/cifar10.png?raw=1)'

 
markdown:
## Preliminaries'

 
code:
%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
from torch import nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
import torchvision
import torchvision.transforms as transforms
from torchvision.utils import make_grid
from sklearn import metrics

sns.set_style(""whitegrid"")

def accuracy(target, pred):
    return metrics.accuracy_score(target.detach().cpu().numpy(), pred.detach().cpu().numpy())

def compute_confusion_matrix(target, pred, normalize=None):
    return metrics.confusion_matrix(
        target.detach().cpu().numpy(), 
        pred.detach().cpu().numpy(),
        normalize=normalize
    )

def show_image(img):
    img = img.detach().cpu()
    img = img / 2 + 0.5   # unnormalize
    with sns.axes_style(""white""):
        plt.figure(figsize=(8, 8))
        plt.imshow(img.permute((1, 2, 0)).numpy())', ""        plt.axis('off')"", '        plt.show()'

 
code:
# The output of torchvision datasets are PIL images in the range [0, 1]. 
# We transform them to PyTorch tensors and rescale them to be in the range [-1, 1].
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # subtract 0.5 and divide by 0.5
    ]
)

batch_size = 64  # both for training and testing

# Load datasets', ""train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)"", ""test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"", 'train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False)
test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)

# Map from class index to class name.
classes = {index: name for name, index in train_set.class_to_idx.items()}'

 
code:
print(""Training data"")
print(""Number of points:"", len(train_set))
x, y = next(iter(train_loader))
print(""Batch dimension (B x C x H x W):"", x.shape)
print(f""Number of distinct labels: {len(set(train_set.targets))} (unique labels: {set(train_set.targets)})"")",0.439159095287323,notebook 5_1,11.0,"code:
max_dataset_size = 1000 # let's use a small subset for now,"", 'max_seq_size = 10 # and very short sequences

# load and tokenizer the dataset
def batch_tokenize(batch: List[Dict[str, Any]], max_length=max_seq_size, tokenizer: tokenizers.Tokenizer = None, key:str=""text"") -> torch.Tensor:
    texts = batch[key]
    encodings = tokenizer.encode_batch(texts)
    return {""token_ids"": [x.ids[:max_length] for x in encodings]}

# load AG News, take a subset of `max_dataset_size` rows and tokenize
dataset = datasets.load_dataset(""ag_news"")
dataset = datasets.DatasetDict({split: dset.select(range(max_dataset_size)) if len(dset) > max_dataset_size else dset for split, dset in dataset.items()})
dataset = dataset.map(partial(batch_tokenize, tokenizer=glove_tokenizer), batched=True, num_proc=2, batch_size=10)
rich.print(dataset)'

 
code:
class RNNLM(torch.nn.Module):
    """"""A simple implementation of a language model using RNNs.""""""
    def __init__(self, vectors:torch.Tensor):
        super().__init__()
        # register the embeddings
        self.embeddings = torch.nn.Embedding(*glove_vectors.shape)
        self.embeddings.weight.data = glove_vectors

        # register the LSTM
        self.rnn = torch.nn.LSTM(
            input_size=glove_vectors.shape[1],
            hidden_size=glove_vectors.shape[1],
            num_layers=1,
            batch_first=True,
        )

        # project the output of the LSTM (hidden state) back to the vocabulary space
        self.proj = nn.Linear(glove_vectors.shape[1], glove_vectors.shape[0], bias=False)
        # init the projection using the embeddings weights
        self.proj.weight.data = glove_vectors

    def forward(self, token_ids: torch.Tensor, retain_ws:bool=False) -> torch.Tensor:
        # convert the tokens into vectors
        ws = self.embeddings(token_ids)

        # store the word vectors for debugging
        if retain_ws:
          ws.retain_grad()
          self.ws = ws

        # shift the input `ws` right
        w0 = torch.zeros((ws.shape[0], 1, self.embeddings.weight.shape[1]),
                         device=self.embeddings.weight.device, dtype=torch.long)
        ws_shifted = torch.cat([w0, ws[:, :-1]], dim=1)

        # call the RNN: w_{-1:T-1} -> h{1:T}
        hidden_states, _ = self.rnn(ws_shifted)

        # project the hidden state to the vocabulary space
        logits = self.proj(hidden_states)
        return logits",0.6617038249969482,notebook 4_3,0.0,"markdown:
# Transfer learning on the Caltech101 dataset

In this notebook, we will consider a more complex dataset than MNIST or CIFAR10. The images in Caltech101 are RGB images (3 channels) with variable size. There are 101 different classes. We will try a very common practice in computer vision nowadays: transfer learning from a pre-trained ImageNet model. 

Roadmap:
- Modify the network from the previous exercise (CIFAR-10) to work with 224x224 images.
- Train the model for a while on Caltech101 and see how far we can get.
- Take a ResNet34 that was pre-trained on ImageNet-1k and fine-tune it to Caltech101.
  - Consider both training only the head (the linear classifier at the end of the network) or the entire network.
  - We should be able to reach better performance than our original network in fewer training steps.
- Optional: play around with other pre-trained models from `timm` (see info [here](https://github.com/rwightman/pytorch-image-models)).'

 
markdown:
## Preliminaries'

 
code:
%matplotlib inline
from typing import List, Optional, Callable, Iterator
import random
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
from torch import nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torchvision import transforms
from sklearn.model_selection import train_test_split

from sklearn.metrics import accuracy_score
from torch.utils.data import DataLoader, Dataset, Subset

sns.set_style(""whitegrid"")

!pip install timm
import timm

def accuracy(target, pred):
    return accuracy_score(target.detach().cpu().numpy(), pred.detach().cpu().numpy())

def show_image(img, title=None):
    img = img.detach().cpu()
    img = img.permute((1, 2, 0)).numpy()
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    img = std * img + mean   # unnormalize
    img = np.clip(img, 0, 1)
    plt.imshow(img)
    plt.gca().tick_params(axis=""both"", which=""both"", bottom=False, left=False, labelbottom=False, labelleft=False)
    if title is not None:
        plt.title(title)'

 
markdown:
### Set up dataset'

 
code:
imagenet_mean = [0.485, 0.456, 0.406]
imagenet_std = [0.229, 0.224, 0.225]
default_imagenet_normalization = transforms.Normalize(mean=imagenet_mean, std=imagenet_std)
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.25, 1)),  # crop of random size and aspect ratio, resize to square
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    default_imagenet_normalization,
])
test_transform = transforms.Compose([
    transforms.Resize(224),  # keep aspect ratio
    transforms.CenterCrop(224),  # square crop
    transforms.ToTensor(),
    default_imagenet_normalization,
])",0.6686028242111206,notebook 5_2,4.0,"return training_set, validation_set, test_set
    

training_set, validation_set, test_set = create_datasets(sequences, Dataset)
', ""print(f'We have {len(training_set)} samples in the training set.')"", ""print(f'We have {len(validation_set)} samples in the validation set.')"", ""print(f'We have {len(test_set)} samples in the test set.')""]'

 
markdown:
When working with more complex data than what we use in this exercise, creating a PyTorch `DataLoader` on top of the dataset can be beneficial. A data loader is basically a fancy generator/iterator that we can use to abstract away all of the data handling and pre-processing + it's super useful for processing batches of data as well! Data loaders will come in handy later when you start to work on your projects, so be sure to check them out!"", '
For more information on how to use datasets and data loaders in PyTorch, [consult the official guide](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html).'

 
markdown:
## Nanograd utilities'

 
markdown:
We load necessary utility functions for the Nanograd library, which we saw in Lab 2.'

 
code:
# Copy and pasted from https://github.com/rasmusbergpalm/nanograd/blob/main/nanograd.py

from math import exp, log, tanh

class Var:
    """"""
    A variable which holds a float and enables gradient computations.
    """"""

    def __init__(self, val: float, grad_fn=lambda: []):
        assert type(val) == float
        self.v = val
        self.grad_fn = grad_fn
        self.grad = 0.0

    def backprop(self, bp):
        self.grad += bp
        for input, grad in self.grad_fn():
            input.backprop(grad * bp)

    def backward(self):
        self.backprop(1.0)
', ""    def __add__(self: 'Var', other: 'Var') -> 'Var':"", '        return Var(self.v + other.v, lambda: [(self, 1.0), (other, 1.0)])
', ""    def __mul__(self: 'Var', other: 'Var') -> 'Var':"", '        return Var(self.v * other.v, lambda: [(self, other.v), (other, self.v)])

    def __pow__(self, power):
        assert type(power) in {float, int}, ""power must be float or int""
        return Var(self.v ** power, lambda: [(self, power * self.v ** (power - 1))])
', ""    def __neg__(self: 'Var') -> 'Var':"", '        return Var(-1.0) * self
', ""    def __sub__(self: 'Var', other: 'Var') -> 'Var':"", '        return self + (-other)
', ""    def __truediv__(self: 'Var', other: 'Var') -> 'Var':"", '        return self * other ** -1",0.6796694993972778,notebook 7_1,2.0,"<img src=""static/autoencoder.png"" />

*The exercises are found at the bottom of the notebook*'

 
markdown:
## MNIST
First let us load the MNIST dataset and plot a few examples. In this notebook we will use the *dataloaders* and *datasets* provided by PyTorch. Defining the loading of datasets using a dataloader has the advantage that it only load the data that is *neccessary* into memory, which enables us to use very large scale datasets.

We only load a limited amount of classes defined by the `classes` variable to speed up training.'

 
code:
import torch
cuda = torch.cuda.is_available()

from torch.utils.data import DataLoader
from torch.utils.data.sampler import SubsetRandomSampler
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor

# Flatten the 2d-array image into a vector
flatten = lambda x: ToTensor()(x).view(28**2)

# Define the train and test sets
dset_train = MNIST(""./"", train=True,  transform=flatten, download=True)
dset_test  = MNIST(""./"", train=False, transform=flatten)

# The digit classes to use
classes = [3, 7]

def stratified_sampler(labels, classes):
    """"""Sampler that only picks datapoints corresponding to the specified classes""""""
    from functools import reduce
    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))
    indices = torch.from_numpy(indices)
    return SubsetRandomSampler(indices)


# The loaders perform the actual work
batch_size = 64
train_loader = DataLoader(dset_train, batch_size=batch_size,
                          sampler=stratified_sampler(dset_train.targets, classes), pin_memory=cuda)
test_loader  = DataLoader(dset_test, batch_size=batch_size, 
                          sampler=stratified_sampler(dset_test.targets, classes), pin_memory=cuda)'

 
code:
# Plot a batch of MNIST examples
f, axarr = plt.subplots(4, 16, figsize=(16, 4))

# Load a batch of images into memory
images, labels = next(iter(train_loader))

for i, ax in enumerate(axarr.flat):
    ax.imshow(images[i].view(28, 28), cmap=""binary_r"")', ""    ax.axis('off')"", '    ', ""plt.suptitle('MNIST handwritten digits')"", 'plt.show()'

 
markdown:
### Building the model
When defining the model the latent layer $z$ must act as a bottleneck of information. We initialize the AE with 1 hidden layer in the encoder and decoder using ReLU units as nonlinearities. The latent layer has a dimensionality of 2 in order to make it easy to visualise. Since $x$ are pixel intensities that are normalized between 0 and 1, we use the sigmoid nonlinearity to model the reconstruction.'

 
code:
import torch.nn as nn

# define size variables
num_features = 28*28",0.7174593210220337,notebook 4_3,1.0,"batch_size = 64  # both for training and testing

# Load dataset (downloaded automatically if missing).', ""dataset = torchvision.datasets.Caltech101(root='./data', download=True)"", '

def translate_label(y, keep_classes):
    try:
        return keep_classes.index(y)
    except ValueError:
        return -1


# Filter images such that no class has more than 100 examples.
# Loop through dataset in random order, include each image (its index) only if there are 
# fewer than 100 images of the same class.
# Here we also remove the classes ""Faces"" and ""Faces_easy"".
skip_classes = [0, 1]   # ""Faces"" and ""Faces_easy""
keep_classes = [c for c in range(len(dataset.categories)) if c not in skip_classes]
indices = list(range(len(dataset)))
random.shuffle(indices)
new_indices = []
current_class_size = {class_number: 0 for class_number in np.unique(dataset.y)}
for i in indices:
    class_number = dataset.y[i]
    if class_number not in skip_classes and current_class_size[class_number] < 100:
        new_indices.append(i)
        current_class_size[class_number] += 1
indices = new_indices

# Compute subset of labels given new indices selection
labels = [translate_label(dataset.y[i], keep_classes) for i in indices]
assert max(labels) == 98

test_size = 640
train_size = len(indices) - test_size
train_idx, test_idx = train_test_split(
    indices,
    train_size=train_size,
    test_size=test_size,
    shuffle=True,
    random_state=42,  # always get the same split
    stratify=labels,
)


class DatasetSubsetWithTransform(Subset):
    
    def __init__(self, dataset, indices, transform=None):
        super().__init__(dataset, indices)
        self.transform = transform
        
    def __getitem__(self, idx):
        x, y = super().__getitem__(idx)
        # Convert PIL image to RGB (some of them are greyscale)', ""        x = x.convert('RGB')"", '        if self.transform is not None:
            x = self.transform(x)
        y = translate_label(y, keep_classes)
        return x, y
    

train_set = DatasetSubsetWithTransform(dataset, train_idx, train_transform)
test_set = DatasetSubsetWithTransform(dataset, test_idx, test_transform)
train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, drop_last=True)
test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, drop_last=False)'

 
markdown:
### A closer look at the dataset

We first plot the size of each class and observe the class distribution is not uniform.

Then we show random examples from the dataset, annotated with the class label and index.
Note that the training images include standard augmentations typically used for vision models (defined above).'",0.7291264533996582,notebook 4_1,2.0,"code:
# Load the MNIST data. 

# Note that we reshape the data from:
#   (nsamples, num_features) = (nsamples, channels * height * width)
# to:
#   (nsamples, channels, height, width)
# in order to retain the spatial arrangements of the pixels.
', ""data = np.load('mnist.npz')"", 'channels, height, width = 1, 28, 28


def get_data(split, size):
    x = data[f""X_{split}""][:size].astype(\'float32\')
    x = x.reshape((-1, channels, height, width))
    targets = data[f""y_{split}""][:size].astype(\'int64\')
    return torch.from_numpy(x), torch.from_numpy(targets)

', ""x_train, targets_train = get_data('train', 50000)"", ""x_valid, targets_valid = get_data('valid', 2000)"", ""x_test, targets_test = get_data('test', 5000)"", '
num_classes = len(np.unique(targets_train))

print(""Information on dataset"")
print(""Shape of x_train:"", x_train.shape)
print(""Shape of targets_train:"", targets_train.shape)
print(""Shape of x_valid:"", x_valid.shape)
print(""Shape of targets_valid:"", targets_valid.shape)
print(""Shape of x_test:"", x_test.shape)
print(""Shape of targets_test:"", targets_test.shape)'

 
code:
# Plot a few MNIST examples
plt.figure(figsize=(7, 7))
plt.imshow(make_grid(x_train[:100], nrow=10).permute(1, 2, 0))', ""plt.axis('off')"", 'plt.show()'

 
markdown:
# Define a simple feed forward neural network'

 
code:
assert (channels, height, width) == x_train.shape[1:]
n_features = channels * height * width


class PrintSize(nn.Module):
    """"""Utility module to print current shape of a Tensor in Sequential, only at the first forward pass.""""""
    
    first = True
    
    def forward(self, x):
        if self.first:
            print(f""Size: {x.size()}"")
            self.first = False
        return x


class Model(nn.Module):

    def __init__(self):
        super(Model, self).__init__()
        activation_fn = nn.ReLU

        self.net = nn.Sequential(
            nn.Flatten(),  # from (1, channels, height, width) to (1, channels * height * width)
            nn.Linear(n_features, 128),
            activation_fn(),
            nn.Linear(128, 128),
            activation_fn(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.net(x)


model = Model()
print(model)

loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)'

 
code:
# Test the forward pass with dummy data
out = model(torch.randn(2, 1, 28, 28))
print(""Output shape:"", out.size())
print(f""Output logits:\{out.detach().numpy()}"")
print(f""Output probabilities:\{out.softmax(1).detach().numpy()}"")'

 
markdown:
# Train network'",0.733959436416626,notebook 7_1,5.0,"Below we provide some starting code for using only a subset of the labelled data.'

 
code:
def uniform_stratified_sampler(labels, classes, n=None):
    """"""
    Stratified sampler that distributes labels uniformly by
    sampling at most n data points per class
    """"""
    from functools import reduce
    # Only choose digits in n_labels
    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))

    # Ensure uniform distribution of labels
    np.random.shuffle(indices)
    indices = np.hstack([list(filter(lambda idx: labels[idx] == i, indices))[:n] for i in classes])

    indices = torch.from_numpy(indices)
    sampler = SubsetRandomSampler(indices)
    return sampler


batch_size = 64

# Specify how many labelled examples we want per digit class
labels_per_class = 10

# Large pool of unlabelled data
unlabelled = DataLoader(dset_train, batch_size=batch_size, 
                        sampler=stratified_sampler(dset_train.train_labels, classes=classes), pin_memory=cuda)

# Smaller pool of labelled data
labelled = DataLoader(dset_train, batch_size=batch_size,
                      sampler=uniform_stratified_sampler(dset_train.train_labels, classes=classes, n=labels_per_class),
                      pin_memory=cuda)'

 
code:
from itertools import cycle

# This is an example of how you can use both the labelled
# and unlabelled loader in unison

### Define your classifier ###

num_epochs = 100
for epoch in range(num_epochs):
    
    # Go through both labelled and unlabelled data
    for (x, y), (u, _) in zip(cycle(labelled), unlabelled):
        
        if cuda:
            x, y, u = x.cuda(), y.cuda(), u.cuda()
        
        # Send labelled data through autoencoder
        outputs = net(x)

        ### Define your loss function ###
        loss = 0
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()'

 
code:
'[]'",0.7423829436302185,notebook 7_2,17.0,"# gather data for the full epoch
    for k, v in training_epoch_data.items():
        training_data[k] += [np.mean(training_epoch_data[k])]

    # Evaluate on a single batch, do not propagate gradients
    with torch.no_grad():
        vae.eval()
        
        # Just load a single batch from the test loader
        x, y = next(iter(test_loader))
        x = x.to(device)
        
        # perform a forward pass through the model and compute the ELBO
        loss, diagnostics, outputs = vi(vae, x)
        
        # gather data for the validation step
        for k, v in diagnostics.items():
            validation_data[k] += [v.mean().item()]
    
    # Reproduce the figure from the begining of the notebook, plot the training curves and show latent samples
    make_vae_plots(vae, x, y, outputs, training_data, validation_data)'

 
markdown:
# Analyzing the VAE

## Mandatory Exercises

### Exercise 1.

1. Implement the class `ReparameterizedDiagonalGaussian` (`log_prob()` and `rsample()`).
2. Import the class `Bernoulli`
3. Implement the class `VariationalInference` (computation of the `elbo` and `beta_elbo`).

### Exercise 2.

**Trainnig and Evaluating a VAE model**

1. Why do we use the reparameterization trick?
2. What available metric can you use to estimate the marginal likelihood ($p_\\theta(\\mathbf{x})$) ?
3. In the above plots, we display numerous model samples. If you had to pick one plot, which one would you pick to evaluate the quality of a VAE (i.e. using posterior samples $\\mathbf{z} \\sim q_\\phi(\\mathbf{z} | \\mathbf{x})$ or prior samples $\\mathbf{z} \\sim p(\\mathbf{z})$) ? Why?.
4. How could you exploit the VAE model for classification?

**Answers**:

`[...]`

### Exercise 3.

**Experiment with the VAE model.**

1. Experiment with the number of layers and activation functions in order to improve the reconstructions and latent representation. What solution did you find the best and why?
2. Try to increase the number of digit classes in the training set and analyze the learning curves, latent space and reconstructions. For which classes and why does the VAE fail in reconstructing?  *HINT: Try the combination: `classes=[0, 1, 4, 9]`, to see how well VAE can separate these digits in the latent representation and reconstructions.*
3. Increase the number of units in the latent layer. Does it increase the models representational power and how can you see and explain this? How does this affect the quality of the reconstructions?

**Answers**:

`[...]`

### Exercise 4. 

**Analyze the purpose of the KL-term and the $\\beta$ parameter.**",0.7456674575805664,notebook 3_4,4.0,"net.eval()
    ### Evaluate training
    train_preds, train_targs = [], []
    for i in range(num_batches_train):
        slce = get_slice(i, batch_size)
        output = net(x_train[slce])
        
        preds = torch.max(output, 1)[1]
        
        train_targs += list(targets_train[slce].numpy())
        train_preds += list(preds.data.numpy())
    
    ### Evaluate validation
    val_preds, val_targs = [], []
    for i in range(num_batches_valid):
        slce = get_slice(i, batch_size)
        
        output = net(x_valid[slce])
        preds = torch.max(output, 1)[1]
        val_targs += list(targets_valid[slce].numpy())
        val_preds += list(preds.data.numpy())
        

    train_acc_cur = accuracy_score(train_targs, train_preds)
    valid_acc_cur = accuracy_score(val_targs, val_preds)
    
    train_acc.append(train_acc_cur)
    valid_acc.append(valid_acc_cur)
    
    if epoch % 10 == 0:
        print(""Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f"" % (
                epoch+1, losses[-1], train_acc_cur, valid_acc_cur))

epoch = np.arange(len(train_acc))
plt.figure()', ""plt.plot(epoch, train_acc, 'r', epoch, valid_acc, 'b')"", ""plt.legend(['Train Accucary','Validation Accuracy'])"", ""plt.xlabel('Updates'), plt.ylabel('Acc')""]'

 
markdown:
# Assignments

Try and add these modifications (might require some Googleing -- an important skill in deep learning):
- Kaiming He initialization instead of Xavier Glorot
- add an extra layer
- use the relu activation function
- add momentum to the optimizer
- use the ADAM optimizer instead of stochastic gradient descent

### Advanced - Regularization

Regularization is VERY important in practice and is used practically every time.
Many important results are completely dependent on clever use of regularization, and it is something you need to become familiar with if you want to work with deep learning.

- add L1 or L2 weight regularization (aka. weight decay) 
- add dropout to the network (**note** the `net.train()` and `net.eval()` are already in the code)
- add batchnorm",0.7464888095855713,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
What are convolutional neural networks?,"The standard ConvNets are organised into layers. Each layer is parameterized by weights and biases. Each layer has an element-wise activation function, and there are no cycles in the connections. In ConvNets, each unit is only connected to a small subset of the input units, which is called the receptive field of the unit. ",notebook 4_1,notebook 4_1,0.0,"markdown:
# Convolutional neural networks 101

Convolution neural networks are one of the most successful types of neural networks for image recognition and an integral part of reigniting the interest in neural networks. They are able to extract structural relations in the data, such as spatial in images or temporal in time series.

In this lab, we will experiment with inserting 2D-convolution layers in the fully connected neural networks introduced previously. We will also try to visualize the learned convolution filters and try to understand what kind of features they learn to recognize.
', ""If you have not watched Jason Yosinski's [video on visualizing convolutional networks](https://www.youtube.com/watch?v=AgkfIQ4IGaM), you definitely should do so now. If you are unfamiliar with the convolution operation, [Vincent Dumoulin](https://github.com/vdumoulin/conv_arithmetic) has a nice visualization of different convolution variants. For a more in-depth tutorial, please see http://cs231n.github.io/convolutional-networks/ or http://neuralnetworksanddeeplearning.com/chap6.html.""]'

 
markdown:
## Reminder: what are convolutional networks?

Standard ConvNets are, in many respects, very similar to the dense feedforward networks we saw previously:
 * The network is still organized into layers.
 * Each layer is parameterized by weights and biases.
 * Each layer has an element-wise non-linear transformation (activation function).
 * There are no cycles in the connections (more on this in later labs).

*So what is the difference?*
The networks we saw previously are called *dense* because each unit receives input from all the units in the previous layer. This is not the case for ConvNets. In ConvNets each unit is only connected to a small subset of the input units. This is called the *receptive field* of the unit.

#### Example
The input (green matrix) is a tensor of size `1x5x5` -- i.e. it has one ""channel"" (like a grayscale image), and the feature map has size `5x5`. Let us define a `1x3x3` kernel (yellow submatrix). The kernel weights are indicated in red at the bottom right of each element. The computation can be thought of as an elementwise multiplication followed by a sum. Here we use a *stride* of 1, as shown in this animation:

<img src=""https://raw.githubusercontent.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/master/4_Convolutional/images/convolutions.gif"" style=""width: 400px;""/>

GIF courtesy of [Stanford](http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution)

After having convolved the image, we perform an elementwise non-linear transformation on the *convolved features*.
In this example, the input is a 2D *feature map* with depth 1.'

 
markdown:
# Assignment 1

### Assignment 1.1: Manual calculations

Perform the following computation, and write the result below.

![](https://raw.githubusercontent.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/master/4_Convolutional/images/conv_exe.png)",0.31052178144454956,CourseOutline.txt,0.0,"The purpose of this course is to give the student a detailed understanding of the deep artificial neural network models, their training, computational frameworks for deployment on fast graphical processing units, their limitations and how to formulate learning in a diverse range of settings. These settings include classification, regression, sequences and other types of structured input and outputs and for reasoning in complex environments.

The course outline is:
1. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part I do it yourself on pen and paper.
2. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part II do it yourself in NumPy.
3. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part III PyTorch.
4. Convolutional neural networks (CNN) + presentation of student projects.
5. Sequence modelling for text data with Transformers.
6. Tricks of the trade and data science with PyTorch + Start of student projects.
7. Variational learning and generative adversarial networks for unsupervised and semi-supervised learning.
8. Reinforcement learning - policy gradient and deep Q-learning.

Starting from week 6 and full time from week 9 and the rest of the term will be spent on tutored project work.",0.4196852147579193,notebook 7_4,5.0,"|-|Autoregressive|Variational Autoencoders|Generative Adversarial Networks|Flows|
|-|--------------|---|---|---|
|Objective|log-likelihood (stable)|doubly stochastic ELBO (stable)|approximate adversarial loss (unstable)|log-likelihood (stable)|
|Latent space|None|dimension collapsing|low dimensional|high-dimensional|
|Architecture|requires ordering, arbitrary data|arbitrary|arbitrary, continuous data|requires partitioning (NVP), continuous data|'

 
code:
'[]'",0.5877604484558105,LearningObjectives.txt,0.0,"Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.

Understand and explain the choices and limitations of a model for a given setting.

Apply and analyze results from deep learning models in exercises and own project work.

Plan, delimit and carry out an applied or methods-oriented project in collaboration with fellow students and project supervisor.

Assess and summarize the project results in relation to aims, methods and available data.

Carry out the project and interpret results by use of computational framework for GPU programming such as PyTorch.

Structure and write a final short technical report including problem formulation, description of methods, experiments, evaluation and conclusion.

Organize and present project results at the final project presentation and in report.

Read, evaluate and give feedback to work of other students.",0.5886116623878479,notebook 5_1,25.0,"**Multi-head attention** The attention mechanism introduced in the previous section depends on a softmax of inner-products, which might be sparse depending on the value of the vectors, in that case, the layer can only attend to a few positions in the sequence. To enable attending to more positions in the input sentence, multiple attention mechanism can be used in parallel. This is what we call a multi-head attention layer:
$$
\\begin{align}
\\mathrm{MultiHeadAttention} \\left(\\mathbf{Q}^{1:P}, \\mathbf{K^{1:P}}, \\mathbf{V}^{1:P}, \\mathbf{M} \\right) = [ \\mathrm{Attention} \\left(\\mathbf{Q}^{1}, \\mathbf{K^{1}}, \\mathbf{V}^{1}, \\mathbf{P} \\right), 
\\ldots
\\mathrm{Attention} \\left(\\mathbf{Q}^{P}, \\mathbf{K^{P}}, \\mathbf{V}^{P}, \\mathbf{M} \\right)] \\ ,
\\end{align}
$$
where each set of vectors $\\mathbf{Q}^{i}, \\mathbf{Q}^{i}, \\mathbf{Q}^{i}$ corresponding to the head index $i$ is obtained using a separate linear transformation of the input sequence.

**Feed-forward** The multi-head attention layer allows looking up multiple positions of the input sequence, but the output is only a linear combination of the value vector $\\mathbf{V}$. A multi-layer neural network (feed-forward layer) is applied **element-wise** to each element of the sequence of hidden states to allow modelling more complex non-linear dependencies.

**Add & Norm** A Transformer is a deep neural network, and therefore might be difficult to optimize. Similarly deep neural networks in the image processing field, Transformer layer rely on two stabilizing components:
1. [Residual connections](https://arxiv.org/abs/1512.03385) allow to bypass the attention layer as well as the feed-forward layer.
2. [Layer normalization](https://arxiv.org/abs/1607.06450): allow enforcing that the output of a Transformer layer has values that are properly distributed

**Implementation:** Here is an implementation for the attention and multi-head attention. You can also check the official [PyTorch implementation](https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#MultiheadAttention).'

 
code:
def attention(query, key, value, mask=None, dropout=None):
    ""Compute \'Scaled Dot Product Attention\'""
    d_k = query.size(-1)
    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)
    if mask is not None:
        scores = scores.masked_fill(mask == 0, -math.inf)
    p_attn = F.softmax(scores, dim = -1)
    if dropout is not None:
        p_attn = dropout(p_attn)
    return torch.matmul(p_attn, value), p_attn'",0.606051504611969,CoursePlan.txt,5.0,"Detailed content

Links to individual video lectures and lecture slides are given below. Here is a link to all 2016 video lectures as a playlist and a Google doc folder with all the lecture slides. More videos have been added over the years. They are all linked below. A very good alternative video resource is Hugo Larochelle’s YouTube playlist.
Week 1 - Feed-forward neural networks - do it yourself pen and paper

    During this week and the following two weeks watch video lectures: 

    Part 0 Overview
    Part 1 Deep learning
    Part 2.1 Feed-forward neural networks
    Part 2.2 Feed-forward neural networks
    Part 3 Error Backpropagation
    Part 4 Optimization

and take notes for at least 3 questions to ask. Link to lecture slides is here.

    During this week and the following two weeks read Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapters 1-3 (stop when reaching the section called Overfitting and regularization) and browse Chapter 4. Note that this is reading material for the first three weeks of the course. Also, in total six exercises of your own choice will be homework later in the course.
    Alternative textbooks: All topics are also covered in the deep learning book that may be read as a supplement. The book can also be bought from the DTU bookstore. You will get 10% discount with this link. Feed-forward neural networks are covered in this chapter. Chapter 1 gives an introduction to deep learning and Part II gives the necessary background on linear algebra, probability, numerical computation and machine learning. Alternative textbook 2: Chris Bishop, Pattern recognition and machine learning. If you need to up your game in mathematics, the book Mathematics for machine learning is an excellent resource and the note Mathematics for Machine Learning offers a concise and compressed collection of the mathematical concepts used in deep learning. These resources are freely available online and are very valuable sources of information.
    Install software on your laptop or go directly to Google CoLab (see above). Installation guide for laptop and cloud may be found here.
    Carry out computer exercises week 1. It is encouraged to work together with other students. Type in everything yourself. Code answers are fine not to differ much within the group and text answers should be in your own words. Note that the computer exercises may experience minor change up to 3 days before the actual session. The hand-in is the notebook with your modifications. It is only allowed to hand in .ipynb files. Each week you should only hand in one file. It is the file with EXE in its name. You hand in on peergrade.io. In order to be able to hand in on peergrade you can use this invitation link https://app.peergrade.io/join/JFFJBF or login into peergrade and use the invitation code JFFJBF. There you will receive information on handing in exercises and deadlines for activities. Some students have previously by accident signed up twice with different emails or forgotten the “student” in their DTU student mail address. If you then submit and check with different email addresses it will look as though you have not handed in.
    Peergrade exercise from three other students through peergrade.io. 

Week 2 - Feed-forward neural networks - do it yourself in NumPy",0.6084434986114502,notebook 4_1,1.0,"Perform the following computation, and write the result below.

![](https://raw.githubusercontent.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/master/4_Convolutional/images/conv_exe.png)

1. Manually convolve the input, and compute the convolved features. No padding and stride of 1.
 * **Answer:**
2. Perform `2x2` max pooling on the convolved features. Stride of 2.
 * **Answer:**

### Assignment 1.2: Output dimensionality

Given the following 3D tensor input `(channel, height, width)`, a given amount (`channels_out`) of filters `(channels_in, filter_height, filter_width)`, stride `(height, width)` and padding `(height, width)`, calculate the output dimensionality if it is valid.

1. input tensor with dimensionality (1, 28, 28) and 16 filters of size (1, 5, 5) with stride (1, 1) and padding (0, 0)
 * **Answer:** 
2. input tensor with dimensionality (2, 32, 32) and 24 filters of size (2, 3, 3) with stride (1, 1) and padding (0, 0)
 * **Answer:** 
3. input tensor with dimensionality (10, 32, 32) and 3 filters of size (10, 2, 2) with stride (2, 2) and padding (0, 0)
 * **Answer:** 
4. input tensor with dimensionality (11, 8, 16) and 7 filters of size (11, 3, 3) with stride (2, 2) and padding (1, 1)
 * **Answer:** 
5. input tensor with dimensionality (128, 256, 256) and 112 filters of size (128, 3, 3) with stride (1, 1) and padding (1, 1)
 * **Answer:** 
 '

 
markdown:
# Load packages'

 
code:
%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import torch
from torch import nn
import torch.nn.functional as F
import torch.optim as optim

from sklearn.metrics import accuracy_score
from torch.utils.data import TensorDataset, DataLoader
from torchvision.utils import make_grid

sns.set_style(""whitegrid"")'

 
markdown:
# Load MNIST data

The code below downloads and loads the same MNIST dataset as before.
Note however that the data has a different shape this time: `(num_samples, num_channels, height, width)`.'

 
code:
# Download the MNIST dataset, if you have not already.
!if [ ! -f mnist.npz ]; then wget -N https://www.dropbox.com/s/qxywaq7nx19z72p/mnist.npz; else echo ""mnist.npz already downloaded""; fi'

 
code:
# Load the MNIST data.",0.6140984296798706,notebook 7_3,1.0,"markdown:
# Adversarial learning

The training process of a GAN can be seen as a two player game involving a discriminator network ($D$) and a generator network($G$). Intuitively, we can describe the role of the two networks as ""police"" and ""forger"", respectively. Given some empirical distribution $p(x)$, the forger wants to fool the police by creating samples that look like they come from $p(x)$. The police will then try to ""analayse each art piece"" to guess whether it is forged or not. This process leads the generator to eventually generate samples that are indistinguishable from the real data.

<img src=""../static_files/GAN.png"" alt=""GAN diagram"" width=""500px""/>

Below we define a deep convolutional generative adversarial network (DCGAN), introduced by [[Radford, 2015]](https://arxiv.org/abs/1511.06434). This means that both the discriminator and generator are deep convolutional networks.'

 
code:
from torch import nn

latent_dim = 100

# The generator takes random `latent` noise and
# turns it into an MNIST image.
generator = nn.Sequential(
    # nn.ConvTranspose2d can be seen as the inverse operation
    # of Conv2d, where after convolution we arrive at an
    # upscaled image.
    nn.ConvTranspose2d(latent_dim, 256, kernel_size=3, stride=2),
    nn.BatchNorm2d(256),
    nn.ReLU(),
    nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2),
    nn.BatchNorm2d(128),
    nn.ReLU(),
    nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),
    nn.BatchNorm2d(64),
    nn.ReLU(),
    nn.ConvTranspose2d(64, 1, kernel_size=2, stride=2),
    nn.Sigmoid() # Image intensities are in [0, 1]
).to(device)

class Flatten(nn.Module):
    def forward(self, x):
        return x.view(x.size(0), -1)

# The discriminator takes an image (real or fake)
# and decides whether it is generated or not.
discriminator = nn.Sequential(
    nn.Conv2d(1, 64, kernel_size=4, stride=2),
    nn.LeakyReLU(0.2),
    nn.Conv2d(64, 128, kernel_size=4, stride=2),
    nn.BatchNorm2d(128),
    nn.LeakyReLU(0.2),
    nn.Conv2d(128, 256, kernel_size=4, stride=2),
    nn.BatchNorm2d(256),
    nn.LeakyReLU(0.2),
    Flatten(),
    nn.Linear(256, 1),
    nn.Sigmoid()
).to(device)

loss = nn.BCELoss()
print(""Using device:"", device)

generator_optim = torch.optim.Adam(generator.parameters(), 2e-4, betas=(0.5, 0.999))
discriminator_optim = torch.optim.Adam(discriminator.parameters(), 2e-4, betas=(0.5, 0.999))'

 
markdown:
## The GAN game",0.6192015409469604,CoursePlan.txt,6.0,"Week 2 - Feed-forward neural networks - do it yourself in NumPy

    See 1. and 2. from Week 1.
    Carry out computer exercises week 2.
    Peergrade exercise from three other students through peergrade.io. 

Week 3 - Feed-forward neural networks in PyTorch

    See 1. and 2. from Week 1.
    Carry out computer exercises week 3.
    Peergrade exercise from three other students through peergrade.io.
    Hand in the notebook marked with EXE on peergrade.io. It should contain your added code in the exercises and the answer of one exercise from Michael Nielsen's book (see point 3. above). The answer to the book exercise should be in a markdown cell at the bottom of the notebook.
    Peergrade exercise from three other students through peergrade.io.  

Week 4 - Convolutional neural networks

    Watch week 2 video lectures  

    Part 1 Introduction to CNNs (PART 1/2)
    Part 1 Introduction to CNNs (PART 2/2)
    Part 2 CNNs the details (PART 1/2)
    Part 2 CNNs the details (PART 2/2)
    2017 CNN update
    2017 Activation functions update
    2017 Image segmentation

and take notes for at least 3 questions to ask. Link to lecture slides is here and here for 2017 updates.

    Reading material Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapter 6 (stop when reaching section called Other approaches to deep neural nets).
    Alternative textbook chapter in the deep learning book.
    One exercise from the book chapters.
    Carry out computer exercises week 4.
    Hand in the notebook marked with EXE on peergrade.io.
    Peergrade exercise from three other students through peergrade.io. You will receive instructions about this from peergrade.io.

Week 5 - Transformers and recurrent neural networks

    Watch week 3 video lectures

    02456week3 1 RNN (PART 1 of 3)
    02456week3 1 RNN (PART 2 of 3)
    02456week3 1 RNN (PART 3 of 3)
    02456week3.2_RNN_training (PART 1 of 3)
    02456week3.2_RNN_training (PART 2 of 3)
    02456week3 2 RNN training (PART 3 of 3)
    02456week3 3 Attention (PART 1 of 2)
    02456week3 3 Attention (PART 2 of 2)
    02456week3 4 Supervised learning recap
    2017 Quasi RNN
    2017 Non-recurrent sequence to sequence models
    2017 Text summarization
    2020 Transformers (PART 1 of 2)
    2020 Transformers (PART 2 of 2)
    2020 Language modelling - GPT-2 and 3
    2020 BERT

and take notes for at least 3 questions to ask. Link to: 2016 lectures, 2017 lecture updates and 2020 lecture updates.",0.6207011938095093,notebook 4_1,4.0,"predictions = output.max(1)[1]

        # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=True).
        test_accuracies.append(accuracy_score(targets, predictions) * len(inputs))

    test_accuracy = np.sum(test_accuracies) / len(x_test)
    print(f""Validation accuracy: {valid_accuracies[-1]:.3f}"")
    print(f""Test accuracy: {test_accuracy:.3f}"")
    
    model.train()'

 
markdown:
### Assignment 2

1. Note the performance of the standard feedforward neural network. Add a [2D convolution layer](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) before the first layer. Insert the utility module `PrintSize` to check the size of the tensor at any point in `Sequential`, and notice that the size of the image reduces after the convolution. This can cause loss of information, and can be avoided by using adequate padding in the convolutional layer.
  Does adding a convolutional layer increase the generalization performance of the network (try num_filters=32 and filter_size=5 as a starting point)?
  
2. Can the performance be increases even further by stacking more convolution layers?

3. We now have a deeper network than the initial simple feedforward network. What happens if we replace all convolutional layers with linear layers? Is this deep feedforward network performing as well as the convolutional one?
 
4. Max-pooling is a technique for decreasing the spatial resolution of an image while retaining the important features. Effectively this gives a local translational invariance and reduces the computation by a factor of four. In the classification algorithm which is usually desirable. You can either: 
 
   - add a maxpool layer (see the PyTorch docs, and try with kernel_size=2 and stride=2) after the convolution layer, or
   - add stride=2 to the arguments of the convolution layer directly.
     
  Verify that this decreases the spatial dimension of the image (insert a `PrintSize` module in the `Sequential`). Does this increase the performance of the network? Note that, to increase performance, you may need to stack multiple layers, increase the number of filters, or tune the learning rate.

5. Dropout is a very useful technique for preventing overfitting. Try to add a DropoutLayer after some of the convolution layers. You may observe a higher validation accuracy but lower train accuracy. Can you explain why this might be the case?
 
6. Batch normalization may help convergence in larger networks as well as generalization performance. Try to insert batch normalization layers into the network.'

 
markdown:
Again, if you didn't already, you really should [watch this video](https://www.youtube.com/watch?v=AgkfIQ4IGaM).""]'",0.6283516883850098,1.0,1.0,1.0,1.0,1.0,1.0,2.0,2.0,2.0,3.0
Can you provide some suggestions to improve the model’s performance?,"Tell us something like increase the depth of the network, modify the convolutional layer parameters(number of filters, filter sizes and strides), pooling layers, batch normalization,  change the learning rate, dropout or weight regularization.",notebook 4_2,notebook 4_3,5.0,"num_trainable_model_parameters = 0
    for p in model.parameters():
        if p.requires_grad:
            num_trainable_model_parameters += p.numel()

    return model, {
        ""num_model_parameters"": num_model_parameters,
        ""num_trainable_model_parameters"": num_trainable_model_parameters,
    }
', ""model, data = initialize_model('resnet34d', num_classes=len(np.unique(labels)), finetune_entire_model=False)"", '
print(model)
print(""Number of model parameters:"", data[""num_model_parameters""])
print(""Number of trainable parameters:"", data[""num_trainable_model_parameters""])
', ""device = torch.device('cuda')  # use cuda or cpu"", 'model = model.to(device)'

 
markdown:
**Assignment 3:** 

1. Train the linear classifier on top of the pre-trained network, and observe how quickly you can get pretty good results, compared to training a smaller network from scratch as above.

2. Go back and change argument to finetune entire network, maybe adjust learning rate, see if you can get better performance than before and if you run into any issues.

3. Optional: experiment with `timm`: try smaller or larger models, including state-of-the-art models, e.g. based on vision transformers (ViT) or MLP-Mixers.

4. Briefly describe what you did and any experiments you did along the way as well as what results you obtained.
Did anything surprise you during the exercise?

5. Write down key lessons/insights you got during this exercise.'

 
code:
'[]'",0.6295806765556335,notebook 4_3,3.0,"code:
num_epochs = 10
validation_every_steps = 50

step = 0
model.train()

train_accuracies = []
valid_accuracies = []
        
for epoch in range(num_epochs):
    
    train_accuracies_batches = []
    
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        
        # Forward pass.
        output = model(inputs)
        
        # Compute loss.
        loss = loss_fn(output, targets)
        
        # Clean up gradients from the model.
        optimizer.zero_grad()
        
        # Compute gradients based on the loss from the current batch (backpropagation).
        loss.backward()
        
        # Take one optimizer step using the gradients computed in the previous step.
        optimizer.step()
        
        step += 1
        
        # Compute accuracy.
        predictions = output.max(1)[1]
        train_accuracies_batches.append(accuracy(targets, predictions))
        
        if step % validation_every_steps == 0:
            
            # Append average training accuracy to list.
            train_accuracies.append(np.mean(train_accuracies_batches))
            
            train_accuracies_batches = []
        
            # Compute accuracies on validation set.
            valid_accuracies_batches = []
            with torch.no_grad():
                model.eval()
                for inputs, targets in test_loader:
                    inputs, targets = inputs.to(device), targets.to(device)
                    output = model(inputs)
                    loss = loss_fn(output, targets)

                    predictions = output.max(1)[1]

                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).
                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))

                model.train()
                
            # Append average validation accuracy to list.
            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))
     
            print(f""Step {step:<5}   training accuracy: {train_accuracies[-1]}"")
            print(f""             test accuracy: {valid_accuracies[-1]}"")

print(""Finished training."")'

 
markdown:
## Test the network on the test data'

 
code:
# Evaluate test set
with torch.no_grad():
    model.eval()
    test_accuracies = []
    for inputs, targets in test_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        output = model(inputs)
        loss = loss_fn(output, targets)

        predictions = output.max(1)[1]

        # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=True).
        test_accuracies.append(accuracy(targets, predictions) * len(inputs))

    test_accuracy = np.sum(test_accuracies) / len(test_set)
    print(f""Test accuracy: {test_accuracy:.3f}"")
    
    model.train()'

 
markdown:
## Using a pre-trained model

Here we will load a ResNet34 that was pre-trained on ImageNet. We then discard the linear classifier at the end of the network (the ""head"" of the network) and replace it with a new one that outputs the desired number of logits for classification. To get a rough idea of the structure of the model, we print it below.",0.6679098606109619,LearningObjectives.txt,0.0,"Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.

Understand and explain the choices and limitations of a model for a given setting.

Apply and analyze results from deep learning models in exercises and own project work.

Plan, delimit and carry out an applied or methods-oriented project in collaboration with fellow students and project supervisor.

Assess and summarize the project results in relation to aims, methods and available data.

Carry out the project and interpret results by use of computational framework for GPU programming such as PyTorch.

Structure and write a final short technical report including problem formulation, description of methods, experiments, evaluation and conclusion.

Organize and present project results at the final project presentation and in report.

Read, evaluate and give feedback to work of other students.",0.668523371219635,notebook 7_4,4.0,"code:
import os

tmp_img = ""tmp_nvp_out.png""
losses = []

x = x.to(device)

for epoch in range(2500):
    z, log_det_J = model(x)
    
    # Loss function
    loss = -torch.mean(base.log_prob(z) + log_det_J)
    
    optimizer.zero_grad()
    loss.backward(retain_graph=True)
    optimizer.step()
    
    losses.append(loss.item())
    
    # -- Plotting --
    if epoch % 50 == 0:
        with torch.no_grad():
            z = base.sample((n_samples,))
            z_hat, _ = model.forward(x)
            x_hat, _ = model.inverse(z)
        
        f, axarr = plt.subplots(1, 3, figsize=(18, 6))

        # Loss
        ax = axarr[0]', ""        ax.set_xlabel('Epoch')"", ""        ax.set_ylabel('Negative log likelihood')"", '        ax.plot(np.arange(epoch+1), losses, color=""black"")

        # Data space
        ax = axarr[1]
        ax.set_title(""Data space"")
        ax.scatter(*x.data.cpu().t(), s=3, c=""k"", label=""True"")
        ax.scatter(*x_hat.data.cpu().t(), s=3, label=""Learned"")
        ax.legend()
        ax.set_xlim([-3, 3]); ax.set_ylim([-3, 3])

        # Latent space
        ax = axarr[2]
        ax.set_title(""Latent space"")
        ax.scatter(*z.data.cpu().t(), s=3, c=""k"", label=""True"")
        ax.scatter(*z_hat.data.cpu().t(), s=3, label=""Learned"")
        ax.legend()
        ax.set_xlim([-3, 3]); ax.set_ylim([-3, 3])

        plt.savefig(tmp_img)
        plt.close(f)
        display(Image(filename=tmp_img))
        clear_output(wait=True)

        os.remove(tmp_img)'

 
markdown:
**Assignment**:
    
Experiment with the model. How many affine layers and total neurons do we need to solve this problem? *Hint: You can use the code block below to calculate this number.*

**Solution**:'

 
code:
print(""Total neurons:"", sum([np.prod(p.shape) for p in model.parameters() if p.requires_grad]))'

 
markdown:
**What is possible with this class of models? To get the answer have a look at [OpenAI's](https://blog.openai.com/glow/) recent blog post on the subject.**"", '
In this week we have now discussed all of the current major directions within generative modelling with the exception of autoregressive models. If you are interested in understanding these, please look into models such as PixelCNN and Wavenet. The following table is originally by Laurent Dinh and is a good place to start when comparing the different approaches to deep generative modelling.",0.675074577331543,notebook 4_2,2.0,"code:
batch_size = 64
num_epochs = 2
validation_every_steps = 500

step = 0
model.train()

train_accuracies = []
valid_accuracies = []
        
for epoch in range(num_epochs):
    
    train_accuracies_batches = []
    
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        
        # Forward pass, compute gradients, perform one training step.
        # Your code here!
        
        # Increment step counter
        step += 1
        
        # Compute accuracy.
        predictions = output.max(1)[1]
        train_accuracies_batches.append(accuracy(targets, predictions))
        
        if step % validation_every_steps == 0:
            
            # Append average training accuracy to list.
            train_accuracies.append(np.mean(train_accuracies_batches))
            
            train_accuracies_batches = []
        
            # Compute accuracies on validation set.
            valid_accuracies_batches = []
            with torch.no_grad():
                model.eval()
                for inputs, targets in test_loader:
                    inputs, targets = inputs.to(device), targets.to(device)
                    output = model(inputs)
                    loss = loss_fn(output, targets)

                    predictions = output.max(1)[1]

                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).
                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))

                model.train()
                
            # Append average validation accuracy to list.
            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))
     
            print(f""Step {step:<5}   training accuracy: {train_accuracies[-1]}"")
            print(f""             test accuracy: {valid_accuracies[-1]}"")

print(""Finished training."")'

 
markdown:
## Test the network

Now we show a batch of test images and generate a table below with the true and predicted class for each of these images.'

 
code:
inputs, targets = next(iter(test_loader))
inputs, targets = inputs.to(device), targets.to(device)
show_image(make_grid(inputs))
plt.show()

outputs = model(inputs)
_, predicted = torch.max(outputs.data, 1)

print(""    TRUE        PREDICTED"")
print(""-----------------------------"")
for target, pred in zip(targets, predicted):
    print(f""{classes[target.item()]:^13} {classes[pred.item()]:^13}"")'

 
markdown:
We now evaluate the network as above, but on the entire test set.'

 
code:
# Evaluate test set
confusion_matrix = np.zeros((n_classes, n_classes))
with torch.no_grad():
    model.eval()
    test_accuracies = []
    for inputs, targets in test_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        output = model(inputs)
        loss = loss_fn(output, targets)

        predictions = output.max(1)[1]

        # Multiply by len(inputs) because the final batch of DataLoader may be smaller (drop_last=True).
        test_accuracies.append(accuracy(targets, predictions) * len(inputs))
        
        confusion_matrix += compute_confusion_matrix(targets, predictions)

    test_accuracy = np.sum(test_accuracies) / len(test_set)
    
    model.train()'",0.682543158531189,notebook 4_3,4.0,"The argument `finetune_entire_model` in `initialize_model()` controls whether the entire pre-trained model is fine-tuned. When this is `False`, only the linear head is trained, and the rest of the model is fixed. The idea is that the features extracted by the ImageNet model, up to the final classification layer, are very informative also on other datasets (see, e.g., [this paper](https://arxiv.org/abs/1910.04867) on the transferability of deep representations in large vision models).

We will start here by training only the linear head. You can experiment different models and variations.

Below, we define the model and forget the one we just trained. After that, you can go back to the section ""Define loss function and optimizer"" and re-execute the notebook from there, to train and evaluate the new model.'

 
code:
def initialize_model(model_name: str, *, num_classes: int, finetune_entire_model: bool = False):
    """"""Returns a pretrained model with a new last layer, and a dict with additional info.

    The dict now contains the number of model parameters, computed as the number of
    trainable parameters as soon as the model is loaded.
    """"""

    print(
        f""Loading model \'{model_name}\', with ""
        f""finetune_entire_model={finetune_entire_model}, changing the ""
        f""last layer to output {num_classes} logits.""
    )
    model = timm.create_model(
        model_name, pretrained=True, num_classes=num_classes
    )

    num_model_parameters = 0
    for p in model.parameters():
        if p.requires_grad:
            num_model_parameters += p.numel()

    if not finetune_entire_model:
        for name, param in model.named_parameters():
            param.requires_grad = False

        # Layer names are not consistent, so we have to consider a few cases. This might 
        # break for arbitrary models from timm (we have not checked all available models).
        layer = None
        if hasattr(model, ""classifier""):
            if isinstance(model.classifier, nn.Linear):
                layer = model.classifier
        elif hasattr(model, ""head""):
            if isinstance(model.head, nn.Linear):
                layer = model.head
            elif hasattr(model.head, ""fc"") and isinstance(model.head.fc, nn.Linear):
                layer = model.head.fc
            elif hasattr(model.head, ""l"") and isinstance(model.head.l, nn.Linear):
                layer = model.head.l
        elif hasattr(model, ""fc""):
            if isinstance(model.fc, nn.Linear):
                layer = model.fc
        if layer is None:
            raise ValueError(f""Couldn\'t automatically find last layer of model."")
        
        # Make the last layer trainable.
        layer.weight.requires_grad_()
        layer.bias.requires_grad_()

    num_trainable_model_parameters = 0
    for p in model.parameters():
        if p.requires_grad:
            num_trainable_model_parameters += p.numel()",0.6841752529144287,notebook 7_4,5.0,"|-|Autoregressive|Variational Autoencoders|Generative Adversarial Networks|Flows|
|-|--------------|---|---|---|
|Objective|log-likelihood (stable)|doubly stochastic ELBO (stable)|approximate adversarial loss (unstable)|log-likelihood (stable)|
|Latent space|None|dimension collapsing|low dimensional|high-dimensional|
|Architecture|requires ordering, arbitrary data|arbitrary|arbitrary, continuous data|requires partitioning (NVP), continuous data|'

 
code:
'[]'",0.691534161567688,notebook 7_2,15.0,"code:
def reduce(x:Tensor) -> Tensor:
    """"""for each datapoint: sum over all dimensions""""""
    return x.view(x.size(0), -1).sum(dim=1)

class VariationalInference(nn.Module):
    def __init__(self, beta:float=1.):
        super().__init__()
        self.beta = beta
        
    def forward(self, model:nn.Module, x:Tensor) -> Tuple[Tensor, Dict]:
        
        # forward pass through the model
        outputs = model(x)
        
        # unpack outputs
        px, pz, qz, z = [outputs[k] for k in [""px"", ""pz"", ""qz"", ""z""]]
        
        # evaluate log probabilities
        log_px = reduce(px.log_prob(x))
        log_pz = reduce(pz.log_prob(z))
        log_qz = reduce(qz.log_prob(z))
        
        # compute the ELBO with and without the beta parameter: 
        # `L^\\beta = E_q [ log p(x|z) ] - \\beta * D_KL(q(z|x) | p(z))`
        # where `D_KL(q(z|x) | p(z)) = log q(z|x) - log p(z)`
        kl = log_qz - log_pz
        elbo = # <- your code here
        beta_elbo = # <- your code here
        
        # loss
        loss = -beta_elbo.mean()
        
        # prepare the output
        with torch.no_grad():', ""            diagnostics = {'elbo': elbo, 'log_px':log_px, 'kl': kl}"", '            
        return loss, diagnostics, outputs
        '

 
code:
vi = VariationalInference(beta=1.0)
loss, diagnostics, outputs = vi(vae, images)
print(f""{\'loss\':6} | mean = {loss:10.3f}, shape: {list(loss.shape)}"")
for key, tensor in diagnostics.items():
    print(f""{key:6} | mean = {tensor.mean():10.3f}, shape: {list(tensor.shape)}"")'

 
markdown:
## Training and Evaluation

### Initialize the model, evaluator and optimizer'

 
code:
from collections import defaultdict
# define the models, evaluator and optimizer

# VAE
latent_features = 2
vae = VariationalAutoencoder(images[0].shape, latent_features)

# Evaluator: Variational Inference
beta = 1
vi = VariationalInference(beta=beta)

# The Adam optimizer works really well with VAEs.
optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)

# define dictionary to store the training curves
training_data = defaultdict(list)
validation_data = defaultdict(list)

epoch = 0'

 
markdown:
### Training Loop

**plotting guide**:",0.6920788288116455,notebook 7_2,9.0,"## 6. Evaluating a Variational Autoencoder

### Assessing the Quality of the Samples

The Variational Autoencoder defines a generative process $\\mathbf{z} \\sim p_{\\theta}(\\mathbf{z}), \\  \\mathbf{x} \\sim p_{\\theta}(\\mathbf{x} | \\mathbf{z})$. A *good* VAE should explain well the data $\\mathbf{x}$ and samples $\\mathbf{x} \\sim p_{\\theta}(\\mathbf{x} |\\mathbf{z}), \\mathbf{z} \\sim p_{\\theta}(\\mathbf{z})$ should be representive of the dataset.

### Estimating the Likelihood

A VAE defines a probabilistic model $p_\\theta(\\mathbf{x} | \\mathbf{z}) p(\\mathbf{z})$ and we are interested in maximizing the ability of the model to explain the dataset $\\mathcal{D} = \\{\\mathbf{x}_i\\}_{i=1, \\dots, N}$, hence we aim at obtaining the maximum probability $\\log p_\\theta(\\mathcal{D}) = \\sum_{i=1}^N \\log p_\\theta(\\mathbf{x}_i) =  \\sum_{i=1}^N \\log \\int_\\mathbf{z} p_\\theta(\\mathbf{x}_i, \\mathbf{z}) d\\mathbf{z} $. However, as discussed previously, the log-likelihood is intractable (marginalization over $\\mathbf{z}$), hence we rely on the Evidence Lower Bound (ELBO) as a proxy, or a tighter bound such as the importance weighted bound (see at the end of the notebook). 

**NB** It is common practice to report the average marginal log likelihood $\\log p_\\theta(\\mathcal{D}) / N$ and not $\\log p_\\theta(\\mathcal{D})$ directly:

$$\\frac{1}{N} \\log p_\\theta(\\mathcal{D}) = \\frac{1}{N} \\sum_i \\log p_\\theta(\\mathbf{x}_i) \\geq \\frac{1}{N} \\sum_i \\operatorname{ELBO}(\\mathbf{x}_i) \\ . $$

### Evaluation on Downstream Tasks

As explained in the previous notebook, there is an interest in learning *compressed* representations $\\mathbf{z}$ of $\\mathbf{x}$ with the intent of solving downstream tasks such as classification. In this scenario, it is important to evaluate the VAE on the final task. For instance, learning a classifier using $\\mathbf{z}$ as features: $p(y | \\mathbf{z})$.'

 
markdown:
# Practice: Building and Training VAEs

## Probabilistic Building Blocks

First, we will implement modules representing probability distributions, which are essential in probabilistic machine learning. Here, we loosely follow the implementation from the `torch.distributions` package which provides modules for most of the commonly used distributions. 

### 1. Gaussian Distribution",0.6955620646476746,notebook 5_2,19.0,"# Define a loss function and optimizer for this problem
# YOUR CODE HERE!
criterion = 
optimizer = 

# Track loss
training_loss, validation_loss = [], []

# For each epoch
for i in range(num_epochs):
    
    # Track loss
    epoch_training_loss = 0
    epoch_validation_loss = 0
    
    net.eval()
        
    # For each sentence in validation set
    for inputs, targets in validation_set:
        
        # One-hot encode input and target sequence
        inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
        targets_idx = [word_to_idx[word] for word in targets]
        
        # Convert input to tensor
        inputs_one_hot = torch.Tensor(inputs_one_hot)
        inputs_one_hot = inputs_one_hot.permute(0, 2, 1)
        
        # Convert target to tensor
        targets_idx = torch.LongTensor(targets_idx)
        
        # Forward pass
        # YOUR CODE HERE!
        outputs = 
        
        # Compute loss
        # YOUR CODE HERE!
        loss = 
        
        # Update loss
        epoch_validation_loss += loss.detach().numpy()
    
    net.train()
    
    # For each sentence in training set
    for inputs, targets in training_set:
        
        # One-hot encode input and target sequence
        inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
        targets_idx = [word_to_idx[word] for word in targets]
        
        # Convert input to tensor
        inputs_one_hot = torch.Tensor(inputs_one_hot)
        inputs_one_hot = inputs_one_hot.permute(0, 2, 1)
        
        # Convert target to tensor
        targets_idx = torch.LongTensor(targets_idx)
        
        # Forward pass
        # YOUR CODE HERE!
        outputs = 
        
        # Compute loss
        # YOUR CODE HERE!
        loss = 
        
        # Backward pass
        # YOUR CODE HERE!
        # zero grad, backward, step...
        
        # Update loss
        epoch_training_loss += loss.detach().numpy()
        
    # Save loss for plot
    training_loss.append(epoch_training_loss/len(training_set))
    validation_loss.append(epoch_validation_loss/len(validation_set))

    # Print loss every 10 epochs
    if i % 10 == 0:', ""        print(f'Epoch {i}, training loss: {training_loss[-1]}, validation loss: {validation_loss[-1]}')"", '
        
# Get first sentence in test set
inputs, targets = test_set[1]

# One-hot encode input and target sequence
inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
targets_idx = [word_to_idx[word] for word in targets]

# Convert input to tensor
inputs_one_hot = torch.Tensor(inputs_one_hot)
inputs_one_hot = inputs_one_hot.permute(0, 2, 1)

# Convert target to tensor
targets_idx = torch.LongTensor(targets_idx)

# Forward pass
outputs = net.forward(inputs_one_hot).data.numpy()
', ""print('\Input sequence:')"", 'print(inputs)
', ""print('\Target sequence:')"", 'print(targets)
', ""print('\Predicted sequence:')"", 'print([idx_to_word[np.argmax(output)] for output in outputs])",0.705211341381073,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,1.0,1.0
What do RNN and LSTM stand for?,RNN stands for Reccurent Neural Network and LSTM stands for Long Short-Term Memory (unit).,notebook 5_1,notebook 5_3,25.0,"Go back and generate a more complex patterned dataset to learn from. Do you see any significant differences between the vanilla RNN and LSTM when you increase the difficulty of the task?'

 
markdown:
# It works, now what?'

 
markdown:
In this notebook you have learned how to use embeddings, recurrent neural networks, and the LSTM cell in particular.
', ""As we have already seen, RNNs are excellent for sequential data such as language. But what do we do if we're modelling data with strong dependency in both directions? Like in many things deep learning, we can build powerful models by stacking layers on top of each other; *bi-directional* RNNs consist of two LSTM cells, one for each direction. A sequence is first fed into the forward LSTM cell and the reversed sequence is then used as input to the backward LSTM cell together with the last hidden state from the forward LSTM cell. Follow [this link](https://pdfs.semanticscholar.org/4b80/89bc9b49f84de43acc2eb8900035f7d492b2.pdf) for the original paper from 1997(!)."", '
For even deeper representations, multiple layers of both uni-directional and bi-directional RNNs can be stacked ontop of each other, just like feed-forward and convolutional layers. For more information on this, check out the [LSTM PyTorch documentation](https://pytorch.org/docs/stable/nn.html#lstm). Next week we will also explore ways to combine RNNs with other types of layers for even more expressive function approximators.'",0.4954652190208435,notebook 5_2,7.0,"markdown:
Great! Now that we have our one-hot encodings in place, we can move on to the RNNs!'

 
markdown:
# Introduction to Recurrent Neural Networks (RNN)

Reading material: [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) and (optionally) [this lecture](https://www.youtube.com/watch?v=iWea12EAu6U&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z).

___

A recurrent neural network (RNN) is a type of neural network that has been succesful in modelling sequential data, e.g. language, speech, protein sequences, etc.

A RNN performs its computations in a cyclic manner, where the same computation is applied to every sample of a given sequence.
The idea is that the network should be able to use the previous computations as some form of memory and apply this to future computations.
An image may best explain how this is to be understood,

![rnn-unroll image](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/static_files/rnn-unfold.png?raw=1)


where it the network contains the following elements:

- $x$ is the input sequence of samples, 
- $U$ is a weight matrix applied to the given input sample,
- $V$ is a weight matrix used for the recurrent computation in order to pass memory along the sequence,
- $W$ is a weight matrix used to compute the output of the every timestep (given that every timestep requires an output),', ""- $h$ is the hidden state (the network's memory) for a given time step, and"", '- $o$ is the resulting output.

When the network is unrolled as shown, it is easier to refer to a timestep, $t$.
We have the following computations through the network:

- $h_t = f(U\\,{x_t} + V\\,{h_{t-1}})$, where $f$ is a non-linear activation function, e.g. $\\mathrm{tanh}$.
- $o_t = W\\,{h_t}$

When we are doing language modelling using a cross-entropy loss, we additionally apply the softmax function to the output $o_{t}$:

- $\\hat{y}_t = \\mathrm{softmax}(o_{t})$


### Backpropagation through time

We define a loss function

- $E = \\sum_t E_t  = \\sum_t E_t(y_t ,\\hat{y}_t ) \\ , $

where $E_t(y_t ,\\hat{y}_t )$ is the cross-entropy function.

Backpropagation through time amounts to computing the gradients of the loss using the same type of clever bookkeeping we applied to the feed-forward network in week 1. This you will do in Exercise D.'

 
markdown:
## Implementing an RNN

We will implement the forward pass, backward pass, optimization and training loop for an RNN in Nanograd so that you can get familiar with the recurrent nature of RNNs. Later, we will go back to PyTorch.'",0.5320344567298889,notebook 5_2,20.0,"# Plot training and validation loss
epoch = np.arange(len(training_loss))
plt.figure()', ""plt.plot(epoch, training_loss, 'r', label='Training loss',)"", ""plt.plot(epoch, validation_loss, 'b', label='Validation loss')"", 'plt.legend()', ""plt.xlabel('Epoch'), plt.ylabel('NLL')"", 'plt.show()'

 
markdown:
# Exercise k) Compare PyTorch and Nanograd implementations

Compare the two implementations (in terms of predictive performance, training speed, etc.). Are they similar? How do they differ?


Try to play around with the choice of hyper-parameters, optimizer, and hidden dimensions. How much can you improve the negative log-likelihood by these simple changes?'

 
markdown:
## Exercise l) Other RNN cells (optional)

Aside from the LSTM cell, various other RNN cells exist. The gated recurrent unit (GRU) is a variation of the LSTM cell that uses less gating mechanisms. Try to look it up in the [PyTorch documentation](https://pytorch.org/docs/stable/nn.html#gru) and switch out the LSTM cell in the code above. What do you notice in terms of performance and convergence speed?'

 
markdown:
## Exercise m) More complex tasks (optional)

Go back and generate a more complex patterned dataset to learn from. Do you see any significant differences between a vanilla RNN and LSTM (implemented in e.g. PyTorch) when you increase the difficulty of the task?'

 
markdown:
# It works, now what?'

 
markdown:
In this notebook you have learned how to use embeddings, recurrent neural networks, and the LSTM cell in particular.
', ""As we have already seen, RNNs are excellent for sequential data such as language. But what do we do if we're modelling data with strong dependency in both directions? Like in many things deep learning, we can build powerful models by stacking layers on top of each other; *bi-directional* RNNs consist of two LSTM cells, one for each direction. A sequence is first fed into the forward LSTM cell and the reversed sequence is then used as input to the backward LSTM cell together with the last hidden state from the forward LSTM cell. Follow [this link](https://pdfs.semanticscholar.org/4b80/89bc9b49f84de43acc2eb8900035f7d492b2.pdf) for the original paper from 1997(!)."", '
For even deeper representations, multiple layers of both uni-directional and bi-directional RNNs can be stacked ontop of each other, just like feed-forward and convolutional layers. For more information on this, check out the [LSTM PyTorch documentation](https://pytorch.org/docs/stable/nn.html#lstm). Next week we will also explore ways to combine RNNs with other types of layers for even more expressive function approximators.'",0.5414207577705383,notebook 5_3,5.0,"___

A recurrent neural network (RNN) is a type of neural network that has been succesful in modelling sequential data, e.g. language, speech, protein sequences, etc.

A RNN performs its computations in a cyclic manner, where the same computation is applied to every sample of a given sequence.
The idea is that the network should be able to use the previous computations as some form of memory and apply this to future computations.
An image may best explain how this is to be understood,

![rnn-unroll image](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/static_files/rnn-unfold.png?raw=1)


where it the network contains the following elements:

- $x$ is the input sequence of samples, 
- $U$ is a weight matrix applied to the given input sample,
- $V$ is a weight matrix used for the recurrent computation in order to pass memory along the sequence,
- $W$ is a weight matrix used to compute the output of the every timestep (given that every timestep requires an output),', ""- $h$ is the hidden state (the network's memory) for a given time step, and"", '- $o$ is the resulting output.

When the network is unrolled as shown, it is easier to refer to a timestep, $t$.
We have the following computations through the network:

- $h_t = f(U\\,{x_t} + V\\,{h_{t-1}})$, where $f$ is a non-linear activation function, e.g. $\\mathrm{tanh}$.
- $o_t = W\\,{h_t}$

When we are doing language modelling using a cross-entropy loss, we additionally apply the softmax function to the output $o_{t}$:

- $\\hat{y}_t = \\mathrm{softmax}(o_{t})$


### Backpropagation through time

We define a loss function

- $E = \\sum_t E_t  = \\sum_t E_t(y_t ,\\hat{y}_t ) \\ , $

where $E_t(y_t ,\\hat{y}_t )$ is the cross-entropy function.

Backpropagation through time amounts to computing the gradients of the loss using the same type of clever bookkeeping we applied to the feed-forward network in week 1. This you will do in Exercise D.'

 
markdown:
## Implementing an RNN'

 
markdown:
We will implement the forward pass, backward pass, optimization and training loop for an RNN in numpy so that you can get familiar with the recurrent nature of RNNs. Later, we will go back to PyTorch and appreciate how convenient the implementation becomes!'

 
markdown:
Let's first define the necessary model parameters. Recall that an $n \\times m$ weight matrix maps $\\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{n}$.""]'

 
code:
hidden_size = 50 # Number of dimensions in the hidden state
vocab_size  = len(word_to_idx) # Size of the vocabulary used",0.5527451038360596,notebook 5_1,10.0,"**Long Short-Term Memory (LSTM) networks** A standard RNN suffers from [the vanishing gradients problem](http://neuralnetworksanddeeplearning.com/chap5.html#the_vanishing_gradient_problem) which gives challenges in saving memory over longer sequences. To combat these issues the gated hidden units were created. The two most prominent gated hidden units are the [Long Short-Term Memory (LSTM, Hochreiter and Schmidhuber. (1997))](https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735) cell and the Gated Recurrent Unit (GRU), both of which have shown increased performance in saving and reusing memory in later timesteps. RNNs coupled with gated mechanisms are less prone to the problem of vanishing gradients, and can therefore model dependencies over longer number of steps.'

 
markdown:
*Figure: bi-directional recurrent neural network. We highlight the information flowing from the context ""My horse is"" to the predicted word ""very"" (left-to-right), and the information flowing from the context ""fast"" (right-to-left).*
![Recurrent Neural Network](images/bidirectional-lm-activated.png)

**Bi-directional recurrent neural networks** Using two RNNs running in reverse direction allows building bidirectional language models. The distribution $p_\\theta(\\mathbf{x}_t \\mid \\mathbf{x}_{-t})$ can be parameterized as
$$
p_\\theta( \\cdot \\mid \\mathbf{x}_{-t}) = \\mathrm{Softmax}((\\mathbf{h}^\\mathrm{forward}_t + \\mathbf{h}^\\mathrm{reverse}_t) F^T) \\ ,
$$
where the hidden state  $\\mathbf{h}^\\mathrm{bi}_t = \\mathbf{h}^\\mathrm{forward}_t + \\mathbf{h}^\\mathrm{reverse}_t$ defines hidden state contextualized on all the tokens but $\\mathbf{w}_t$. 

This is the strategy adopted by [ELMo (""Deep contextualized word representations"", Peters et al. (2018))](https://arxiv.org/abs/1802.05365), which popularized learning deep contextualized representations as a pre-training step, and at the samd time, started a [tradition of naming models after Seame Street characters](https://www.theverge.com/2019/12/11/20993407/ai-language-models-muppets-sesame-street-muppetware-elmo-bert-ernie).'

 
markdown:
**Experiment: train your own LSTM language model**
', ""> **NB:**  *training on CPU is very slow. If you don't have access to a GPU, it will be difficult to train a model that generate acceptable samples. In the end of the notebook, we will use pre-trained models directly, so feel free to skip this experiment.* **You still need to implement the loss in the training loop.**""]'

 
code:
max_dataset_size = 1000 # let's use a small subset for now,"", 'max_seq_size = 10 # and very short sequences",0.5639777779579163,notebook 5_3,0.0,"markdown:
# Week 5 - Recurrent Neural Networks

In this lab, we will introduce different ways of learning from sequential data.

As a recurring example, we will train neural networks to do language modelling, i.e. predict the next token in a sentence. In the context of natural language processing a token could be a character or a word, but mind you that the concepts introduced here apply to all kinds of sequential data, such as e.g. protein sequences, weather measurements, audio signals, or videos, just to name a few.
', ""To really get a grasp of what is going on inside a recurrent neural network (RNN), we will carry out a substantial part of this exercise in NumPy rather than PyTorch. We start off with a simple toy problem, build an RNN using NumPy, train and it, and see for ourselves that it really works. Once we're convinced, we proceed to build and train a Long Short-Term Memory (LSTM) cell, also in NumPy. This is *not* simply to cause you frustration, but rather to provide you with a deeper understanding of the recurrence in RNNs, which will become very beneficial to you in the following weeks. Once you understand the inner workings of an RNN, we will proceed to a PyTorch implementation that you may use for the remainder of the course and in your projects."", '
To summarize, in this notebook we will show you:
* How to represent sequences of categorical variables
* How to build and train an RNN in NumPy
* How to build and train an LSTM network in NumPy
* How to build and train an LSTM network in PyTorch'

 
markdown:
## Representing tokens or text

In previous labs we mainly considered data $x \\in \\mathrm{R}^d$, where $d$ is the feature space dimension.
With time sequences our data can be represented as $x \\in \\mathrm{R}^{t \\, \\times \\, d}$, where $t$ is the sequence length. 
This emphasises sequence dependence and that the samples along the sequence are not independent and identically distributed (i.i.d.).
We will model functions as $\\mathrm{R}^{t \\, \\times \\, d} \\rightarrow \\mathrm{R}^c$, where $c$ is the amount of classes in the output.

There are several ways to represent sequences. With text, the challenge is how to represent a word as a feature vector in $d$ dimensions, as we are required to represent text with decimal numbers in order to apply neural networks to it.

In this exercise we will use a simple one-hot encoding but for categorical variables that can take on many values (e.g. words in the English language) this may be infeasible. For such scenarios, you can project the encodings into a smaller space by use of embeddings. If you want to learn more about tokens, encodings and embeddings than what is covered in this exercise, we highly recommend [this lecture](https://www.youtube.com/watch?v=kEMJRjEdNzM&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z).'

 
markdown:
### One-hot encoding over vocabulary",0.5906652212142944,notebook 5_3,14.0,"markdown:
## Exercise F:

How well does your RNN extrapolate -- does it work as expected? Are there any imperfections? If yes, why could that be?'

 
markdown:
## Exercise G (optional):'

 
markdown:
Alter the forward pass, backward pass and training loop to handle batches of samples. You will see great improvements!'

 
markdown:
# Introduction to the Long Short-Term Memory (LSTM) Cell'

 
markdown:
Reading material: [Christopher Olah's walk-through](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)."", '
___


A vanilla RNN suffers from [the vanishing gradients problem](http://neuralnetworksanddeeplearning.com/chap5.html#the_vanishing_gradient_problem) which gives challenges in saving memory over longer sequences. To combat these issues the gated hidden units were created. The two most prominent gated hidden units are the Long Short-Term Memory (LSTM) cell and the Gated Recurrent Unit (GRU), both of which have shown increased performance in saving and reusing memory in later timesteps. In this exercise, we will focus on LSTM but you would easily be able to go ahead and implement the GRU as well based on the principles that you learn here.

Below is a figure of the LSTM cell:'

 
markdown:
![lstm](https://i.imgur.com/3VkmUCe.png)
Source: https://arxiv.org/abs/1412.7828'

 
markdown:

The LSTM cell contains three gates, input, forget, output gates and a memory cell.
The output of the LSTM unit is computed with the following functions, where $\\sigma = \\mathrm{sigmoid}$.
We have input gate $i$, forget gate $f$, and output gate $o$ defines as

- $i = \\sigma ( W^i [h_{t-1}, x_t])$

- $f = \\sigma ( W^f [h_{t-1},x_t])$

- $o = \\sigma ( W^o [h_{t-1},x_t])$

where $W^i, W^f, W^o$ are weight matrices applied to a concatenated $h_{t-1}$ (hidden state vector) and $x_t$ (input vector)  for each respective gate.

$h_{t-1}$, from the previous time step along with the current input $x_t$ are used to compute the a candidate $g$

- $g = \\mathrm{tanh}( W^g [h_{t-1}, x_t])$
', ""The value of the cell's memory, $c_t$, is updated as"", '
- $c_t = c_{t-1} \\circ f + g \\circ i$

where $c_{t-1}$ is the previous memory, and $\\circ$ refers to element-wise multiplication (hint: element-wise multiplication is computed with the `*` operator in numpy).

The output, $h_t$, is computed as",0.5911611318588257,notebook 5_2,8.0,"We will implement the forward pass, backward pass, optimization and training loop for an RNN in Nanograd so that you can get familiar with the recurrent nature of RNNs. Later, we will go back to PyTorch.'

 
markdown:
We define the Nanograd DenseLayer class from [lab 2](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/2_Feedforward_Python/2.1-EXE-FNN-AutoDif-Nanograd.ipynb) with a few additions:
* the option use_bias to define a layer without bias. This is useful when we define the recurrent layer and
* a method forward_sequence which is useful when a DenseLayer is used as part of a recurrent neural network'

 
code:
from typing import Sequence

class DenseLayer:
    def __init__(self, n_in: int, n_out: int, act_fn, initializer = NormalInitializer(), use_bias=True):
        self.weights = initializer.init_weights(n_in, n_out)
        self.use_bias = use_bias
        if use_bias:
          self.bias = initializer.init_bias(n_out)
        self.act_fn = act_fn
    
    def __repr__(self):    ', ""        return 'Weights: ' + repr(self.weights) + (' Biases: ' + repr(self.bias) if self.use_bias else '')"", '
    def parameters(self) -> Sequence[Var]:
      params = []
      for r in self.weights:
        params += r

      if self.use_bias:
        params += self.bias

      return params

    def forward(self, input: Sequence[Var]) -> Sequence[Var]:
        # self.weights is a matrix with dimension n_in x n_out. We check that the dimensionality of the input 
        # to the current layer matches the number of nodes in the current layer
        assert len(self.weights) == len(input), ""weights and input must match in first dimension""
        weights = self.weights
        out = []
        # For some given data point single_input, we now want to calculate the resulting value in each node in the current layer
        # We therefore loop over the (number of) nodes in the current layer:
        for j in range(len(weights[0])): 
            # Initialize the node value depending on its corresponding parameters.
            node = self.bias[j] if self.use_bias else Var(0.0)
            # We now finish the linear transformation corresponding to the parameters of the currently considered node.
            for i in range(len(input)):
                node += input[i]*weights[i][j]
            node = self.act_fn(node)
            out.append(node)

        return out
    
    def forward_sequence(self, input: Sequence[Sequence[Var]]) -> Sequence[Sequence[Var]]:
        out = []
        for i in range(len(input)): 
            node = self.forward(input[i])
            out.append(node)

        return out'

 
markdown:
## Exercise b) The RNNLayer class

Complete the RNNLayer class below.

Explain how we reuse the DenseLayer class.

Explain what the forward and the forward_sequence method do.'

 
code:
from typing import Sequence",0.6188123226165771,notebook 5_1,11.0,"code:
max_dataset_size = 1000 # let's use a small subset for now,"", 'max_seq_size = 10 # and very short sequences

# load and tokenizer the dataset
def batch_tokenize(batch: List[Dict[str, Any]], max_length=max_seq_size, tokenizer: tokenizers.Tokenizer = None, key:str=""text"") -> torch.Tensor:
    texts = batch[key]
    encodings = tokenizer.encode_batch(texts)
    return {""token_ids"": [x.ids[:max_length] for x in encodings]}

# load AG News, take a subset of `max_dataset_size` rows and tokenize
dataset = datasets.load_dataset(""ag_news"")
dataset = datasets.DatasetDict({split: dset.select(range(max_dataset_size)) if len(dset) > max_dataset_size else dset for split, dset in dataset.items()})
dataset = dataset.map(partial(batch_tokenize, tokenizer=glove_tokenizer), batched=True, num_proc=2, batch_size=10)
rich.print(dataset)'

 
code:
class RNNLM(torch.nn.Module):
    """"""A simple implementation of a language model using RNNs.""""""
    def __init__(self, vectors:torch.Tensor):
        super().__init__()
        # register the embeddings
        self.embeddings = torch.nn.Embedding(*glove_vectors.shape)
        self.embeddings.weight.data = glove_vectors

        # register the LSTM
        self.rnn = torch.nn.LSTM(
            input_size=glove_vectors.shape[1],
            hidden_size=glove_vectors.shape[1],
            num_layers=1,
            batch_first=True,
        )

        # project the output of the LSTM (hidden state) back to the vocabulary space
        self.proj = nn.Linear(glove_vectors.shape[1], glove_vectors.shape[0], bias=False)
        # init the projection using the embeddings weights
        self.proj.weight.data = glove_vectors

    def forward(self, token_ids: torch.Tensor, retain_ws:bool=False) -> torch.Tensor:
        # convert the tokens into vectors
        ws = self.embeddings(token_ids)

        # store the word vectors for debugging
        if retain_ws:
          ws.retain_grad()
          self.ws = ws

        # shift the input `ws` right
        w0 = torch.zeros((ws.shape[0], 1, self.embeddings.weight.shape[1]),
                         device=self.embeddings.weight.device, dtype=torch.long)
        ws_shifted = torch.cat([w0, ws[:, :-1]], dim=1)

        # call the RNN: w_{-1:T-1} -> h{1:T}
        hidden_states, _ = self.rnn(ws_shifted)

        # project the hidden state to the vocabulary space
        logits = self.proj(hidden_states)
        return logits",0.6406675577163696,notebook 5_2,0.0,"markdown:
# Week 5 - Recurrent Neural Networks

In this lab, we will introduce different ways of learning from sequential data.

As a recurring example, we will train neural networks to do language modelling, i.e. predict the next token in a sentence. In the context of natural language processing a token could be a character or a word, but mind you that the concepts introduced here apply to all kinds of sequential data, such as e.g. protein sequences, weather measurements, audio signals, or videos, just to name a few.

To really get a grasp of what is going on inside a recurrent neural network (RNN), we will carry out a substantial part of this exercise in Nanograd rather than PyTorch. 
', ""We start off with a simple toy problem, build an RNN using Nanograd, train it, and see for ourselves that it really works. Once we're convinced, you will implement the Long Short-Term Memory (LSTM) cell, also in Nanograd. "", '
This is *not* simple but with the DenseLayer class we already have, it is doable. Having done it yourself will help you understand what happens under the hood of the PyTorch code we will use throughout the course.

To summarize, in this notebook we will show you:
* How to represent sequences of categorical variables
* How to build and train an RNN in Nanograd
* How to build and train an LSTM network in Nanograd
* How to build and train an LSTM network in PyTorch


[Numpy version of the Notebook (previous version)](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/5_Recurrent/OLD-5.1-Numpy-Recurrent-Neural-Networks.ipynb)'

 
markdown:
## Representing tokens or text

In previous labs we mainly considered data $x \\in \\mathbb{R}^d$, where $d$ is the feature space dimension.
With time sequences our data can be represented as $x \\in \\mathbb{R}^{t \\, \\times \\, d}$, where $t$ is the sequence length. 
This emphasises sequence dependence and that the samples along the sequence are not independent and identically distributed (i.i.d.).

With RNNs, we can model both many-to-one functions: $\\mathbb{R}^{t \\, \\times \\, d} \\rightarrow \\mathbb{R}^c$ and many-to-many functions: $\\mathbb{R}^{t \\, \\times \\, d} \\rightarrow \\mathbb{R}^{t \\, \\times \\, c}$, where $c$ is the amount of classes/output dimensions.

There are several ways to represent sequences. With text, the challenge is how to represent a word as a feature vector in $d$ dimensions, as we are required to represent text with decimal numbers in order to apply neural networks to it.",0.6440799832344055,0.0,0.0,0.0,0.0,1.0,1.0,1.0,1.0,2.0,2.0
How can I give text as input to my network?,"Before text can be used as input for a neural network, it needs to be represented as a vector. This can be done by tokenizing the text, and then looking up the embedding vector for each token. Tokenization transforms characters, words, or parts of words into tokens, which can be numbers.",notebook 5_1,notebook 5_2,14.0,"code:
def freestyle(NN, sentence='', num_generate=10):"", '    """"""
    Takes in a sentence as a string and outputs a sequence
    based on the predictions of the RNN.
    
    Args:
     `params`: the parameters of the network
     `sentence`: string with whitespace-separated tokens
     `num_generate`: the number of tokens to generate
    """"""', ""    sentence = sentence.split(' ')"", '    output_sentence = sentence
    sentence_one_hot = one_hot_encode_sequence(sentence, vocab_size)

    # Begin predicting
    outputs = forward_batch([sentence_one_hot], NN, use_stored_hid=False)
    output_words = [idx_to_word[np.argmax(output)] for output in Var_to_nparray(outputs[0])]
    word = output_words[-1]

    # Append first prediction
    output_sentence.append(word)

    # Forward pass - Insert code here!', ""    if word != 'EOS':"", '      for i in range(num_generate-1):
          sentence_one_hot = 
          outputs = 
          output_words = 
          word = 
          output_sentence.append(word)', ""          if word == 'EOS':"", '              break
          
    return output_sentence


# Perform freestyle (extrapolation)', ""test_examples = ['a a b
a a a a b
a a a a a a b
a
r n n']"", 'for i, test_example in enumerate(test_examples):', ""    print(f'Example {i}:', test_example)"", ""    print('Predicted sequence:', freestyle(NN, sentence=test_example), end='\\')""]'

 
markdown:
# Introduction to the Long Short-Term Memory (LSTM) Cell
', ""Reading material: [Christopher Olah's walk-through](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)."", '
___


A vanilla RNN suffers from [the vanishing gradients problem](http://neuralnetworksanddeeplearning.com/chap5.html#the_vanishing_gradient_problem) which gives challenges in saving memory over longer sequences. To combat these issues the gated hidden units were created. The two most prominent gated hidden units are the Long Short-Term Memory (LSTM) cell and the Gated Recurrent Unit (GRU), both of which have shown increased performance in saving and reusing memory in later timesteps. In this exercise, we will focus on LSTM but you would easily be able to go ahead and implement the GRU as well based on the principles that you learn here.

Below is a figure of the LSTM cell:'

 
markdown:
![lstm](https://i.imgur.com/3VkmUCe.png)
Source: https://arxiv.org/abs/1412.7828'

 
markdown:

The LSTM cell contains three gates, input, forget, output gates and a memory cell.
The output of the LSTM unit is computed with the following functions, where $\\sigma = \\mathrm{sigmoid}$.
We have input gate $i$, forget gate $f$, and output gate $o$ defines as

- $i = \\sigma ( W^i [h_{t-1}, x_t])$

- $f = \\sigma ( W^f [h_{t-1},x_t])$",0.7381507754325867,notebook 5_3,23.0,"markdown:
### Training loop'

 
markdown:
It's time for us to train our network. In the section below, you will get to put your deep learning skills to use and create your own training loop. You may want to consult previous exercises if you cannot recall how to define the training loop.""]'

 
code:
# Hyper-parameters
num_epochs = 200

# Initialize a new network
net = MyRecurrentNet()

# Define a loss function and optimizer for this problem
# YOUR CODE HERE!
criterion = 
optimizer = 

# Track loss
training_loss, validation_loss = [], []

# For each epoch
for i in range(num_epochs):
    
    # Track loss
    epoch_training_loss = 0
    epoch_validation_loss = 0
    
    net.eval()
        
    # For each sentence in validation set
    for inputs, targets in validation_set:
        
        # One-hot encode input and target sequence
        inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
        targets_idx = [word_to_idx[word] for word in targets]
        
        # Convert input to tensor
        inputs_one_hot = torch.Tensor(inputs_one_hot)
        inputs_one_hot = inputs_one_hot.permute(0, 2, 1)
        
        # Convert target to tensor
        targets_idx = torch.LongTensor(targets_idx)
        
        # Forward pass
        # YOUR CODE HERE!
        outputs = 
        
        # Compute loss
        # YOUR CODE HERE!
        loss = 
        
        # Update loss
        epoch_validation_loss += loss.detach().numpy()
    
    net.train()
    
    # For each sentence in training set
    for inputs, targets in training_set:
        
        # One-hot encode input and target sequence
        inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
        targets_idx = [word_to_idx[word] for word in targets]
        
        # Convert input to tensor
        inputs_one_hot = torch.Tensor(inputs_one_hot)
        inputs_one_hot = inputs_one_hot.permute(0, 2, 1)
        
        # Convert target to tensor
        targets_idx = torch.LongTensor(targets_idx)
        
        # Forward pass
        # YOUR CODE HERE!
        outputs = 
        
        # Compute loss
        # YOUR CODE HERE!
        loss = 
        
        # Backward pass
        # YOUR CODE HERE!
        # zero grad, backward, step...
        
        # Update loss
        epoch_training_loss += loss.detach().numpy()
        
    # Save loss for plot
    training_loss.append(epoch_training_loss/len(training_set))
    validation_loss.append(epoch_validation_loss/len(validation_set))

    # Print loss every 10 epochs
    if i % 10 == 0:', ""        print(f'Epoch {i}, training loss: {training_loss[-1]}, validation loss: {validation_loss[-1]}')"", '
        
# Get first sentence in test set
inputs, targets = test_set[1]

# One-hot encode input and target sequence
inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
targets_idx = [word_to_idx[word] for word in targets]

# Convert input to tensor
inputs_one_hot = torch.Tensor(inputs_one_hot)
inputs_one_hot = inputs_one_hot.permute(0, 2, 1)",0.7729473114013672,notebook 5_3,8.0,"markdown:
### Implement the forward pass'

 
markdown:
Now that we have all the definitions in place, we can start to implement a forward pass.'

 
code:
def forward_pass(inputs, hidden_state, params):
    """"""
    Computes the forward pass of a vanilla RNN.
    
    Args:
     `inputs`: sequence of inputs to be processed
     `hidden_state`: an already initialized hidden state
     `params`: the parameters of the RNN
    """"""
    # First we unpack our parameters
    U, V, W, b_hidden, b_out = params
    
    # Create a list to store outputs and hidden states
    outputs, hidden_states = [], []
    
    # For each element in input sequence
    for t in range(len(inputs)):

        # Compute new hidden state
        # YOUR CODE HERE!
        hidden_state = 

        # Compute output
        # YOUR CODE HERE!
        out = 
        
        # Save results and continue
        outputs.append(out)
        hidden_states.append(hidden_state.copy())
    
    return outputs, hidden_states


# Get first sequence in training set
test_input_sequence, test_target_sequence = training_set[0]

# One-hot encode input and target sequence
test_input = one_hot_encode_sequence(test_input_sequence, vocab_size)
test_target = one_hot_encode_sequence(test_target_sequence, vocab_size)

# Initialize hidden state as zeros
hidden_state = np.zeros((hidden_size, 1))
', ""# Now let's try out our new function"", 'outputs, hidden_states = forward_pass(test_input, hidden_state, params)
', ""print('Input sequence:')"", 'print(test_input_sequence)
', ""print('\Target sequence:')"", 'print(test_target_sequence)
', ""print('\Predicted sequence:')"", 'print([idx_to_word[np.argmax(output)] for output in outputs])'

 
markdown:
## Exercise C:'

 
markdown:
Implement the forward pass in the code above. Use $\\tanh{x}$ as the non-linear activation function $f$. You can use `np.dot()` to compute dot products. Refer to the equations and the figure if you're in doubt.""]'

 
markdown:
## Backward pass'

 
markdown:
It's now time to implement the backward pass. This can be a bit tricky so it may be helpful to take another look at the RNN equations, figure and your forward pass implementation. Note that (depending on your implementation) you may sometimes need to transpose using `np.transpose()` or simply `.T`.""]'

 
markdown:
## Exercise D:'

 
markdown:
Implement the missing code in the backward pass code given below using a cross-entropy loss and $\\tanh{x}$ as non-linear activation function $f$.

To complete the implementation, we need to compute the partial derivatives
$
\\frac{\\partial E}{\\partial W},~\\frac{\\partial E}{\\partial U},~\\frac{\\partial E}{\\partial V}
$. 
We repeat the definition of the RNN forward pass from above:",0.7830948233604431,notebook 5_2,16.0,"def forward_step(self, input: Sequence[Var], input_hid: Sequence[Var], input_c: Sequence[Var]) -> Sequence[Var]:
        hids = []
        cs = []
        concatenated_input = []
        for val in input_hid:
          concatenated_input.append(val)
        for val in input:
          concatenated_input.append(val)

        # Insert code here

        return hids, cs
    
    def forward_sequence(self, input: Sequence[Sequence[Var]], use_stored_hid = False) -> Sequence[Sequence[Var]]:
        out = []
        if use_stored_hid:
            hid = self.stored_hid
            c = self.stored_c
        else:
            hid = self.initial_hid
            c = self.initial_c
        # Takes a sequence and loops over each character in the sequence. Note that each character has dimenson equal to the embeddng dimenson
        for i in range(len(input)):
            hid, c = # insert code here
            out.append(hid)
        self.stored_hid = hid
        self.stored_c = c
        return out'

 
markdown:
Here is a bit of code to test it out:'

 
code:
NN = [
    LSTMLayer(1, 5, lambda x: x.tanh()),
    DenseLayer(5, 1, lambda x: x.identity())
]

print(NN[0])
x_train =[[[Var(1.0)], [Var(2.0)], [Var(3.0)]],
          [[Var(1.0)], [Var(2.0)], [Var(3.0)]]]

output_train = forward_batch(x_train, NN)          
output_train[0][0][0].backward()

print(output_train)'

 
markdown:
## Exercise i) LSTM training

Complete the LSTM training loop

Run the training loop. Training time in Nanograd will likely be long, but see if you can find settings to compare your LSTM learning curve (NLL and number of epochs) to the vanilla RNN from earlier. Do you observe any improvements? Motivate your answer.

Finally, below we will implement LSTM in PyTorch. You will notice it is much, much faster!'

 
code:
# Initialize training hyperparameters
EPOCHS = 
LR = 
LR_DECAY = '

 
code:
NN = [
    LSTMLayer(4, 1, lambda x: x.tanh()),
    DenseLayer(1, 4, lambda x: x.identity())
]

train_loss = []
val_loss = []

batch_size = 8

for e in range(EPOCHS):
    for b in range(int(np.ceil(len(encoded_training_set_x)/batch_size))):
        # Forward pass and loss computation
        Loss =
        # Backward pass
        Loss.backward()
        
        # gradient descent update
        update_parameters(parameters(NN), LR)
        zero_gradients(parameters(NN))
      
    LR = LR * LR_DECAY",0.7956113815307617,notebook 4_2,1.0,"print(""\Test data"")
print(""Number of points:"", len(test_set))
x, y = next(iter(test_loader))
print(""Batch dimension (B x C x H x W):"", x.shape)
print(f""Number of distinct labels: {len(set(test_set.targets))} (unique labels: {set(test_set.targets)})"")

n_classes = len(set(test_set.targets))'

 
markdown:
### Show example images

Run multiple times to see different examples.'

 
code:
# Get random training images and show them.
images, labels = next(iter(train_loader))
show_image(torchvision.utils.make_grid(images))'

 
markdown:
## Define a convolutional neural network


**Assignment 1:** Define a convolutional neural network. 
You may use the code from previous notebooks.
We suggest that you start with a small network, and make sure that everything is working.
Once you can train successfully, come back and improve the architecture.'

 
code:
class PrintSize(nn.Module):
    """"""Utility module to print current shape of a Tensor in Sequential, only at the first pass.""""""
    
    first = True
    
    def forward(self, x):
        if self.first:
            print(f""Size: {x.size()}"")
            self.first = False
        return x


class Model(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.num_classes = num_classes
        # Your code here!

    def forward(self, x):
        # Your code here!
        return x


model = Model(n_classes)', ""device = torch.device('cpu')  # use cuda or cpu"", 'model.to(device)
print(model)'

 
markdown:
## Define a loss function and optimizer

**Assignment 2:** Define the loss function and optimizer.
You might need to experiment a bit with the learning rate.'

 
code:
loss_fn = None  # Your code here!
optimizer = None  # Your code here!'

 
markdown:
## Train the network

**Assignment 3:** Finish the training loop below. 
Start by using a small number of epochs (e.g. 2).
Even with a low number of epochs you should be able to see results that are better than chance.
When everything is working increase the number of epochs to find out how good your network really is.'

 
code:
# Test the forward pass with dummy data
out = model(torch.randn(2, 3, 32, 32, device=device))
print(""Output shape:"", out.size())
print(f""Output logits:\{out.detach().cpu().numpy()}"")
print(f""Output probabilities:\{out.softmax(1).detach().cpu().numpy()}"")'

 
code:
batch_size = 64
num_epochs = 2
validation_every_steps = 500

step = 0
model.train()",0.7999306917190552,notebook 8_4_Q,1.0,"def forward(self, x):
        return self.out(x)
    
    def loss(self, q_outputs, q_targets):
        return torch.sum(torch.pow(q_targets - q_outputs, 2))'

 
code:
def one_hot(i, l):
    """"""One-hot encoder for the states""""""
    a = np.zeros((len(i), l))
    a[range(len(i)), i] = 1
    return a'

 
code:
# train Q-network

num_episodes = 1000
episode_limit = 100
learning_rate = 0.1
gamma = 0.99 # discount rate
val_freq = 100 # validation frequency
epsilon_start = 1.0

n_inputs = env.observation_space.n
n_outputs = env.action_space.n

qnet = QNetwork(n_inputs, n_outputs, learning_rate)

try:
    epsilon = epsilon_start
    rewards, lengths, losses, epsilons = [], [], [], []', ""    print('start training')"", '    for i in range(num_episodes):
        # init new episode
        s, ep_reward, ep_loss = env.reset(), 0, 0
        for j in range(episode_limit):
            # 1. do foward pass of current state to compute Q-values for all actions
            qnet.optimizer.zero_grad()
            Q = qnet(torch.from_numpy(one_hot([s], n_inputs)).float())
            # 2. select action with epsilon-greedy strategy
            a = Q.argmax().item() if np.random.rand() > epsilon else env.action_space.sample()
            s1, r, done, _ = env.step(a)
            # 3. do forward pass for the next state
            with torch.no_grad():
                Q1 = qnet(torch.from_numpy(one_hot([s1], n_inputs)).float())
            # 4. set Q-target
            q_target = Q.clone()
            q_target[0, a] = r + gamma * Q1.max().item() * (not done)
            # 5. update network weights
            loss = qnet.loss(Q, q_target)
            loss.backward()
            qnet.optimizer.step()
            # 6. bookkeeping
            s = s1
            ep_reward += r
            ep_loss += loss.item()
            if done: break
        # bookkeeping
        epsilon *= num_episodes/(i/(num_episodes/20)+num_episodes) # decrease epsilon
        epsilons.append(epsilon); rewards.append(ep_reward); lengths.append(j+1); losses.append(ep_loss)', ""        if (i+1) % val_freq == 0: print('{:5d} mean training reward: {:5.2f}'.format(i+1, np.mean(rewards[-val_freq:])))"", ""    print('done')"", 'except KeyboardInterrupt:', ""    print('interrupt')""]'

 
code:
# plot results

def moving_average(a, n=10) :
    ret = np.cumsum(a, dtype=float)
    ret[n:] = ret[n:] - ret[:-n]
    return ret / n",0.8092914819717407,notebook 5_3,18.0,"# First we unpack our parameters
    W_f, W_i, W_g, W_o, W_v, b_f, b_i, b_g, b_o, b_v = p
    
    # Save a list of computations for each of the components in the LSTM
    x_s, z_s, f_s, i_s,  = [], [] ,[], []
    g_s, C_s, o_s, h_s = [], [] ,[], []
    v_s, output_s =  [], [] 
    
    # Append the initial cell and hidden state to their respective lists
    h_s.append(h_prev)
    C_s.append(C_prev)
    
    for x in inputs:
        
        # Concatenate input and hidden state
        z = np.row_stack((h_prev, x))
        z_s.append(z)
        
        # Calculate forget gate
        # YOUR CODE HERE!
        f = 
        f_s.append(f)
        
        # Calculate input gate
        # YOUR CODE HERE!
        i = 
        i_s.append(i)
        
        # Calculate candidate
        g = tanh(np.dot(W_g, z) + b_g)
        g_s.append(g)
        
        # Calculate memory state
        # YOUR CODE HERE!
        C_prev = 
        C_s.append(C_prev)
        
        # Calculate output gate
        # YOUR CODE HERE!
        o = 
        o_s.append(o)
        
        # Calculate hidden state
        h_prev = o * tanh(C_prev)
        h_s.append(h_prev)

        # Calculate logits
        v = np.dot(W_v, h_prev) + b_v
        v_s.append(v)
        
        # Calculate softmax
        output = softmax(v)
        output_s.append(output)

    return z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, output_s


# Get first sentence in test set
inputs, targets = test_set[1]

# One-hot encode input and target sequence
inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
targets_one_hot = one_hot_encode_sequence(targets, vocab_size)

# Initialize hidden state as zeros
h = np.zeros((hidden_size, 1))
c = np.zeros((hidden_size, 1))

# Forward pass
z_s, f_s, i_s, g_s, C_s, o_s, h_s, v_s, outputs = forward(inputs_one_hot, h, c, params)

output_sentence = [idx_to_word[np.argmax(output)] for output in outputs]', ""print('Input sentence:')"", 'print(inputs)
', ""print('\Target sequence:')"", 'print(targets)
', ""print('\Predicted sequence:')"", 'print([idx_to_word[np.argmax(output)] for output in outputs])'

 
markdown:
## Exercise I:'

 
markdown:
Complete the implementation of the LSTM forward pass above. Refer to the equations and figures further up if you're in doubt.""]'

 
markdown:
## Backward pass'

 
markdown:
Similar to the RNN in numpy we also need to specify a backward pass. Fortunately, we have already done the work for you here :-)

Feel free to dive into the code to get a better intuition of what is going on -- otherwise you can jump straight to the training loop.'",0.8118568658828735,notebook 4_1,2.0,"code:
# Load the MNIST data. 

# Note that we reshape the data from:
#   (nsamples, num_features) = (nsamples, channels * height * width)
# to:
#   (nsamples, channels, height, width)
# in order to retain the spatial arrangements of the pixels.
', ""data = np.load('mnist.npz')"", 'channels, height, width = 1, 28, 28


def get_data(split, size):
    x = data[f""X_{split}""][:size].astype(\'float32\')
    x = x.reshape((-1, channels, height, width))
    targets = data[f""y_{split}""][:size].astype(\'int64\')
    return torch.from_numpy(x), torch.from_numpy(targets)

', ""x_train, targets_train = get_data('train', 50000)"", ""x_valid, targets_valid = get_data('valid', 2000)"", ""x_test, targets_test = get_data('test', 5000)"", '
num_classes = len(np.unique(targets_train))

print(""Information on dataset"")
print(""Shape of x_train:"", x_train.shape)
print(""Shape of targets_train:"", targets_train.shape)
print(""Shape of x_valid:"", x_valid.shape)
print(""Shape of targets_valid:"", targets_valid.shape)
print(""Shape of x_test:"", x_test.shape)
print(""Shape of targets_test:"", targets_test.shape)'

 
code:
# Plot a few MNIST examples
plt.figure(figsize=(7, 7))
plt.imshow(make_grid(x_train[:100], nrow=10).permute(1, 2, 0))', ""plt.axis('off')"", 'plt.show()'

 
markdown:
# Define a simple feed forward neural network'

 
code:
assert (channels, height, width) == x_train.shape[1:]
n_features = channels * height * width


class PrintSize(nn.Module):
    """"""Utility module to print current shape of a Tensor in Sequential, only at the first forward pass.""""""
    
    first = True
    
    def forward(self, x):
        if self.first:
            print(f""Size: {x.size()}"")
            self.first = False
        return x


class Model(nn.Module):

    def __init__(self):
        super(Model, self).__init__()
        activation_fn = nn.ReLU

        self.net = nn.Sequential(
            nn.Flatten(),  # from (1, channels, height, width) to (1, channels * height * width)
            nn.Linear(n_features, 128),
            activation_fn(),
            nn.Linear(128, 128),
            activation_fn(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.net(x)


model = Model()
print(model)

loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)'

 
code:
# Test the forward pass with dummy data
out = model(torch.randn(2, 1, 28, 28))
print(""Output shape:"", out.size())
print(f""Output logits:\{out.detach().numpy()}"")
print(f""Output probabilities:\{out.softmax(1).detach().numpy()}"")'

 
markdown:
# Train network'",0.8136121034622192,notebook 5_3,13.0,"# Plot training and validation loss
epoch = np.arange(len(training_loss))
plt.figure()', ""plt.plot(epoch, training_loss, 'r', label='Training loss',)"", ""plt.plot(epoch, validation_loss, 'b', label='Validation loss')"", 'plt.legend()', ""plt.xlabel('Epoch'), plt.ylabel('NLL')"", 'plt.show()'

 
markdown:
## Exercise E:'

 
markdown:
Complete the training loop above and run the training. You can leave the hyper-parameters and network size unchanged.

A correct implementation should yield a loss of around **1** (using mean CE) or around **4** (using sum CE) after 1000 epochs. Does it work? If not, try to identify the issue -- perhaps something in the backward pass is not right?'

 
markdown:
## Extrapolation'

 
markdown:
Now that we have trained an RNN, it's time to put it to test. We will provide the network with a starting sentence and let it `freestyle` from there!""]'

 
code:
def freestyle(params, sentence='', num_generate=10):"", '    """"""
    Takes in a sentence as a string and outputs a sequence
    based on the predictions of the RNN.
    
    Args:
     `params`: the parameters of the network
     `sentence`: string with whitespace-separated tokens
     `num_generate`: the number of tokens to generate
    """"""', ""    sentence = sentence.split(' ')"", '    
    sentence_one_hot = one_hot_encode_sequence(sentence, vocab_size)
    
    # Initialize hidden state as zeros
    hidden_state = np.zeros((hidden_size, 1))

    # Generate hidden state for sentence
    outputs, hidden_states = forward_pass(sentence_one_hot, hidden_state, params)
    
    # Output sentence
    output_sentence = sentence
    
    # Append first prediction
    word = idx_to_word[np.argmax(outputs[-1])]    
    output_sentence.append(word)
    
    # Forward pass
    for i in range(num_generate):

        # Get the latest prediction and latest hidden state
        output = outputs[-1]
        hidden_state = hidden_states[-1]
    
        # Reshape our output to match the input shape of our forward pass
        output = output.reshape(1, output.shape[0], output.shape[1])
    
        # Forward pass
        outputs, hidden_states = forward_pass(output, hidden_state, params)
        
        # Compute the index of the most likely word and look up the corresponding word
        word = idx_to_word[np.argmax(outputs)]
        
        output_sentence.append(word)
        ', ""        if word == 'EOS':"", '            break
        
    return output_sentence


# Perform freestyle (extrapolation)', ""test_examples = ['a a b
a a a a b
a a a a a a b
a
r n n']"", 'for i, test_example in enumerate(test_examples):', ""    print(f'Example {i}:', test_example)"", ""    print('Predicted sequence:', freestyle(params, sentence=test_example), end='\\')""]'

 
markdown:
## Exercise F:

How well does your RNN extrapolate -- does it work as expected? Are there any imperfections? If yes, why could that be?'

 
markdown:
## Exercise G (optional):'",0.814132809638977,notebook 3_3,3.0,"# list individual parameters by name', ""print('WEIGHTS')"", 'print(net.W_1)
print(net.W_1.size())', ""print('\BIAS')"", 'print(net.b_1)
print(net.b_1.size())'

 
markdown:
# Exploring Parameter
', ""Ok, let's investigate what a Parameter is""]'

 
code:
param = net.W_1
print(""## this is the tensor"")
print(param.data)
print(""\## this is the tensor\'s gradient"")
print(param.grad)
# notice, the gradient is undefined because we have not yet run a backward pass

print(""\## is it a leaf in the graph?"")
print(param.is_leaf)'

 
markdown:
## Excluding subgraphs from backward propagation
', ""To exclude part of your computational graph (i.e. a subgraph) from backward propagation, simply set the relevant tensors' attribute `requires_grad` to `False`."", '
If there’s a single input to an operation that requires gradient, its output will also require gradient. Conversely, only if all inputs don’t require gradient, the output also won’t require it. Backward computation is never performed in the subgraphs, where all Tensors didn’t require gradients.'

 
markdown:
# Test network
', ""To use our network we can simply call our graph, and it will dynamically be created. Here is an example of running the network's forward pass.""]'

 
code:
X = torch.randn(5, num_features)
# the net.__call__ runs some pre-defined functions
# both before and after running net.forward()
# see http://pytorch.org/docs/master/_modules/torch/nn/modules/module.html
', ""print('input')"", 'print(X)
', ""print('\output')"", 'print(net(X))'

 
markdown:
`Parameter`s are a special kind of `Tensor`'

 
code:
# let's take a look at the gradients"", 'for p in net.parameters():
    print(p.data)
    print(p.grad)
    print()'

 
code:
X = torch.randn(7, num_features)
out = net(X)
# we need to give a tensor of gradients to .backward,
# we give a dummy tensor
out.backward(torch.randn(7, num_output))'

 
markdown:
for details on `.backward()`, see http://pytorch.org/docs/master/autograd.html#torch.autograd.backward'

 
code:
# let's take a look at the gradients"", 'for p in net.parameters():
    print(p.data)
    print(p.grad)
    print()'

 
code:
# ok, let's try and zero the accumulated gradients"", 'net.zero_grad()
for p in net.parameters():
    print(p.data)
    print(p.grad)'

 
markdown:
# Loss function
', ""Let's define a custom loss function to compute how good our graph is doing.""]'

 
code:
def cross_entropy(ys, ts):
    # computing cross entropy per sample
    cross_entropy = -torch.sum(ts * torch.log(ys), dim=1, keepdim=False)
    # averaging over samples
    return torch.mean(cross_entropy)'",0.8256494998931885,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
What variables are used in the attention function?,"The attention mechanism is defined using the query Q, the keys K, the values V, and the scaling parameter tau.",notebook 5_1,notebook 5_1,15.0,"We define three variables:
1. The query $\\mathbf{Q} = [\\mathbf{q}_i, \\ldots \\mathbf{q}_{T_\\mathbf{Q}}] \\in \\mathcal{R}^{T_\\mathbf{Q} \\times h_i}$, a sequence of vectors of length $T_\\mathbf{Q}$ and vector dimension $h_i$.
1. The keys $\\mathbf{K} = [\\mathbf{k}_1, \\ldots \\mathbf{k}_{T_{\\mathbf{K}\\mathbf{V}}}] \\in \\mathcal{R}^{T_{\\mathbf{K}\\mathbf{V}} \\times h_i}$, a sequence of vectors of length $T_{\\mathbf{K}\\mathbf{V}}$ and vector dimension $h_i$.
1. The values $\\mathbf{V} = [\\mathbf{v}_1, \\ldots \\mathbf{v}_{T_{\\mathbf{K}\\mathbf{V}}}] \\in \\mathcal{R}^{T_{\\mathbf{K}\\mathbf{V}} \\times h_o}$, a sequence of vectors of length $T_{\\mathbf{K}\\mathbf{V}}$ and of another dimension $h_o$, although in general we choose $h_i = h_o$.

For each query, the attention mechanism returns a convex combinations of the values $\\mathbf{V}$. The attention mechanism is defined as
$$
\\mathrm{Attention}(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}) = \\mathrm{Softmax}\\left( \\frac{\\mathbf{Q} \\mathbf{K}^T}{\\tau} \\right) \\mathbf{V} \\ ,
$$
where $\\tau$ is a scaling parameter, set to $\\sqrt{h_i}$ in ([""Attention is All You Need"", Wasrani et al. (2016)](https://arxiv.org/abs/1706.03762)). $\\mathrm{Attention}(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V})$ is a sequence of $T_\\mathbf{Q}$ vectors, each of dimension $h_o$.",0.39504289627075195,notebook 5_1,19.0,"markdown:
**Implementing the attention function** We obtained a set of attention weights for each query, concatenating them results in a 2D matrix that will display bellow. Let's implement the `attention` function in the cell bellow using the inputs vectors $\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}$ and visualize the output vector. we use [`torch.einsum`](https://pytorch.org/docs/stable/generated/torch.einsum.html) to implement the sum $\\sum_{i=1}^{T_{\\mathbf{K}\\mathbf{V}}} \\mathbf{\\lambda}_i \\mathbf{v}_i$.""]'

 
code:

def plot_attention_map(attention_map, queries_labels, keys_labels, print_values:bool=False, ax=None, color_bar:bool=True):
    """"""Plot the attention weights as a 2D heatmap""""""
    if ax is None:
        fig, ax = plt.subplots(figsize = (10,6), dpi=300)
    else:
        fig = plt.gcf()
    im = ax.imshow(attention_map, cmap=sns.color_palette(""viridis"", as_cmap=True))
    ax.grid(False)
    ax.set_ylabel(""$\\mathbf{Q}$"")
    ax.set_xlabel(""$\\mathbf{K}$"")
    ax.set_yticks(np.arange(len(queries_labels)))
    ax.set_yticklabels(queries_labels)
    ax.set_xticks(np.arange(len(keys_labels)))
    ax.set_xticklabels(keys_labels)
    plt.setp(ax.get_xticklabels(), rotation=45, ha=""right"",
            rotation_mode=""anchor"")

    # Loop over data dimensions and create text annotations.
    if print_values:
        for i in range(len(queries_labels)):
            for j in range(len(keys_labels)):
                text = ax.text(j, i, f""{attention_map[i, j]:.2f}"",
                            ha=""center"", va=""center"", color=""w"")

    if color_bar:
      fig.colorbar(im, fraction=0.02, pad=0.04)
    fig.tight_layout()

def attention(Q, K, V, tau=None):
    """"""A simple parallelized attention layer""""""
    if tau is None:
        tau = math.sqrt(float(Q.shape[-1]))
    assert Q.shape[-1] == K.shape[-1]
    assert K.shape[0] == V.shape[0]
    attention_map = Q @ K.T / tau
    attention_weights = attention_map.softmax(dim=1)
    return torch.einsum(""qk, kh -> qh"", attention_weights, V), attention_weights

# return the output of the attention
output, attention_weights = attention(Q, K, V, tau=1.)

# plot the attention weights
plot_attention_map(attention_weights, queries_labels, keys_labels, print_values=True)'

 
markdown:
**Exercise 5**:  What effect has the parameter $\\tau$ on the attention mechanism? What is happening when using a large value for $\\tau$? using a small value for $\\tau$? In the limits $\\tau \\rightarrow 0$ and $\\tau \\rightarrow \\infty$

> *Insert your answer here*",0.4495989978313446,notebook 5_1,16.0,"The above expresson is equivalent to applying attention to each query vector $\\mathbf{q}$ separately. The output for each vector $\\mathbf{q}$ depends on the vector of weights $\\mathbf{\\Lambda} = \\mathrm{Softmax}\\left( \\frac{\\mathbf{q} \\mathbf{K}^T}{\\tau} \\right)$ with values $[\\lambda_1, \\ldots \\lambda_{T_{\\mathbf{K}\\mathbf{V}}}]$. The vector of weights $\\Lambda$ is a function of the inner-product $\\mathbf{q} \\mathbf{K}^T$, which defines a similarity metric between the the vectors $\\mathbf{q}$ and each of the key vectors $[\\mathbf{k}_1, \\ldots \\mathbf{k}_{T_{\\mathbf{K}\\mathbf{V}}}]$. Furthermore, as the weights sum to one, the output of the attention function is a convex combinations of the values:
$$
\\mathrm{Attention}(\\mathbf{q}, \\mathbf{K}, \\mathbf{V}) = \\sum_{i=1}^{T_{\\mathbf{K}\\mathbf{V}}} \\mathbf{\\lambda}_i \\mathbf{v}_i \\ .
$$'

 
markdown:
**Experiment** We will use the GloVe word vectors to illustrate the attention mechanism. 

We define queries and keys using the GloVe word vectors correspond to country names:
$$
\\begin{align}
\\mathbf{Q} =& [\\mathrm{vec(""Italy"")}, \\mathrm{vec(""Korea"")}, \\mathrm{vec(""Nicaragua"")}, \\ldots] \\\\
\\mathbf{K} =& [\\mathrm{vec(""China"")}, \\mathrm{vec(""Russia"")}, \\mathrm{vec(""Turkey"")}, \\ldots] \\ .
\\end{align}
$$
The inner-product between paris is of country vectors will have a large values when the vectors are similar, this might happend when two countries are geographically or culturally close to each other because of the properties of the GloVe vectors. The last component required to apply the attention mechanism is set of value vectors $\\mathbf{V}$.

The choice of values depends on the end problem, for this exercise we choose stay in the same theme as for the word2vec experiments. We choose the value vectors to represent the relative concept ""*capital city of a country*"", which correspond to the vector $\\mathrm{vec(""Capital\\, city"")} - \\mathrm{vec(""Country"")}$ in the gloVe vector space. In practice, for each country we set:
$$
\\begin{align}
\\mathbf{V} =& [\\mathrm{vec(""Beijing"")} - \\mathbf{K}_1, \\mathrm{vec(""Moscow"")} - \\mathbf{K}_2, \\mathrm{vec(""Ankara"")} - \\mathbf{K}_3, \\ldots] \\\\
\\end{align}
$$",0.5170033574104309,notebook 5_1,18.0,"def plot_attention_weights(attention_weights, queries_labels, keys_labels, nrows = 2):
    """"""Plot the attention scores between each of the queries and the keys.""""""
    ncols = len(attention_weights) // nrows
    fig, axes = plt.subplots(ncols=ncols, nrows=nrows, figsize = (10,6), sharex=False, sharey=True, dpi=300)
    colors = sns.color_palette(""viridis"", as_cmap=True)
    def normalize(x, values):
        return (x -  values.min()) / (values.max() - values.min())
    for k, ax in enumerate(axes.flat):
        query_label = queries_labels[k]
        attention_weights_k = attention_weights[k]
        cols = [colors(normalize(x, attention_weights).detach().item()) for x in attention_weights_k]
        ax.bar(keys_labels, attention_weights_k, color=cols)
        plt.setp(ax.get_xticklabels(), rotation=45, ha=""right"", rotation_mode=""anchor"")
        ax.set_title(f""Query={query_label}"")
        if k % ncols == 0 :
            ax.set_ylabel(""Attention score"")
        if k >= ncols:
            ax.set_xlabel(""$\\mathbf{K}$"")
    fig.tight_layout()
    plt.show()

# Define keys, queries and values
queries_labels = [""Italy"", ""Korea"", ""Nicaragua"", ""Canada"", ""Algeria"", ""India""]
keys_labels = [""China"", ""Russia"", ""Turkey"", ""Japan"", ""Thailand"", ""Germany"", ""France"", ""Sweden"", ""Poland"", ""Nigeria"", ""Morocco"", ""Colombia"", ""Chile"", ""USA"", ""Pakistan""]
keys_cities_labels = [""Beijing"", ""Moscow"", ""Ankara"", ""Tokyo"", ""Bangkok"", ""Berlin"", ""Paris"", ""Stockholm"", ""Warsaw"", ""Abuja"", ""Rabat"", ""Bogota"", ""Santiago"", ""Washington"", ""Islamabad""]
# convert to vectors
Q = names_to_vectors(queries_labels)
K = names_to_vectors(keys_labels)
V = names_to_vectors(keys_cities_labels) - K


# compute the attention weights for each query using a ´for` loop
attention_weights = []
for q in Q:
    log_lambda_q = (q @ K.T) / math.sqrt(float(Q.shape[-1]))
    attention_weights.append(log_lambda_q)
attention_weights = torch.stack(attention_weights)

# plot attention weights for each query
plot_attention_weights(attention_weights, queries_labels, keys_labels)'

 
markdown:
**Exercise 4**:  In this example, what is the value of $T_{\\mathbf{K}\\mathbf{V}}$, $T_{\\mathbf{Q}}$, $h_i$, $h_o$ and $\\tau$ ?

> * $T_{\\mathbf{K}\\mathbf{V}} = ...$ 
> * $T_{\\mathbf{Q}} = ...$ 
> * $h_i = ...$
> * $h_o = ...$
> * $\\tau = ...$'",0.5495394468307495,notebook 5_1,21.0,"# visualized the log of the attention map
plot_attention_map(attention_map.log(), tokens, tokens)'

 
markdown:
**Exercise 7**: Comment on the structure of the attention map. Why is that the case?

> *Insert your answer here*'

 
markdown:
### IV.b Masked attention

The self-attention layer allows computing the hidden state $\\mathbf{h}_{t}$ based on all the input vectors $\\mathbf{w}_{1:T}$. In language modelling, we want to enforce constrains on the dependencies of $\\mathbf{h}_t$ to allow left-to-right or masked factorizations. A attention mask $\\mathbf{M} \\in \\{0, -\\infty \\}^{T \\times T}$ is of the same dimension as the matrix $ \\mathbf{Q} \\mathbf{K}^T$ and can be utilized to enforce the attention weights $\\mathbf{\\lambda}_1, \\ldots, \\mathbf{{\\lambda}_T}$ to be zero wherever it is necessary. The masked attention mechanism is expressed as
$$
\\mathrm{Attention} \\left(\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}, \\mathbf{M} \\right) = \\mathrm{Softmax}\\left( \\mathbf{M} + \\frac{\\mathbf{Q} \\mathbf{K}^T}{\\tau} \\right) \\mathbf{V} \\ .
$$'

 
markdown:
**Exercise 8**:  Let's implement an attention mask corresponding to:"", '1. Left-to-right language model $p(\\mathbf{w}_t \\mid \\mathbf{w}_{<t})$
1. bidirection language model $p(\\mathbf{w}_t \\mid \\mathbf{w}_{-t})$
1. right-to-left language model $p(\\mathbf{w}_t \\mid \\mathbf{w}_{t>})$

> Answer in the code below.

**NB** In the visualization bellow, we re-use the gradient map extracted from the left-to-right RNN language model.'

 
code:
def masked_attention(Q, K, V, tau=None, mask=None):
    """"""A simple masked attention layer""""""
    if tau is None:
        tau = math.sqrt(float(Q.shape[-1]))
    assert Q.shape[-1] == K.shape[-1]
    assert K.shape[0] == V.shape[0]
    attention_map = Q @ K.T / tau
    if mask is not None:
        attention_map = mask + attention_map
    attention_weights = attention_map.softmax(dim=1)
    return torch.einsum(""qk, kh -> qh"", attention_weights, V), attention_weights

# get a more natural sentence
sentence = ""Masked attention allows implementing dependency constrains between inputs and outputs.""
token_ids = torch.tensor(glove_tokenizer.encode(sentence).ids)
tokens = [glove_vocabulary[x] for x in token_ids]
vectors = embeddings(token_ids)",0.559607744216919,notebook 5_1,25.0,"**Multi-head attention** The attention mechanism introduced in the previous section depends on a softmax of inner-products, which might be sparse depending on the value of the vectors, in that case, the layer can only attend to a few positions in the sequence. To enable attending to more positions in the input sentence, multiple attention mechanism can be used in parallel. This is what we call a multi-head attention layer:
$$
\\begin{align}
\\mathrm{MultiHeadAttention} \\left(\\mathbf{Q}^{1:P}, \\mathbf{K^{1:P}}, \\mathbf{V}^{1:P}, \\mathbf{M} \\right) = [ \\mathrm{Attention} \\left(\\mathbf{Q}^{1}, \\mathbf{K^{1}}, \\mathbf{V}^{1}, \\mathbf{P} \\right), 
\\ldots
\\mathrm{Attention} \\left(\\mathbf{Q}^{P}, \\mathbf{K^{P}}, \\mathbf{V}^{P}, \\mathbf{M} \\right)] \\ ,
\\end{align}
$$
where each set of vectors $\\mathbf{Q}^{i}, \\mathbf{Q}^{i}, \\mathbf{Q}^{i}$ corresponding to the head index $i$ is obtained using a separate linear transformation of the input sequence.

**Feed-forward** The multi-head attention layer allows looking up multiple positions of the input sequence, but the output is only a linear combination of the value vector $\\mathbf{V}$. A multi-layer neural network (feed-forward layer) is applied **element-wise** to each element of the sequence of hidden states to allow modelling more complex non-linear dependencies.

**Add & Norm** A Transformer is a deep neural network, and therefore might be difficult to optimize. Similarly deep neural networks in the image processing field, Transformer layer rely on two stabilizing components:
1. [Residual connections](https://arxiv.org/abs/1512.03385) allow to bypass the attention layer as well as the feed-forward layer.
2. [Layer normalization](https://arxiv.org/abs/1607.06450): allow enforcing that the output of a Transformer layer has values that are properly distributed

**Implementation:** Here is an implementation for the attention and multi-head attention. You can also check the official [PyTorch implementation](https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#MultiheadAttention).'

 
code:
def attention(query, key, value, mask=None, dropout=None):
    ""Compute \'Scaled Dot Product Attention\'""
    d_k = query.size(-1)
    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)
    if mask is not None:
        scores = scores.masked_fill(mask == 0, -math.inf)
    p_attn = F.softmax(scores, dim = -1)
    if dropout is not None:
        p_attn = dropout(p_attn)
    return torch.matmul(p_attn, value), p_attn'",0.5887876152992249,notebook 5_1,26.0,"code:
class MultiHeadedAttention(nn.Module):
    """"""A simple Multi-head attention layer.""""""
    def __init__(self, h, d_model, dropout=0.1):
        ""Take in model size and number of heads.""
        super(MultiHeadedAttention, self).__init__()
        assert d_model % h == 0
        # We assume d_v always equals d_k
        self.d_k = d_model // h
        self.h = h
        self.linears = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(4)])
        self.attn = None # store the attention maps
        self.dropout = nn.Dropout(p=dropout)

    def forward(self, query, key, value, mask=None):
        nbatches = query.size(0)
        if mask is not None:
            # Same mask applied to all h heads.
            mask = mask.unsqueeze(1)

        # 1) Do all the linear projections in batch from d_model => h x d_k 
        query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))]

        # 2) Apply attention on all the projected vectors in batch. 
        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)

        # 3) ""Concat"" using a view and apply a final linear. 
        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)
        return self.linears[-1](x)'

 
markdown:
### IV.c Conditional layers
', ""In the description of the base layer, we have applied attention to the input sequence (*self-attention*). Machine translation is a sequence-to-sequence task, which requires and *encoder* component, that encodes a source text into a sequence of hidden states $\\mathbf{g_{1:T'}}$. The base layer can be modified with an additional attention layer that is conditionned on the source text. Given a sequence of hidden states $\\mathbf{h}_{1:T}$, the conditional attention layer is:"", '$$', ""\\mathrm{Attention}(\\mathbf{Q}(\\mathbf{h}_{1:T}), \\mathbf{K}(\\mathbf{g}_{1:T'}), \\mathbf{V}(\\mathbf{g}_{1:T'})) \\ ."", '$$
Conditional attention layers are place right after the self-attention layers, before the feed-forward layer (see diagram).

### IV.d Pre-training as language models

Transformers (the decoder component) are language models can therefore be pre-train on vast amount of unlabelled text via maximum likelihood or pseudo likelihood. They allow obtaining contextualized text representations, that can be applied to a multitude of downstream tasks (question-answering, classification, ...). While the original Transformer architecture was applied to a sequence-to-sequence problem with a component that encodes the source text and a language model decoder conditioned on the encoded source text. Transformer-based language models consist in a single decoder component (without conditional attention). The two main alternatives for language modelling are:",0.5976018309593201,notebook 5_1,22.0,"# EXERCISE: Implement the masks corresponding to each factorization
# Hint: check the documentation for `torch.diag()`, `torch.triu()` and `torch.tril()`
T = len(token_ids)
masks = {
    ""left-to-right"": ..., # <- YOUR CODE HERE
    ""bidirectional"": ..., # <- YOUR CODE HERE
    ""right-to-left"": ..., # <- YOUR CODE HERE
}
for key in masks.keys():
    if masks[key] is not None:
        masks[key] = masks[key] = torch.where(masks[key] == 0, 0, -math.inf)

# visualized the log of the masked attention map
fig, axes = plt.subplots(ncols=1+len(masks), figsize = (16,6), sharex=False, sharey=False, dpi=300)
# plot the gradient map from the RNN LM
axes.flat[0].imshow(grad_magnitude, sns.color_palette(""viridis"", as_cmap=True))
axes.flat[0].set_xlabel(""$t$ (input)"")
axes.flat[0].set_ylabel(""$t\'$ (output)"")
axes.flat[0].grid(False)
axes.flat[0].set_title(""gradient map (RNN LM)"")
# plot the attention map
for ax, (mask_name, mask) in zip(axes.flat[1:], masks.items()):
    if mask is not None:
        H, attention_map_masked = masked_attention(vectors, vectors, vectors, mask=mask)
        plot_attention_map(attention_map_masked.log(), tokens, tokens, ax=ax, color_bar=False)
    ax.set_title(f""Attention map {mask_name}"")
plt.tight_layout()
plt.show()'

 
markdown:
----
## IV. Transformers

<img src=""images/transformer.png"" alt=""Transformer architecture"" width=""600""/>

In this section we are going to introduce the [Transformer (""Attention is all you need"", Vaswani (2017))](https://arxiv.org/abs/1706.03762) architecture.

For further information, see the excellent PyTorch tutorial [""language translation using Transformers""](https://pytorch.org/tutorials/beginner/translation_transformer.html) and blog article [""Annotated Transformer""](https://nlp.seas.harvard.edu/2018/04/03/attention.html), which review the original in great details and provide additional content such as visualizations of the learned attention maps.

**Architecture** A Transformer is composed of two main components: a decoder which implements a language model and an encoder. The encoder is only required for conditional language models like those used in translation tasks. Each of the two components is made by stacking Transformer layers (layers with and without conditioning). Each layer transforms a sequence of hidden state $\\mathbf{h}_{1:T}^l$ into another sequence $\\mathbf{h}_{1:T}^{l+1}$. The input tokens are converted into the first state $\\mathbf{h}_{1:T}^0$ using an embedding layer coupled with positioal encodings. the last hidden state $\\mathbf{h}_{1:T}^{L}$ is projected into the vocabulary space using a liner layer.'

 
markdown:
### IV.a Positional encodings",0.6001656651496887,notebook 5_1,20.0,"> *Insert your answer here*


**Visualizing the output word vector** In the code below we use the code from the previous word2vec experiment to generate the nearest neighbour corresponding to the analogy: 

$$\\mathrm{vec(""Capital\\,city\\,of\\,the\\,query\\,country"")} = \\mathrm{vec(""Query\\,country"")} + \\mathrm{Attention}(\\mathrm{vec(""Query\\,country"")}, \\mathbf{K}, \\mathbf{V})$$'

 
code:
# Report of the nearest neighbors of the vector `query + Attention(query, keys, values)``
for i, attn_output in enumerate(output):
    # z = query + Attention(qeury, keys, values)
    z = Q[i] + attn_output
    rich.print(f""Nearest neighbors of [red]{queries_labels[i]}[/red] + [blue]Attention({queries_labels[i]}, K, V)"")
    rich.print(vec2words(z, k=5, **glove_args, exclude_vecs=[word2vec(queries_labels[i], **glove_args)]))'

 
markdown:
**Eercise 6** Would the results be different when shuffling the vectors $\\mathbf{K}$ and $\\mathbf{V}$ (with the same permutation for both vectors)?

> *Insert your answer here*'

 
markdown:
### III.b Self-attention

*Figure: A self-attention layers allows attending all the sequence positions*
![Self-attention allows attentind at all the sequence positions](images/self-attention.png)

The attention mechanism is a transformation of a sequence of vectors $\\mathbf{Q}$ given all the values in the sequence $\\mathbf{V}$. In a self-attention layers, the attention layer is parameterized with transformations of the input sequence $\\mathbf{w}_{1:T}$ as parameters, which allows processing each vector in a sequence $\\mathbf{w}_{1:T}$ based on all the other locations. The output of the self-attention layer is a sequence of hidden states:
$$
 \\mathbf{h}_{1:T} = \\mathrm{Attention} \\left(\\mathbf{Q}(\\mathbf{w}_{1:T}), \\mathbf{K}(\\mathbf{w}_{1:T}), \\mathbf{V}(\\mathbf{w}_{1:T}) \\right)
$$
', ""**Illustration** Let's apply the self-attention to a list of word vectors, do you any structure emerging?""]'

 
code:
# Illustration of the above using code
hdim = 300
sentence = ""Copenhagen Denmark Stockholm Sweden Beijing China Tokyo Japan truck car bus""
token_ids = torch.tensor(glove_tokenizer.encode(sentence).ids)
tokens = [glove_vocabulary[x] for x in token_ids]
vectors = embeddings(token_ids)
H, attention_map = attention(vectors, vectors, vectors)
rich.print({
    ""Q"": Q.shape,
    ""K"": K.shape,
    ""V"": V.shape,
    ""H"": H.shape
})

# visualized the log of the attention map
plot_attention_map(attention_map.log(), tokens, tokens)'

 
markdown:
**Exercise 7**: Comment on the structure of the attention map. Why is that the case?",0.6477934122085571,notebook 5_1,17.0,"*Figure: Word vectors vec(""capital city"") - vec(""country"") represented in a vector space. Vectors might point in different direction depending on their position in the vector space.*
![Attention analogies](images/attention-analogies.png)

We represent the query, key and value vectors in the GloVe vector space in the above figure. The intuition is that the value vector $\\mathrm{vec}(\\text{""capital city of a country""})$ is not always the same depending on the country. Therefore, in this experiment, we will attempt to extract value vectors that are contextualized on the query. To do so, we will add the output of the attention (a mixture of vectors $\\mathrm{vec}(\\text{""capital city""}) - \\mathrm{vec}(\\text{""country""})$) to the vector representation of the query (a country). This corresponds to:

$$
\\mathrm{vec(""Capital\\,city\\,of\\,the\\,query\\,country"")} =  \\mathrm{vec(""Query\\,country"")} + \\underbrace{\\mathrm{Attention}(\\mathrm{vec(""Query\\,country"")}, \\mathbf{K}, \\mathbf{V})}_{\\sum_{i=1}^{T_{\\mathbf{K}\\mathbf{V}}} \\mathbf{\\lambda}_i \\mathbf{v}_i}
$$
', ""First, let's investigate the attention weights $\\lambda_1, \\ldots, \\lambda_{T_{\\mathbf{K}\\mathbf{V}}}$ for each query $\\mathbf{q}_1, \\ldots, \\mathbf{q}_\\mathbf{Q} $ separately:""]'

 
code:
# instantiate some embeddings
embeddings = torch.nn.Embedding(*glove_vectors.shape)
embeddings.weight.data = glove_vectors
embeddings.weight.requires_grad = False

def names_to_vectors(values: List[str]) -> torch.Tensor:
    encodings = glove_tokenizer.encode_batch(values)
    vectors = [embeddings(torch.tensor(e.ids)).mean(dim=0) for e in encodings]
    return torch.stack(vectors)",0.6651980876922607,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0
What is sampling for a language model?,"Sampling text means that the language model is generating text. This corresponds to the inference process of the network, as opposed to training.",notebook 5_1,notebook 5_1,8.0,"**Training** As long as the transition function $p_\\theta(\\mathbf{w}_t \\mid \\mathbf{w}_{<t})$ is differentiable (i.e., using neural networks), a language model can be  trained via maximum likelihood, e.g. maximizing the log-likelihood with the loss:
$$
L = - \\log p_\\theta(\\mathbf{w}_{1:T}) = - \\sum_{t=1}^T \\log p_\\theta(\\mathbf{w}_t \\mid \\mathbf{w}_{<t})
$$
Each term $p_\\theta(\\mathbf{w}_t \\mid \\mathbf{w}_{<t})$ can be evaluated using the observed variables $\\mathbf{w}_t$ and $\\mathbf{w}_{<t}$ (no sampling is required) and thus training of auto-regressive models is fast when the evaluation of $f_\\theta(\\mathbf{w}_t \\mid \\mathbf{w}_{<t})$ can be parallelized.'

 
markdown:
*Figure: Bidirectional language models*
![Masked language model](images/masked-lm.png)

**Bidirectional and masked language models** Autoregressive language models learn to predict a token $\\mathbf{w}_t$ given the context up to the step $t-1$. One can also use a [pseudo likelihood](https://en.wikipedia.org/wiki/Pseudolikelihood), where $\\mathbf{w}_t$ is not only conditioned on the preceeding tokens $\\mathbf{w}_{<t}$, but also on the next tokens $\\mathbf{w}_{>t}$. This defines a bidirectional language model, which factorizes as
$$
L_\\theta(\\mathbf{w}_{1:T}) = \\prod_{t=1}^T p_\\theta(\\mathbf{w}_t \\mid \\mathbf{w}_{-t}) \\ ,
$$
where $\\mathbf{w}_{-t}$ represent the set of tokens $\\mathbf{w}_{1:T} \\backslash \\{ \\mathbf{w}_t \\}$. We call it pseudo because this likelihood is not forming a valid distribution (because the graph formed by $\\mathbf{w}_{1:T}$ is not a directed acyclic graph (a DAG)).  Bidirectional language models such as [ELMo (""Deep contextualized word representations"", Peters et al. (2018))](https://arxiv.org/abs/1802.05365), learn token representation contextualized on the whole context.",0.4333145022392273,notebook 5_1,6.0,"### II.a Language Modelling

*Figure: Left-to-right language models*
![Autoregressive left-to-right language model](images/ar-lm.png)

**Autoregressive factorization** Language models aim at grasping the underlying linguistic structure of a text fragment: whereas word vectors model words independently of each others, a language model tracks the grammatical and semantic relationships between word tokens. Given a piece of text encoded into tokens $\\mathbf{w}_{1:T} = [\\mathbf{w_1}, \\ldots, \\mathbf{w}_T]$ a *left-to-right* language model describes $\\mathbf{w}_{1:T}$ with the following factorization:
$$
 p_\\theta(\\mathbf{w}_{1:T}) = \\prod_{t=1}^T p_\\theta(\\mathbf{w}_t \\mid \\mathbf{w}_{<t}) \\ ,
$$
where $\\theta$ is a model parameter. The above *autoregressive* factorization describes a *recursive* function $p_\\theta(\\mathbf{w}_t \\mid \\mathbf{w}_{<t})$, which is shared across all the time steps. In the above figure, we represent a left-to-right language model with dependencies represented by arrows for fixed steps $t=3$ and $t=4$. Because of this choice of factorization, a language model defines a graphical model where each step $t$ depends on all the previous steps $<t$ and the conditional $p_\\theta(\\mathbf{w}_t \\mid \\mathbf{w}_{<t})$ models the dependendies between the context $\\mathbf{w}_{<t}$ and the variable $\\mathbf{w}_t$.

**Other factorizations** Autoregressive models are not required to adopt a left-to-right factorization and other forms of factorizations can be implemented (right-to-left or arbitrary permutations). See [""XLNet: Generalized Autoregressive Pretraining for Language Understanding"", Yang et al. (2019)](https://arxiv.org/abs/1906.08237) for an example.'

 
markdown:
*Figure: Categorical distribution over the possible next tokens given the context*
![Categorical distribution](images/categorical-dist.png)",0.4871198534965515,notebook 5_1,28.0,"### V.a Language generation
', ""Let's experiment with GPT-2 (in the notebook, we use the smaller [`distilgpt2`](https://huggingface.co/distilgpt2), but feel free to use the original `gpt2` if you have enough compute)"", '
**Experiment** Generate text using GPT-2:'

 
code:
# load a GPT-2 model
model_id = ""distilgpt2""
# model_id = ""gpt2""
tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)
model = transformers.AutoModel.from_pretrained(model_id)
# Here we want to load the weights of GPT2 as an autoregressive LM, or ""causal"" LM: we use the class `AutoModelForCausalLM`.
model = transformers.AutoModelForCausalLM.from_pretrained(model_id)'

 
code:
# encode context the generation is conditioned on
prompt = tokenizer.bos_token # use the Begining Of Sentence token to initialize allow generating text from scratch', ""input_ids = tokenizer.encode(prompt, return_tensors='pt')"", '# expand input_ids, so we can sample multiple generations in parallel
input_ids = input_ids.repeat(5, 1)

# generate text until the output length (which includes the context length) reaches 50
# documentation for `model.generate()` https://huggingface.co/docs/transformers/v4.22.1/en/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate
output = model.generate(input_ids, do_sample=True, temperature=1., max_length=50)
decoded = tokenizer.batch_decode(output)
for txt in decoded:
    txt = txt.replace(""\"", """")
    print(txt)'

 
markdown:
**Exercise 9**: Play with the temperature parameter, what is it controlling? how can you related it to the definition of a language model?

> *Insert your your answer here*'

 
markdown:
### V.b. Prompt-based learning

Prompt-based learning consists in framing a problem into a *prompt* which completion by a language model corresponds to the answer. In other words, it consists in using natural language to interface with language models.

**Experiment** Do language models know what hygge is?

**Exercise 10**: Write a prompt that triggers a language model to define ""hygge"".

> *write your prompt here and test it using GPT-2 and GPT-3*'

 
code:
prompt = ""Q: What is Hygge? A:""', ""input_ids = tokenizer.encode(prompt, return_tensors='pt')"", 'input_ids = input_ids.repeat(5, 1)
output = model.generate(input_ids, do_sample=True, temperature=1, max_length=50)
decoded = tokenizer.batch_decode(output)
for txt in decoded:
    txt = txt.replace(""\"", """")
    print(txt)'

 
markdown:
**Exercise 11**: Test your prompt [with GPT-3](https://beta.openai.com/playground)

> *Insert your prompt and the GPT-3 completion here*
'

 
markdown:",0.5504145622253418,notebook 7_2,9.0,"## 6. Evaluating a Variational Autoencoder

### Assessing the Quality of the Samples

The Variational Autoencoder defines a generative process $\\mathbf{z} \\sim p_{\\theta}(\\mathbf{z}), \\  \\mathbf{x} \\sim p_{\\theta}(\\mathbf{x} | \\mathbf{z})$. A *good* VAE should explain well the data $\\mathbf{x}$ and samples $\\mathbf{x} \\sim p_{\\theta}(\\mathbf{x} |\\mathbf{z}), \\mathbf{z} \\sim p_{\\theta}(\\mathbf{z})$ should be representive of the dataset.

### Estimating the Likelihood

A VAE defines a probabilistic model $p_\\theta(\\mathbf{x} | \\mathbf{z}) p(\\mathbf{z})$ and we are interested in maximizing the ability of the model to explain the dataset $\\mathcal{D} = \\{\\mathbf{x}_i\\}_{i=1, \\dots, N}$, hence we aim at obtaining the maximum probability $\\log p_\\theta(\\mathcal{D}) = \\sum_{i=1}^N \\log p_\\theta(\\mathbf{x}_i) =  \\sum_{i=1}^N \\log \\int_\\mathbf{z} p_\\theta(\\mathbf{x}_i, \\mathbf{z}) d\\mathbf{z} $. However, as discussed previously, the log-likelihood is intractable (marginalization over $\\mathbf{z}$), hence we rely on the Evidence Lower Bound (ELBO) as a proxy, or a tighter bound such as the importance weighted bound (see at the end of the notebook). 

**NB** It is common practice to report the average marginal log likelihood $\\log p_\\theta(\\mathcal{D}) / N$ and not $\\log p_\\theta(\\mathcal{D})$ directly:

$$\\frac{1}{N} \\log p_\\theta(\\mathcal{D}) = \\frac{1}{N} \\sum_i \\log p_\\theta(\\mathbf{x}_i) \\geq \\frac{1}{N} \\sum_i \\operatorname{ELBO}(\\mathbf{x}_i) \\ . $$

### Evaluation on Downstream Tasks

As explained in the previous notebook, there is an interest in learning *compressed* representations $\\mathbf{z}$ of $\\mathbf{x}$ with the intent of solving downstream tasks such as classification. In this scenario, it is important to evaluate the VAE on the final task. For instance, learning a classifier using $\\mathbf{z}$ as features: $p(y | \\mathbf{z})$.'

 
markdown:
# Practice: Building and Training VAEs

## Probabilistic Building Blocks

First, we will implement modules representing probability distributions, which are essential in probabilistic machine learning. Here, we loosely follow the implementation from the `torch.distributions` package which provides modules for most of the commonly used distributions. 

### 1. Gaussian Distribution",0.5508440732955933,notebook 5_1,27.0,"* [Generative Pre-trained Transformers (GPT)](https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf): autoregressive left-to-right language models implemented using a Transformer.

* [Bidirectional Encoder Representations from Transformers (BERT)](https://arxiv.org/abs/1810.04805): a masked language model trained to predict tokens that are randomly masked out (masked language model) and trained to predict whether two sentences are related or not (next-sentence prediction (NSP) task).'

 
markdown:
___
## V. Applications of Transformer-based language models
', ""Let's experiment with a few pre-trained Transformers using the [🤗 HuggingFace](https://huggingface.co/) environment and the [OpenAI API](https://beta.openai.com/docs/guides/completion). "", '
HuggingFace is a company that manages multiple open source projects:
* **[tokenizers](https://huggingface.co/docs/tokenizers/index)**: a very efficient implementation of tokenizers using Rust.
* **[datasets](https://huggingface.co/docs/datasets/index)**:a library for handling and sharing large datasets (in particular they use [Apache Arrow](https://arrow.apache.org/)  for efficient data loading from disk)
* **[transformers](https://huggingface.co/docs/transformers/index)**: implementation and sharing of Transformers in Tensorflow, PyTorch and JAX

All HuggingFace models and datasets (text, audio, image and more) can be accessed through the [🤗 Hub](https://huggingface.co/), and many models can tested lives on [🤗 spaces](https://huggingface.co/spaces). In the examples bellow, we will first try to manipulate data and models using lower primitives (tokenizing data, loading a model, generating / inference), so you can interact if the intermediate variables if you want to. Then we will us the blackbox [`Pipeline`](https://huggingface.co/docs/transformers/v4.22.1/en/main_classes/pipelines#transformers.pipeline) object. If you want to apply Transformers without modifying any of the components, the `Pipeline` can be used to perform complex tasks in one line of code, as showed here with the translation task.

The OpenAI API gives access to GPT-3 ([""Language Models are Few-Shot Learners"", Brown et al. (2020)](https://arxiv.org/abs/2005.14165)) through a [playground](https://beta.openai.com/playground), where you can test the text completion capabilities of these models. GPT-3 is a large language model (up to 175 billion parameters) which has acquired impressive language understanding capabilities. It can be applied to solve new tasks without task-specific fine-tuning. [OpenAI gives you $18 to of API credits, but careful with the number of calls: running the largest version of GPT-3 (´davinci´) can be expensive](https://openai.com/api/pricing/).",0.5613974928855896,notebook 5_2,14.0,"code:
def freestyle(NN, sentence='', num_generate=10):"", '    """"""
    Takes in a sentence as a string and outputs a sequence
    based on the predictions of the RNN.
    
    Args:
     `params`: the parameters of the network
     `sentence`: string with whitespace-separated tokens
     `num_generate`: the number of tokens to generate
    """"""', ""    sentence = sentence.split(' ')"", '    output_sentence = sentence
    sentence_one_hot = one_hot_encode_sequence(sentence, vocab_size)

    # Begin predicting
    outputs = forward_batch([sentence_one_hot], NN, use_stored_hid=False)
    output_words = [idx_to_word[np.argmax(output)] for output in Var_to_nparray(outputs[0])]
    word = output_words[-1]

    # Append first prediction
    output_sentence.append(word)

    # Forward pass - Insert code here!', ""    if word != 'EOS':"", '      for i in range(num_generate-1):
          sentence_one_hot = 
          outputs = 
          output_words = 
          word = 
          output_sentence.append(word)', ""          if word == 'EOS':"", '              break
          
    return output_sentence


# Perform freestyle (extrapolation)', ""test_examples = ['a a b
a a a a b
a a a a a a b
a
r n n']"", 'for i, test_example in enumerate(test_examples):', ""    print(f'Example {i}:', test_example)"", ""    print('Predicted sequence:', freestyle(NN, sentence=test_example), end='\\')""]'

 
markdown:
# Introduction to the Long Short-Term Memory (LSTM) Cell
', ""Reading material: [Christopher Olah's walk-through](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)."", '
___


A vanilla RNN suffers from [the vanishing gradients problem](http://neuralnetworksanddeeplearning.com/chap5.html#the_vanishing_gradient_problem) which gives challenges in saving memory over longer sequences. To combat these issues the gated hidden units were created. The two most prominent gated hidden units are the Long Short-Term Memory (LSTM) cell and the Gated Recurrent Unit (GRU), both of which have shown increased performance in saving and reusing memory in later timesteps. In this exercise, we will focus on LSTM but you would easily be able to go ahead and implement the GRU as well based on the principles that you learn here.

Below is a figure of the LSTM cell:'

 
markdown:
![lstm](https://i.imgur.com/3VkmUCe.png)
Source: https://arxiv.org/abs/1412.7828'

 
markdown:

The LSTM cell contains three gates, input, forget, output gates and a memory cell.
The output of the LSTM unit is computed with the following functions, where $\\sigma = \\mathrm{sigmoid}$.
We have input gate $i$, forget gate $f$, and output gate $o$ defines as

- $i = \\sigma ( W^i [h_{t-1}, x_t])$

- $f = \\sigma ( W^f [h_{t-1},x_t])$",0.5780456066131592,LearningObjectives.txt,0.0,"Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.

Understand and explain the choices and limitations of a model for a given setting.

Apply and analyze results from deep learning models in exercises and own project work.

Plan, delimit and carry out an applied or methods-oriented project in collaboration with fellow students and project supervisor.

Assess and summarize the project results in relation to aims, methods and available data.

Carry out the project and interpret results by use of computational framework for GPU programming such as PyTorch.

Structure and write a final short technical report including problem formulation, description of methods, experiments, evaluation and conclusion.

Organize and present project results at the final project presentation and in report.

Read, evaluate and give feedback to work of other students.",0.5838748216629028,notebook 7_2,14.0,"def forward(self, x) -> Dict[str, Any]:
        """"""compute the posterior q(z|x) (encoder), sample z~q(z|x) and return the distribution p(x|z) (decoder)""""""
        
        # flatten the input
        x = x.view(x.size(0), -1)
        
        # define the posterior q(z|x) / encode x into q(z|x)
        qz = self.posterior(x)
        
        # define the prior p(z)
        pz = self.prior(batch_size=x.size(0))
        
        # sample the posterior using the reparameterization trick: z ~ q(z | x)
        z = qz.rsample()
        
        # define the observation model p(x|z) = B(x | g(z))
        px = self.observation_model(z)
        ', ""        return {'px': px, 'pz': pz, 'qz': qz, 'z': z}"", '    
    
    def sample_from_prior(self, batch_size:int=100):
        """"""sample z~p(z) and return p(x|z)""""""
        
        # degine the prior p(z)
        pz = self.prior(batch_size=batch_size)
        
        # sample the prior 
        z = pz.rsample()
        
        # define the observation model p(x|z) = B(x | g(z))
        px = self.observation_model(z)
        ', ""        return {'px': px, 'pz': pz, 'z': z}"", '

latent_features = 2
vae = VariationalAutoencoder(images[0].shape, latent_features)
print(vae)'

 
markdown:
## Implement a module for Variational Inference

**Exercise 1**: implement `elbo` ($\\mathcal{L}$) and `beta_elbo` ($\\mathcal{L}^\\beta$)'

 
code:
def reduce(x:Tensor) -> Tensor:
    """"""for each datapoint: sum over all dimensions""""""
    return x.view(x.size(0), -1).sum(dim=1)",0.5979732275009155,notebook 7_2,13.0,"# Inference Network
        # Encode the observation `x` into the parameters of the posterior distribution
        # `q_\\phi(z|x) = N(z | \\mu(x), \\sigma(x)), \\mu(x),\\log\\sigma(x) = h_\\phi(x)`
        self.encoder = nn.Sequential(
            nn.Linear(in_features=self.observation_features, out_features=256),
            nn.ReLU(),
            nn.Linear(in_features=256, out_features=128),
            nn.ReLU(),
            # A Gaussian is fully characterised by its mean \\mu and variance \\sigma**2
            nn.Linear(in_features=128, out_features=2*latent_features) # <- note the 2*latent_features
        )
        
        # Generative Model
        # Decode the latent sample `z` into the parameters of the observation model
        # `p_\\theta(x | z) = \\prod_i B(x_i | g_\\theta(x))`
        self.decoder = nn.Sequential(
            nn.Linear(in_features=latent_features, out_features=128),
            nn.ReLU(),
            nn.Linear(in_features=128, out_features=256),
            nn.ReLU(),
            nn.Linear(in_features=256, out_features=self.observation_features)
        )
        
        # define the parameters of the prior, chosen as p(z) = N(0, I)', ""        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))"", '        
    def posterior(self, x:Tensor) -> Distribution:
        """"""return the distribution `q(x|x) = N(z | \\mu(x), \\sigma(x))`""""""
        
        # compute the parameters of the posterior
        h_x = self.encoder(x)
        mu, log_sigma =  h_x.chunk(2, dim=-1)
        
        # return a distribution `q(x|x) = N(z | \\mu(x), \\sigma(x))`
        return ReparameterizedDiagonalGaussian(mu, log_sigma)
    
    def prior(self, batch_size:int=1)-> Distribution:
        """"""return the distribution `p(z)`""""""
        prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])
        mu, log_sigma = prior_params.chunk(2, dim=-1)
        
        # return the distribution `p(z)`
        return ReparameterizedDiagonalGaussian(mu, log_sigma)
    
    def observation_model(self, z:Tensor) -> Distribution:
        """"""return the distribution `p(x|z)`""""""
        px_logits = self.decoder(z)
        px_logits = px_logits.view(-1, *self.input_shape) # reshape the output
        return Bernoulli(logits=px_logits, validate_args=False)",0.6020568013191223,notebook 5_1,26.0,"code:
class MultiHeadedAttention(nn.Module):
    """"""A simple Multi-head attention layer.""""""
    def __init__(self, h, d_model, dropout=0.1):
        ""Take in model size and number of heads.""
        super(MultiHeadedAttention, self).__init__()
        assert d_model % h == 0
        # We assume d_v always equals d_k
        self.d_k = d_model // h
        self.h = h
        self.linears = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(4)])
        self.attn = None # store the attention maps
        self.dropout = nn.Dropout(p=dropout)

    def forward(self, query, key, value, mask=None):
        nbatches = query.size(0)
        if mask is not None:
            # Same mask applied to all h heads.
            mask = mask.unsqueeze(1)

        # 1) Do all the linear projections in batch from d_model => h x d_k 
        query, key, value = [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linears, (query, key, value))]

        # 2) Apply attention on all the projected vectors in batch. 
        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)

        # 3) ""Concat"" using a view and apply a final linear. 
        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)
        return self.linears[-1](x)'

 
markdown:
### IV.c Conditional layers
', ""In the description of the base layer, we have applied attention to the input sequence (*self-attention*). Machine translation is a sequence-to-sequence task, which requires and *encoder* component, that encodes a source text into a sequence of hidden states $\\mathbf{g_{1:T'}}$. The base layer can be modified with an additional attention layer that is conditionned on the source text. Given a sequence of hidden states $\\mathbf{h}_{1:T}$, the conditional attention layer is:"", '$$', ""\\mathrm{Attention}(\\mathbf{Q}(\\mathbf{h}_{1:T}), \\mathbf{K}(\\mathbf{g}_{1:T'}), \\mathbf{V}(\\mathbf{g}_{1:T'})) \\ ."", '$$
Conditional attention layers are place right after the self-attention layers, before the feed-forward layer (see diagram).

### IV.d Pre-training as language models

Transformers (the decoder component) are language models can therefore be pre-train on vast amount of unlabelled text via maximum likelihood or pseudo likelihood. They allow obtaining contextualized text representations, that can be applied to a multitude of downstream tasks (question-answering, classification, ...). While the original Transformer architecture was applied to a sequence-to-sequence problem with a component that encodes the source text and a language model decoder conditioned on the encoded source text. Transformer-based language models consist in a single decoder component (without conditional attention). The two main alternatives for language modelling are:",0.6022605895996094,1.0,2.0,3.0,3.0,4.0,4.0,4.0,4.0,4.0,5.0
What is a rnn?,"A recurrent neural network (RNN) is a type of neural network that has been succesful in modelling sequential data, e.g. language, speech, protein sequences, etc. A RNN performs its computations in a cyclic manner, where the same computation is applied to every sample of a given sequence. The idea is that the network should be able to use the previous computations as some form of memory and apply this to future computations"," notebook 5_2, notebook 5_3",notebook 5_2,7.0,"markdown:
Great! Now that we have our one-hot encodings in place, we can move on to the RNNs!'

 
markdown:
# Introduction to Recurrent Neural Networks (RNN)

Reading material: [blog post](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) and (optionally) [this lecture](https://www.youtube.com/watch?v=iWea12EAu6U&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z).

___

A recurrent neural network (RNN) is a type of neural network that has been succesful in modelling sequential data, e.g. language, speech, protein sequences, etc.

A RNN performs its computations in a cyclic manner, where the same computation is applied to every sample of a given sequence.
The idea is that the network should be able to use the previous computations as some form of memory and apply this to future computations.
An image may best explain how this is to be understood,

![rnn-unroll image](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/static_files/rnn-unfold.png?raw=1)


where it the network contains the following elements:

- $x$ is the input sequence of samples, 
- $U$ is a weight matrix applied to the given input sample,
- $V$ is a weight matrix used for the recurrent computation in order to pass memory along the sequence,
- $W$ is a weight matrix used to compute the output of the every timestep (given that every timestep requires an output),', ""- $h$ is the hidden state (the network's memory) for a given time step, and"", '- $o$ is the resulting output.

When the network is unrolled as shown, it is easier to refer to a timestep, $t$.
We have the following computations through the network:

- $h_t = f(U\\,{x_t} + V\\,{h_{t-1}})$, where $f$ is a non-linear activation function, e.g. $\\mathrm{tanh}$.
- $o_t = W\\,{h_t}$

When we are doing language modelling using a cross-entropy loss, we additionally apply the softmax function to the output $o_{t}$:

- $\\hat{y}_t = \\mathrm{softmax}(o_{t})$


### Backpropagation through time

We define a loss function

- $E = \\sum_t E_t  = \\sum_t E_t(y_t ,\\hat{y}_t ) \\ , $

where $E_t(y_t ,\\hat{y}_t )$ is the cross-entropy function.

Backpropagation through time amounts to computing the gradients of the loss using the same type of clever bookkeeping we applied to the feed-forward network in week 1. This you will do in Exercise D.'

 
markdown:
## Implementing an RNN

We will implement the forward pass, backward pass, optimization and training loop for an RNN in Nanograd so that you can get familiar with the recurrent nature of RNNs. Later, we will go back to PyTorch.'",0.5132202506065369,notebook 5_3,5.0,"___

A recurrent neural network (RNN) is a type of neural network that has been succesful in modelling sequential data, e.g. language, speech, protein sequences, etc.

A RNN performs its computations in a cyclic manner, where the same computation is applied to every sample of a given sequence.
The idea is that the network should be able to use the previous computations as some form of memory and apply this to future computations.
An image may best explain how this is to be understood,

![rnn-unroll image](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/static_files/rnn-unfold.png?raw=1)


where it the network contains the following elements:

- $x$ is the input sequence of samples, 
- $U$ is a weight matrix applied to the given input sample,
- $V$ is a weight matrix used for the recurrent computation in order to pass memory along the sequence,
- $W$ is a weight matrix used to compute the output of the every timestep (given that every timestep requires an output),', ""- $h$ is the hidden state (the network's memory) for a given time step, and"", '- $o$ is the resulting output.

When the network is unrolled as shown, it is easier to refer to a timestep, $t$.
We have the following computations through the network:

- $h_t = f(U\\,{x_t} + V\\,{h_{t-1}})$, where $f$ is a non-linear activation function, e.g. $\\mathrm{tanh}$.
- $o_t = W\\,{h_t}$

When we are doing language modelling using a cross-entropy loss, we additionally apply the softmax function to the output $o_{t}$:

- $\\hat{y}_t = \\mathrm{softmax}(o_{t})$


### Backpropagation through time

We define a loss function

- $E = \\sum_t E_t  = \\sum_t E_t(y_t ,\\hat{y}_t ) \\ , $

where $E_t(y_t ,\\hat{y}_t )$ is the cross-entropy function.

Backpropagation through time amounts to computing the gradients of the loss using the same type of clever bookkeeping we applied to the feed-forward network in week 1. This you will do in Exercise D.'

 
markdown:
## Implementing an RNN'

 
markdown:
We will implement the forward pass, backward pass, optimization and training loop for an RNN in numpy so that you can get familiar with the recurrent nature of RNNs. Later, we will go back to PyTorch and appreciate how convenient the implementation becomes!'

 
markdown:
Let's first define the necessary model parameters. Recall that an $n \\times m$ weight matrix maps $\\mathbb{R}^{m} \\rightarrow \\mathbb{R}^{n}$.""]'

 
code:
hidden_size = 50 # Number of dimensions in the hidden state
vocab_size  = len(word_to_idx) # Size of the vocabulary used",0.5703247785568237,notebook 5_2,8.0,"We will implement the forward pass, backward pass, optimization and training loop for an RNN in Nanograd so that you can get familiar with the recurrent nature of RNNs. Later, we will go back to PyTorch.'

 
markdown:
We define the Nanograd DenseLayer class from [lab 2](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/2_Feedforward_Python/2.1-EXE-FNN-AutoDif-Nanograd.ipynb) with a few additions:
* the option use_bias to define a layer without bias. This is useful when we define the recurrent layer and
* a method forward_sequence which is useful when a DenseLayer is used as part of a recurrent neural network'

 
code:
from typing import Sequence

class DenseLayer:
    def __init__(self, n_in: int, n_out: int, act_fn, initializer = NormalInitializer(), use_bias=True):
        self.weights = initializer.init_weights(n_in, n_out)
        self.use_bias = use_bias
        if use_bias:
          self.bias = initializer.init_bias(n_out)
        self.act_fn = act_fn
    
    def __repr__(self):    ', ""        return 'Weights: ' + repr(self.weights) + (' Biases: ' + repr(self.bias) if self.use_bias else '')"", '
    def parameters(self) -> Sequence[Var]:
      params = []
      for r in self.weights:
        params += r

      if self.use_bias:
        params += self.bias

      return params

    def forward(self, input: Sequence[Var]) -> Sequence[Var]:
        # self.weights is a matrix with dimension n_in x n_out. We check that the dimensionality of the input 
        # to the current layer matches the number of nodes in the current layer
        assert len(self.weights) == len(input), ""weights and input must match in first dimension""
        weights = self.weights
        out = []
        # For some given data point single_input, we now want to calculate the resulting value in each node in the current layer
        # We therefore loop over the (number of) nodes in the current layer:
        for j in range(len(weights[0])): 
            # Initialize the node value depending on its corresponding parameters.
            node = self.bias[j] if self.use_bias else Var(0.0)
            # We now finish the linear transformation corresponding to the parameters of the currently considered node.
            for i in range(len(input)):
                node += input[i]*weights[i][j]
            node = self.act_fn(node)
            out.append(node)

        return out
    
    def forward_sequence(self, input: Sequence[Sequence[Var]]) -> Sequence[Sequence[Var]]:
        out = []
        for i in range(len(input)): 
            node = self.forward(input[i])
            out.append(node)

        return out'

 
markdown:
## Exercise b) The RNNLayer class

Complete the RNNLayer class below.

Explain how we reuse the DenseLayer class.

Explain what the forward and the forward_sequence method do.'

 
code:
from typing import Sequence",0.7128164768218994,notebook 5_3,25.0,"Go back and generate a more complex patterned dataset to learn from. Do you see any significant differences between the vanilla RNN and LSTM when you increase the difficulty of the task?'

 
markdown:
# It works, now what?'

 
markdown:
In this notebook you have learned how to use embeddings, recurrent neural networks, and the LSTM cell in particular.
', ""As we have already seen, RNNs are excellent for sequential data such as language. But what do we do if we're modelling data with strong dependency in both directions? Like in many things deep learning, we can build powerful models by stacking layers on top of each other; *bi-directional* RNNs consist of two LSTM cells, one for each direction. A sequence is first fed into the forward LSTM cell and the reversed sequence is then used as input to the backward LSTM cell together with the last hidden state from the forward LSTM cell. Follow [this link](https://pdfs.semanticscholar.org/4b80/89bc9b49f84de43acc2eb8900035f7d492b2.pdf) for the original paper from 1997(!)."", '
For even deeper representations, multiple layers of both uni-directional and bi-directional RNNs can be stacked ontop of each other, just like feed-forward and convolutional layers. For more information on this, check out the [LSTM PyTorch documentation](https://pytorch.org/docs/stable/nn.html#lstm). Next week we will also explore ways to combine RNNs with other types of layers for even more expressive function approximators.'",0.7405613660812378,notebook 5_2,20.0,"# Plot training and validation loss
epoch = np.arange(len(training_loss))
plt.figure()', ""plt.plot(epoch, training_loss, 'r', label='Training loss',)"", ""plt.plot(epoch, validation_loss, 'b', label='Validation loss')"", 'plt.legend()', ""plt.xlabel('Epoch'), plt.ylabel('NLL')"", 'plt.show()'

 
markdown:
# Exercise k) Compare PyTorch and Nanograd implementations

Compare the two implementations (in terms of predictive performance, training speed, etc.). Are they similar? How do they differ?


Try to play around with the choice of hyper-parameters, optimizer, and hidden dimensions. How much can you improve the negative log-likelihood by these simple changes?'

 
markdown:
## Exercise l) Other RNN cells (optional)

Aside from the LSTM cell, various other RNN cells exist. The gated recurrent unit (GRU) is a variation of the LSTM cell that uses less gating mechanisms. Try to look it up in the [PyTorch documentation](https://pytorch.org/docs/stable/nn.html#gru) and switch out the LSTM cell in the code above. What do you notice in terms of performance and convergence speed?'

 
markdown:
## Exercise m) More complex tasks (optional)

Go back and generate a more complex patterned dataset to learn from. Do you see any significant differences between a vanilla RNN and LSTM (implemented in e.g. PyTorch) when you increase the difficulty of the task?'

 
markdown:
# It works, now what?'

 
markdown:
In this notebook you have learned how to use embeddings, recurrent neural networks, and the LSTM cell in particular.
', ""As we have already seen, RNNs are excellent for sequential data such as language. But what do we do if we're modelling data with strong dependency in both directions? Like in many things deep learning, we can build powerful models by stacking layers on top of each other; *bi-directional* RNNs consist of two LSTM cells, one for each direction. A sequence is first fed into the forward LSTM cell and the reversed sequence is then used as input to the backward LSTM cell together with the last hidden state from the forward LSTM cell. Follow [this link](https://pdfs.semanticscholar.org/4b80/89bc9b49f84de43acc2eb8900035f7d492b2.pdf) for the original paper from 1997(!)."", '
For even deeper representations, multiple layers of both uni-directional and bi-directional RNNs can be stacked ontop of each other, just like feed-forward and convolutional layers. For more information on this, check out the [LSTM PyTorch documentation](https://pytorch.org/docs/stable/nn.html#lstm). Next week we will also explore ways to combine RNNs with other types of layers for even more expressive function approximators.'",0.7450581789016724,notebook 5_3,0.0,"markdown:
# Week 5 - Recurrent Neural Networks

In this lab, we will introduce different ways of learning from sequential data.

As a recurring example, we will train neural networks to do language modelling, i.e. predict the next token in a sentence. In the context of natural language processing a token could be a character or a word, but mind you that the concepts introduced here apply to all kinds of sequential data, such as e.g. protein sequences, weather measurements, audio signals, or videos, just to name a few.
', ""To really get a grasp of what is going on inside a recurrent neural network (RNN), we will carry out a substantial part of this exercise in NumPy rather than PyTorch. We start off with a simple toy problem, build an RNN using NumPy, train and it, and see for ourselves that it really works. Once we're convinced, we proceed to build and train a Long Short-Term Memory (LSTM) cell, also in NumPy. This is *not* simply to cause you frustration, but rather to provide you with a deeper understanding of the recurrence in RNNs, which will become very beneficial to you in the following weeks. Once you understand the inner workings of an RNN, we will proceed to a PyTorch implementation that you may use for the remainder of the course and in your projects."", '
To summarize, in this notebook we will show you:
* How to represent sequences of categorical variables
* How to build and train an RNN in NumPy
* How to build and train an LSTM network in NumPy
* How to build and train an LSTM network in PyTorch'

 
markdown:
## Representing tokens or text

In previous labs we mainly considered data $x \\in \\mathrm{R}^d$, where $d$ is the feature space dimension.
With time sequences our data can be represented as $x \\in \\mathrm{R}^{t \\, \\times \\, d}$, where $t$ is the sequence length. 
This emphasises sequence dependence and that the samples along the sequence are not independent and identically distributed (i.i.d.).
We will model functions as $\\mathrm{R}^{t \\, \\times \\, d} \\rightarrow \\mathrm{R}^c$, where $c$ is the amount of classes in the output.

There are several ways to represent sequences. With text, the challenge is how to represent a word as a feature vector in $d$ dimensions, as we are required to represent text with decimal numbers in order to apply neural networks to it.

In this exercise we will use a simple one-hot encoding but for categorical variables that can take on many values (e.g. words in the English language) this may be infeasible. For such scenarios, you can project the encodings into a smaller space by use of embeddings. If you want to learn more about tokens, encodings and embeddings than what is covered in this exercise, we highly recommend [this lecture](https://www.youtube.com/watch?v=kEMJRjEdNzM&list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z).'

 
markdown:
### One-hot encoding over vocabulary",0.7527111172676086,notebook 5_1,14.0,"# backward and optimize
            loss.backward()
            optimiser.step()
            step += 1
            pbar.update(1)

            # Report
            if step % 5 ==0 :
                loss = loss.detach().cpu()
                pbar.set_description(f""epoch={epoch}, step={step}, loss={loss:.1f}"")

            # save checkpoint
            if step % 50 ==0 :
                torch.save(rnn.state_dict(), checkpoint_file)
            if step >= num_steps:
                break
        epoch += 1'

 
code:
# sample the RNN language model
with torch.no_grad():
    sample = rnn.sample(num_steps=10, batch_size=10, temperature=0.5, prevent_repetitions=True)
    rich.print(glove_tokenizer.decode_batch(sample.detach().cpu().numpy()))'

 
code:
_ = rnn.cpu()
# free-up memory if needed: delete the RNN model
# del rnn'

 
markdown:
**Exercise 3**: What would happen if the inputs of the RNN were not shifted to the right (in sample in the RNNLM class)?  

> *Insert your answer here.*'

 
markdown:
___
## III. Attention mechanism and Transformers


The attention mechanism was first introduce in machine learning for machine translation tasks [(""Neural Machine Translation by Jointly Learning to Align and Translate"", Bahdanau et al. (2014))](https://arxiv.org/abs/1409.0473). Translation is a sequence-to-sequence problem which goal is to generate a translation of a source text. The attention mechanism was introduced to allow *attenting* the whole source text at any of the generation steps. We implement attention with the softmax function because it is a differential version of a hard zero-one attention.

In this section, we will introduce the *scaled dot-product* self-attention mechanism and the Transformer architecture [(""Attention is All You Need"", Wasrani et al. (2016))](https://arxiv.org/abs/1706.03762).

### III.a Attention mechanism

Attention has become a very important concept in deep learning beginning with [""Neural Machine Translation by Jointly Learning to Align and Translate"", Badanau et. al. (2015)](https://arxiv.org/abs/1409.0473). The idea key idea in that paper is that when you translate a sentence from for example German to English then it is a good is helpful for the model when it generates",0.7713947296142578,notebook 5_1,10.0,"**Long Short-Term Memory (LSTM) networks** A standard RNN suffers from [the vanishing gradients problem](http://neuralnetworksanddeeplearning.com/chap5.html#the_vanishing_gradient_problem) which gives challenges in saving memory over longer sequences. To combat these issues the gated hidden units were created. The two most prominent gated hidden units are the [Long Short-Term Memory (LSTM, Hochreiter and Schmidhuber. (1997))](https://dl.acm.org/doi/10.1162/neco.1997.9.8.1735) cell and the Gated Recurrent Unit (GRU), both of which have shown increased performance in saving and reusing memory in later timesteps. RNNs coupled with gated mechanisms are less prone to the problem of vanishing gradients, and can therefore model dependencies over longer number of steps.'

 
markdown:
*Figure: bi-directional recurrent neural network. We highlight the information flowing from the context ""My horse is"" to the predicted word ""very"" (left-to-right), and the information flowing from the context ""fast"" (right-to-left).*
![Recurrent Neural Network](images/bidirectional-lm-activated.png)

**Bi-directional recurrent neural networks** Using two RNNs running in reverse direction allows building bidirectional language models. The distribution $p_\\theta(\\mathbf{x}_t \\mid \\mathbf{x}_{-t})$ can be parameterized as
$$
p_\\theta( \\cdot \\mid \\mathbf{x}_{-t}) = \\mathrm{Softmax}((\\mathbf{h}^\\mathrm{forward}_t + \\mathbf{h}^\\mathrm{reverse}_t) F^T) \\ ,
$$
where the hidden state  $\\mathbf{h}^\\mathrm{bi}_t = \\mathbf{h}^\\mathrm{forward}_t + \\mathbf{h}^\\mathrm{reverse}_t$ defines hidden state contextualized on all the tokens but $\\mathbf{w}_t$. 

This is the strategy adopted by [ELMo (""Deep contextualized word representations"", Peters et al. (2018))](https://arxiv.org/abs/1802.05365), which popularized learning deep contextualized representations as a pre-training step, and at the samd time, started a [tradition of naming models after Seame Street characters](https://www.theverge.com/2019/12/11/20993407/ai-language-models-muppets-sesame-street-muppetware-elmo-bert-ernie).'

 
markdown:
**Experiment: train your own LSTM language model**
', ""> **NB:**  *training on CPU is very slow. If you don't have access to a GPU, it will be difficult to train a model that generate acceptable samples. In the end of the notebook, we will use pre-trained models directly, so feel free to skip this experiment.* **You still need to implement the loss in the training loop.**""]'

 
code:
max_dataset_size = 1000 # let's use a small subset for now,"", 'max_seq_size = 10 # and very short sequences",0.7806407809257507,CoursePlan.txt,7.0,"and take notes for at least 3 questions to ask. Link to: 2016 lectures, 2017 lecture updates and 2020 lecture updates.

    Reading material Alex Graves book, Supervised Sequence Labelling with Recurrent Neural Networks Chapters 3.1, 3.2 and 4. Browse Michael Nielsen, Neural networks and deep learning Chapter 6 section Other approaches to deep neural nets) and onwards. A good introduction to Transformers is The Illustrated Transformer. New tutorial on Transformers https://aman.ai/primers/ai/transformers/#one-hot-encoding
    Alternative textbook chapter in the deep learning book. Andrej Karpathy has a nice blogpost that gives a good flavour of the whats and hows of RNNs.
    Carry out computer exercises week 5
    Hand in and peergrade on peergrade.io like in previous week.

Week 6 - Tricks of the trade and data science challenge

    Watch week 4 video lectures 

    02456week4 1 1 Initialization and gradient clipping 
    02456week4 1 2 batch normalization
    02456week4 2 1 regularization
    02456week4 2 2 regularization methods
    02456week4 2 3 data augmentation
    02456week4 2 4 ensemble methods and dropout
    02456week4 3 recap
    2017 37 reasons your nn working (part 1 of 2) Walk through of the 37 reasons why your neural network is not working blog post.
    2017 37 reasons you not working (part 2 of 2)
    2020 Recipe to training neural networks - become one with data (part 1 of 3).
    2020 Recipe to training neural networks - baselines (part 2 of 3).
    2020 Recipe to training neural networks - overfit, tune and tune some more (part 3 of 3).

and take notes for at least 3 questions to ask. Link to lecture slides 2016 lecture slides, 2017 blog post and 2020 lecture slides.  

    Reading material Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapter 3 from section Overfitting and regularization and Chapter 5.
    Alternative textbook chapters on regularization, optimization, deep learning practice and applications from the deep learning book.  
    Additional material: Andrei Karpathy blogpost on how to approach a data science problem with deep learning, blogpost on things that can go wrong in neural network training and interactive initialization demo.
    Computer exercises week 6 using PyTorch on the Kaggle competition leaf classification. Hand in and peergrade on peergrade.io like in previous weeks.

Week 7 - Un- and semi-supervised learning

    Watch week 5 video lectures",0.7816317081451416,notebook 5_2,0.0,"markdown:
# Week 5 - Recurrent Neural Networks

In this lab, we will introduce different ways of learning from sequential data.

As a recurring example, we will train neural networks to do language modelling, i.e. predict the next token in a sentence. In the context of natural language processing a token could be a character or a word, but mind you that the concepts introduced here apply to all kinds of sequential data, such as e.g. protein sequences, weather measurements, audio signals, or videos, just to name a few.

To really get a grasp of what is going on inside a recurrent neural network (RNN), we will carry out a substantial part of this exercise in Nanograd rather than PyTorch. 
', ""We start off with a simple toy problem, build an RNN using Nanograd, train it, and see for ourselves that it really works. Once we're convinced, you will implement the Long Short-Term Memory (LSTM) cell, also in Nanograd. "", '
This is *not* simple but with the DenseLayer class we already have, it is doable. Having done it yourself will help you understand what happens under the hood of the PyTorch code we will use throughout the course.

To summarize, in this notebook we will show you:
* How to represent sequences of categorical variables
* How to build and train an RNN in Nanograd
* How to build and train an LSTM network in Nanograd
* How to build and train an LSTM network in PyTorch


[Numpy version of the Notebook (previous version)](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/5_Recurrent/OLD-5.1-Numpy-Recurrent-Neural-Networks.ipynb)'

 
markdown:
## Representing tokens or text

In previous labs we mainly considered data $x \\in \\mathbb{R}^d$, where $d$ is the feature space dimension.
With time sequences our data can be represented as $x \\in \\mathbb{R}^{t \\, \\times \\, d}$, where $t$ is the sequence length. 
This emphasises sequence dependence and that the samples along the sequence are not independent and identically distributed (i.i.d.).

With RNNs, we can model both many-to-one functions: $\\mathbb{R}^{t \\, \\times \\, d} \\rightarrow \\mathbb{R}^c$ and many-to-many functions: $\\mathbb{R}^{t \\, \\times \\, d} \\rightarrow \\mathbb{R}^{t \\, \\times \\, c}$, where $c$ is the amount of classes/output dimensions.

There are several ways to represent sequences. With text, the challenge is how to represent a word as a feature vector in $d$ dimensions, as we are required to represent text with decimal numbers in order to apply neural networks to it.",0.7981358766555786,1.0,2.0,3.0,4.0,5.0,6.0,6.0,6.0,6.0,7.0
What topics are covered in the first three weeks of the course?,". Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part I do it yourself on pen and paper. 2. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part II do it yourself in NumPy. 3. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part III PyTorch.", CourseOutline.txt,CoursePlan.txt,3.0,"Week 1 computer exercise. Deadline: Monday week 2.
    Week 2 computer exercise. Deadline: Monday week 3.
    Week 3 computer exercise and 1 exercise of your own choice from course material week 1. Deadline: Monday week 4
    Week 4 computer exercise  and 1 exercise of your own choice from course material week 1-2. Deadline: Monday week 5.
    Week 5 computer exercise. Deadline: Monday week 6.
    Week 6 computer exercise. Deadline: Monday week 7.
    Week 7 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 8
    Week 8 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 9.
    Project selection. Deadline Friday, Oct 20th 2023 at 23.59.
    Link to 2023 project selection sheet
    Project synopsis. Deadline: Monday week 9 at 23:59. The synopsis should be approximately half a page and maximum one page with a project title, motivation, background, milestones and references. It is important that the plan is realistic. The main purposes of the synopsis are to make sure the project size is well-calibrated and is concrete enough to start working from day one. The synopsis will not be used in the evaluation. The synopsis should be sent to your project supervisor.
    Project poster session. PhD students taking the course as part of their PhD will not have to make a poster and take part of the poster session. In mixed groups of PhD and non-PhD students, only the non-PhD students have to take part in the poster session. The exam date is December 7th from 9 to 17. We divide the day into half hour slots and your group will later be given the possibility to register for a slot. A link to sign up for the poster session will appear here in due time. So having another exam on the same day should not be a problem. We will also organise an extra exam date for those of you who cannot make it on the date. It will be group poster presentations. We will invite outside guests and we will walk around and ask questions to all groups. We will make a schedule for when the teachers visit your poster. Plan for a 2 minute presentation per group member and 1-2 minutes for questions. The remainder of the time you can either present your poster to other students and guests or go visit other posters. Remember that it is important for the overall impression that you divide the presentation and answering of the questions more or less equally between you. The poster should be in A1 format. Remember to put both your names and student numbers under title. Here and here are links to examples using the latex template and here is one in powerpoint. You do not have to use that. The DTU library offers poster printing for a not too high price.",0.7079682946205139,CoursePlan.txt,0.0,"02456 Deep learning 2023 - course plan and information

Time: Mondays at 13:00-17:00 (first session is August 28th, 2023)

Locations: We will use the following rooms - building/room - (Campus map):

B303A-A042

B303A-046

B303A-047

B303A-048

B303A-HOEST

Zoom (You need to sign-in with you DTU account)

We use flipped classroom teaching. During the weeks with labs, the teachers and teaching assistants will circulate between the rooms so there will be opportunity to meet all. Any short lectures/instructions will be repeated in all rooms. You are free to choose whatever room you prefer of course respecting the limits on room capacity. During the weeks with project work each room will cover specific topics.

If you are not able to be on campus or prefer to work remotely you will be able to participate through Zoom. One teaching assistant will be dedicated to the Zoom channel: Zoom.

We also use Slack for communication: We will make dedicated channels for labs and projects. Here is a Slack invite link. (In Slack you can add channels from the list of channels by clicking the “+” next to Channels in the left panel and click “Browse channels” to choose.)

Bring a laptop.

The first eight weeks of the course will be dedicated to lab work. There will be a brief introduction to the course at the first session and a number of dedicated meetings online or in person with project supervisors.

Teachers

    Ole Winther
    Jes Frellsen

Teaching assistants

    Aleksander Nagaj
    Anders Christensen
    Anna Maria Clara Schibelle
    Anshuk Uppal
    Beatrix Miranda Ginn Nielsen
    Bo Li
    Kenny Olsen
    Marco Miani
    Nina Weng
    Paul Jeha
    Pawel Tomasz Pieta
    Raul Ortega Ochoa
    Teresa Karen Scheidt
    Thea Brüsch

Google CoLab

Google CoLab is a free cloud based Jupyter notebook platform with collaboration functionality. It even has GPUs and you don't need any credits, just log in with your Google account. To start, import a notebook using a github link or upload it from your pc: https://colab.research.google.com/. Setting up is quite straightforward. If you need to install libraries you can add that in a code cell with `! pip install <library name>`. You can upload some extra files (such as additional py scripts) that your jupyter notebook will use.
Other free GPU compute resources

It might be that Google CoLab will start putting restrictions if you use it too much. But there are alternatives:
DTU HPC

Nicklas Hansen and Aleksander Nagaj and Anna Schibelle (2023 update) have made this guide.
Google cloud platform (GCP)

You can also sign up to Google cloud (GCP) and get free credits there. Here are instructions on how to set up GPU computation on Google cloud. Follow the instructions until Optional.
Topics in the first eight weeks",0.7336627244949341,CoursePlan.txt,5.0,"Detailed content

Links to individual video lectures and lecture slides are given below. Here is a link to all 2016 video lectures as a playlist and a Google doc folder with all the lecture slides. More videos have been added over the years. They are all linked below. A very good alternative video resource is Hugo Larochelle’s YouTube playlist.
Week 1 - Feed-forward neural networks - do it yourself pen and paper

    During this week and the following two weeks watch video lectures: 

    Part 0 Overview
    Part 1 Deep learning
    Part 2.1 Feed-forward neural networks
    Part 2.2 Feed-forward neural networks
    Part 3 Error Backpropagation
    Part 4 Optimization

and take notes for at least 3 questions to ask. Link to lecture slides is here.

    During this week and the following two weeks read Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapters 1-3 (stop when reaching the section called Overfitting and regularization) and browse Chapter 4. Note that this is reading material for the first three weeks of the course. Also, in total six exercises of your own choice will be homework later in the course.
    Alternative textbooks: All topics are also covered in the deep learning book that may be read as a supplement. The book can also be bought from the DTU bookstore. You will get 10% discount with this link. Feed-forward neural networks are covered in this chapter. Chapter 1 gives an introduction to deep learning and Part II gives the necessary background on linear algebra, probability, numerical computation and machine learning. Alternative textbook 2: Chris Bishop, Pattern recognition and machine learning. If you need to up your game in mathematics, the book Mathematics for machine learning is an excellent resource and the note Mathematics for Machine Learning offers a concise and compressed collection of the mathematical concepts used in deep learning. These resources are freely available online and are very valuable sources of information.
    Install software on your laptop or go directly to Google CoLab (see above). Installation guide for laptop and cloud may be found here.
    Carry out computer exercises week 1. It is encouraged to work together with other students. Type in everything yourself. Code answers are fine not to differ much within the group and text answers should be in your own words. Note that the computer exercises may experience minor change up to 3 days before the actual session. The hand-in is the notebook with your modifications. It is only allowed to hand in .ipynb files. Each week you should only hand in one file. It is the file with EXE in its name. You hand in on peergrade.io. In order to be able to hand in on peergrade you can use this invitation link https://app.peergrade.io/join/JFFJBF or login into peergrade and use the invitation code JFFJBF. There you will receive information on handing in exercises and deadlines for activities. Some students have previously by accident signed up twice with different emails or forgotten the “student” in their DTU student mail address. If you then submit and check with different email addresses it will look as though you have not handed in.
    Peergrade exercise from three other students through peergrade.io. 

Week 2 - Feed-forward neural networks - do it yourself in NumPy",0.7731426954269409,LearningObjectives.txt,0.0,"Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.

Understand and explain the choices and limitations of a model for a given setting.

Apply and analyze results from deep learning models in exercises and own project work.

Plan, delimit and carry out an applied or methods-oriented project in collaboration with fellow students and project supervisor.

Assess and summarize the project results in relation to aims, methods and available data.

Carry out the project and interpret results by use of computational framework for GPU programming such as PyTorch.

Structure and write a final short technical report including problem formulation, description of methods, experiments, evaluation and conclusion.

Organize and present project results at the final project presentation and in report.

Read, evaluate and give feedback to work of other students.",0.7997888922691345,CoursePlan.txt,7.0,"and take notes for at least 3 questions to ask. Link to: 2016 lectures, 2017 lecture updates and 2020 lecture updates.

    Reading material Alex Graves book, Supervised Sequence Labelling with Recurrent Neural Networks Chapters 3.1, 3.2 and 4. Browse Michael Nielsen, Neural networks and deep learning Chapter 6 section Other approaches to deep neural nets) and onwards. A good introduction to Transformers is The Illustrated Transformer. New tutorial on Transformers https://aman.ai/primers/ai/transformers/#one-hot-encoding
    Alternative textbook chapter in the deep learning book. Andrej Karpathy has a nice blogpost that gives a good flavour of the whats and hows of RNNs.
    Carry out computer exercises week 5
    Hand in and peergrade on peergrade.io like in previous week.

Week 6 - Tricks of the trade and data science challenge

    Watch week 4 video lectures 

    02456week4 1 1 Initialization and gradient clipping 
    02456week4 1 2 batch normalization
    02456week4 2 1 regularization
    02456week4 2 2 regularization methods
    02456week4 2 3 data augmentation
    02456week4 2 4 ensemble methods and dropout
    02456week4 3 recap
    2017 37 reasons your nn working (part 1 of 2) Walk through of the 37 reasons why your neural network is not working blog post.
    2017 37 reasons you not working (part 2 of 2)
    2020 Recipe to training neural networks - become one with data (part 1 of 3).
    2020 Recipe to training neural networks - baselines (part 2 of 3).
    2020 Recipe to training neural networks - overfit, tune and tune some more (part 3 of 3).

and take notes for at least 3 questions to ask. Link to lecture slides 2016 lecture slides, 2017 blog post and 2020 lecture slides.  

    Reading material Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapter 3 from section Overfitting and regularization and Chapter 5.
    Alternative textbook chapters on regularization, optimization, deep learning practice and applications from the deep learning book.  
    Additional material: Andrei Karpathy blogpost on how to approach a data science problem with deep learning, blogpost on things that can go wrong in neural network training and interactive initialization demo.
    Computer exercises week 6 using PyTorch on the Kaggle competition leaf classification. Hand in and peergrade on peergrade.io like in previous weeks.

Week 7 - Un- and semi-supervised learning

    Watch week 5 video lectures",0.8040153980255127,CoursePlan.txt,4.0,"Final report deadline December 21st at 23:59. [Note this was earlier set to a later date but according to DTU rules, the latest allowed deadline is December 21st.] The report should be a maximum 6 pages plus references using this conference paper format. The report should also contain a link to your project code Github repository. Among the files in the repository should be a jupyter notebook that ideally should recreate the main results of your report. If some of your data is confidential then use some shareable data instead. For MSc students, please also include your poster in the submission.",0.8208600282669067,CoursePlan.txt,2.0,"Handing in and peer grading six of the eight labs reports is required for being able to execute the project and eventually pass the course. If a hand-in is not passed you will be contacted with the option of re-submitting the lab directly to the teacher so if you hear nothing assume that you have passed the lab. You can also contact the teacher directly on Slack if something went wrong with the submission of the lab. Peergrade deadlines are strict so no need to write about getting an extension.

The following reports should be handed in jupyter notebook format. The weeks refer to weeks in term, and the fall break week is not counted.",0.8321106433868408,CoursePlan.txt,6.0,"Week 2 - Feed-forward neural networks - do it yourself in NumPy

    See 1. and 2. from Week 1.
    Carry out computer exercises week 2.
    Peergrade exercise from three other students through peergrade.io. 

Week 3 - Feed-forward neural networks in PyTorch

    See 1. and 2. from Week 1.
    Carry out computer exercises week 3.
    Peergrade exercise from three other students through peergrade.io.
    Hand in the notebook marked with EXE on peergrade.io. It should contain your added code in the exercises and the answer of one exercise from Michael Nielsen's book (see point 3. above). The answer to the book exercise should be in a markdown cell at the bottom of the notebook.
    Peergrade exercise from three other students through peergrade.io.  

Week 4 - Convolutional neural networks

    Watch week 2 video lectures  

    Part 1 Introduction to CNNs (PART 1/2)
    Part 1 Introduction to CNNs (PART 2/2)
    Part 2 CNNs the details (PART 1/2)
    Part 2 CNNs the details (PART 2/2)
    2017 CNN update
    2017 Activation functions update
    2017 Image segmentation

and take notes for at least 3 questions to ask. Link to lecture slides is here and here for 2017 updates.

    Reading material Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapter 6 (stop when reaching section called Other approaches to deep neural nets).
    Alternative textbook chapter in the deep learning book.
    One exercise from the book chapters.
    Carry out computer exercises week 4.
    Hand in the notebook marked with EXE on peergrade.io.
    Peergrade exercise from three other students through peergrade.io. You will receive instructions about this from peergrade.io.

Week 5 - Transformers and recurrent neural networks

    Watch week 3 video lectures

    02456week3 1 RNN (PART 1 of 3)
    02456week3 1 RNN (PART 2 of 3)
    02456week3 1 RNN (PART 3 of 3)
    02456week3.2_RNN_training (PART 1 of 3)
    02456week3.2_RNN_training (PART 2 of 3)
    02456week3 2 RNN training (PART 3 of 3)
    02456week3 3 Attention (PART 1 of 2)
    02456week3 3 Attention (PART 2 of 2)
    02456week3 4 Supervised learning recap
    2017 Quasi RNN
    2017 Non-recurrent sequence to sequence models
    2017 Text summarization
    2020 Transformers (PART 1 of 2)
    2020 Transformers (PART 2 of 2)
    2020 Language modelling - GPT-2 and 3
    2020 BERT

and take notes for at least 3 questions to ask. Link to: 2016 lectures, 2017 lecture updates and 2020 lecture updates.",0.8469802141189575,CoursePlan.txt,8.0,"Week 7 - Un- and semi-supervised learning

    Watch week 5 video lectures

    02456week5 1 1 unsupervised learning
    02456week5 1 2 unsupervised learning latent variables
    02456week5 2 1 autoencoders
    02456week5 2 2 autoencoders layerwise pretraining
    02456week5 3 1 variational autoencoders
    02456week5 3 2 semi-supervised variational autoencoders 
    2017 Generative adversarial networks
    2020 Flows
    2020 Self-supervised learning
    2020 Self-training/noisy student
    2020 Distribution Augmentation
    2020 Flat minima

and take notes for at least 3 questions to ask. Link to lecture slides 2016 slides and 2017 slides and 2020 slides.

    Reading material DL Chapter 14 and 20.10.3. (Further learning a course dedicated to generative modelling.)
    One exercise from the book chapters.
    Carry out computer exercises week 7 on autoencoder un- and semi-supervised. Hand in and peergrade on peergrade.io like in previous weeks.
    Project selection deadline is this week (see above).

Week 8 - Reinforcement learning 

    Watch week 6 video lectures 

    02456week6 1 1 reinforcement learning
    02456week6 1 2 reinforcement learning approaches
    02456week6 2 1 AlphaGo policy and value networks
    02456week6 2 2 AlphaGo steps 1 to 4
    02456week6 3 policy gradients
    02456week6 4 a few last words
    2017 Deep Q learning
    2017 Evolutionary strategies

and take notes for at least 3 questions to ask. Link to lectures here and here for 2017 update.

    Reading: another nice blog post by Andrei Karpathy. Optional reading material on the connection between variational and reinforcement learning.
    One exercise from the book chapters. 
    Computer exercises on reinforcement learning methods (policy gradient, deep Q learning, evolutionary strategies) in the openAI Gym. Carry out exercises week 8. Hand in and peergrade on peergrade.io like in previous weeks.
    Project work.",0.8533527851104736,notebook 5_2,0.0,"markdown:
# Week 5 - Recurrent Neural Networks

In this lab, we will introduce different ways of learning from sequential data.

As a recurring example, we will train neural networks to do language modelling, i.e. predict the next token in a sentence. In the context of natural language processing a token could be a character or a word, but mind you that the concepts introduced here apply to all kinds of sequential data, such as e.g. protein sequences, weather measurements, audio signals, or videos, just to name a few.

To really get a grasp of what is going on inside a recurrent neural network (RNN), we will carry out a substantial part of this exercise in Nanograd rather than PyTorch. 
', ""We start off with a simple toy problem, build an RNN using Nanograd, train it, and see for ourselves that it really works. Once we're convinced, you will implement the Long Short-Term Memory (LSTM) cell, also in Nanograd. "", '
This is *not* simple but with the DenseLayer class we already have, it is doable. Having done it yourself will help you understand what happens under the hood of the PyTorch code we will use throughout the course.

To summarize, in this notebook we will show you:
* How to represent sequences of categorical variables
* How to build and train an RNN in Nanograd
* How to build and train an LSTM network in Nanograd
* How to build and train an LSTM network in PyTorch


[Numpy version of the Notebook (previous version)](https://github.com/DeepLearningDTU/02456-deep-learning-with-PyTorch/blob/master/5_Recurrent/OLD-5.1-Numpy-Recurrent-Neural-Networks.ipynb)'

 
markdown:
## Representing tokens or text

In previous labs we mainly considered data $x \\in \\mathbb{R}^d$, where $d$ is the feature space dimension.
With time sequences our data can be represented as $x \\in \\mathbb{R}^{t \\, \\times \\, d}$, where $t$ is the sequence length. 
This emphasises sequence dependence and that the samples along the sequence are not independent and identically distributed (i.i.d.).

With RNNs, we can model both many-to-one functions: $\\mathbb{R}^{t \\, \\times \\, d} \\rightarrow \\mathbb{R}^c$ and many-to-many functions: $\\mathbb{R}^{t \\, \\times \\, d} \\rightarrow \\mathbb{R}^{t \\, \\times \\, c}$, where $c$ is the amount of classes/output dimensions.

There are several ways to represent sequences. With text, the challenge is how to represent a word as a feature vector in $d$ dimensions, as we are required to represent text with decimal numbers in order to apply neural networks to it.",0.8742350339889526,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
When does project work start?,Starting from week 6 and full time from week 9 and the rest of the term will be spent on tutored project work., CourseOutline.txt,CoursePlan.txt,3.0,"Week 1 computer exercise. Deadline: Monday week 2.
    Week 2 computer exercise. Deadline: Monday week 3.
    Week 3 computer exercise and 1 exercise of your own choice from course material week 1. Deadline: Monday week 4
    Week 4 computer exercise  and 1 exercise of your own choice from course material week 1-2. Deadline: Monday week 5.
    Week 5 computer exercise. Deadline: Monday week 6.
    Week 6 computer exercise. Deadline: Monday week 7.
    Week 7 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 8
    Week 8 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 9.
    Project selection. Deadline Friday, Oct 20th 2023 at 23.59.
    Link to 2023 project selection sheet
    Project synopsis. Deadline: Monday week 9 at 23:59. The synopsis should be approximately half a page and maximum one page with a project title, motivation, background, milestones and references. It is important that the plan is realistic. The main purposes of the synopsis are to make sure the project size is well-calibrated and is concrete enough to start working from day one. The synopsis will not be used in the evaluation. The synopsis should be sent to your project supervisor.
    Project poster session. PhD students taking the course as part of their PhD will not have to make a poster and take part of the poster session. In mixed groups of PhD and non-PhD students, only the non-PhD students have to take part in the poster session. The exam date is December 7th from 9 to 17. We divide the day into half hour slots and your group will later be given the possibility to register for a slot. A link to sign up for the poster session will appear here in due time. So having another exam on the same day should not be a problem. We will also organise an extra exam date for those of you who cannot make it on the date. It will be group poster presentations. We will invite outside guests and we will walk around and ask questions to all groups. We will make a schedule for when the teachers visit your poster. Plan for a 2 minute presentation per group member and 1-2 minutes for questions. The remainder of the time you can either present your poster to other students and guests or go visit other posters. Remember that it is important for the overall impression that you divide the presentation and answering of the questions more or less equally between you. The poster should be in A1 format. Remember to put both your names and student numbers under title. Here and here are links to examples using the latex template and here is one in powerpoint. You do not have to use that. The DTU library offers poster printing for a not too high price.",0.8024184107780457,CoursePlan.txt,4.0,"Final report deadline December 21st at 23:59. [Note this was earlier set to a later date but according to DTU rules, the latest allowed deadline is December 21st.] The report should be a maximum 6 pages plus references using this conference paper format. The report should also contain a link to your project code Github repository. Among the files in the repository should be a jupyter notebook that ideally should recreate the main results of your report. If some of your data is confidential then use some shareable data instead. For MSc students, please also include your poster in the submission.",0.808994710445404,LearningObjectives.txt,0.0,"Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.

Understand and explain the choices and limitations of a model for a given setting.

Apply and analyze results from deep learning models in exercises and own project work.

Plan, delimit and carry out an applied or methods-oriented project in collaboration with fellow students and project supervisor.

Assess and summarize the project results in relation to aims, methods and available data.

Carry out the project and interpret results by use of computational framework for GPU programming such as PyTorch.

Structure and write a final short technical report including problem formulation, description of methods, experiments, evaluation and conclusion.

Organize and present project results at the final project presentation and in report.

Read, evaluate and give feedback to work of other students.",0.8135966062545776,CoursePlan.txt,2.0,"Handing in and peer grading six of the eight labs reports is required for being able to execute the project and eventually pass the course. If a hand-in is not passed you will be contacted with the option of re-submitting the lab directly to the teacher so if you hear nothing assume that you have passed the lab. You can also contact the teacher directly on Slack if something went wrong with the submission of the lab. Peergrade deadlines are strict so no need to write about getting an extension.

The following reports should be handed in jupyter notebook format. The weeks refer to weeks in term, and the fall break week is not counted.",0.8629888892173767,notebook 8_2_Prerequisites_ipynb,1.0,"# Run environment
while True:
    action = env.action_space.sample() # Get a random action
    _, _, done, _ = env.step(action) # Take a step
    if done: break # Break if environment is done

env.close() # Close environment
env.play() # Show the video'

 
markdown:
Hooray! You now have a working `Gym` environment that we can take actions in and render.'",0.8657190799713135,CoursePlan.txt,0.0,"02456 Deep learning 2023 - course plan and information

Time: Mondays at 13:00-17:00 (first session is August 28th, 2023)

Locations: We will use the following rooms - building/room - (Campus map):

B303A-A042

B303A-046

B303A-047

B303A-048

B303A-HOEST

Zoom (You need to sign-in with you DTU account)

We use flipped classroom teaching. During the weeks with labs, the teachers and teaching assistants will circulate between the rooms so there will be opportunity to meet all. Any short lectures/instructions will be repeated in all rooms. You are free to choose whatever room you prefer of course respecting the limits on room capacity. During the weeks with project work each room will cover specific topics.

If you are not able to be on campus or prefer to work remotely you will be able to participate through Zoom. One teaching assistant will be dedicated to the Zoom channel: Zoom.

We also use Slack for communication: We will make dedicated channels for labs and projects. Here is a Slack invite link. (In Slack you can add channels from the list of channels by clicking the “+” next to Channels in the left panel and click “Browse channels” to choose.)

Bring a laptop.

The first eight weeks of the course will be dedicated to lab work. There will be a brief introduction to the course at the first session and a number of dedicated meetings online or in person with project supervisors.

Teachers

    Ole Winther
    Jes Frellsen

Teaching assistants

    Aleksander Nagaj
    Anders Christensen
    Anna Maria Clara Schibelle
    Anshuk Uppal
    Beatrix Miranda Ginn Nielsen
    Bo Li
    Kenny Olsen
    Marco Miani
    Nina Weng
    Paul Jeha
    Pawel Tomasz Pieta
    Raul Ortega Ochoa
    Teresa Karen Scheidt
    Thea Brüsch

Google CoLab

Google CoLab is a free cloud based Jupyter notebook platform with collaboration functionality. It even has GPUs and you don't need any credits, just log in with your Google account. To start, import a notebook using a github link or upload it from your pc: https://colab.research.google.com/. Setting up is quite straightforward. If you need to install libraries you can add that in a code cell with `! pip install <library name>`. You can upload some extra files (such as additional py scripts) that your jupyter notebook will use.
Other free GPU compute resources

It might be that Google CoLab will start putting restrictions if you use it too much. But there are alternatives:
DTU HPC

Nicklas Hansen and Aleksander Nagaj and Anna Schibelle (2023 update) have made this guide.
Google cloud platform (GCP)

You can also sign up to Google cloud (GCP) and get free credits there. Here are instructions on how to set up GPU computation on Google cloud. Follow the instructions until Optional.
Topics in the first eight weeks",0.9050700664520264,notebook 8_3,3.0,"# setup policy network

policy = PolicyNet(n_inputs, n_hidden, n_outputs, learning_rate)

# train policy network

try:
    training_rewards, losses = [], []', ""    print('start training')"", '    for i in range(num_episodes):
        rollout = []
        s = env.reset()
        for j in range(rollout_limit):
            # generate rollout by iteratively evaluating the current policy on the environment
            with torch.no_grad():
                a_prob = policy(torch.from_numpy(np.atleast_2d(s)).float())
                a = torch.multinomial(a_prob, num_samples=1).squeeze().numpy()
            s1, r, done, _ = env.step(a)
            rollout.append((s, a, r))
            s = s1
            if done: break
        # prepare batch
        rollout = np.array(rollout)
        states = np.vstack(rollout[:,0])
        actions = np.vstack(rollout[:,1])
        rewards = np.array(rollout[:,2], dtype=float)
        returns = compute_returns(rewards, discount_factor)
        # policy gradient update
        policy.optimizer.zero_grad()
        a_probs = policy(torch.from_numpy(states).float()).gather(1, torch.from_numpy(actions)).view(-1)
        loss = policy.loss(a_probs, torch.from_numpy(returns).float())
        loss.backward()
        policy.optimizer.step()
        # bookkeeping
        training_rewards.append(sum(rewards))
        losses.append(loss.item())
        # print
        if (i+1) % val_freq == 0:
            # validation
            validation_rewards = []
            for _ in range(10):
                s = env.reset()
                reward = 0
                for _ in range(rollout_limit):
                    with torch.no_grad():
                        a_prob = policy(torch.from_numpy(np.atleast_2d(s)).float())
                        a = a_prob.argmax().item()
                    s, r, done, _ = env.step(a)
                    reward += r
                    if done: break
                validation_rewards.append(reward)', ""            print('{:4d}. mean training reward: {:6.2f}, mean validation reward: {:6.2f}, mean loss: {:7.4f}'.format(i+1, np.mean(training_rewards[-val_freq:]), np.mean(validation_rewards), np.mean(losses[-val_freq:])))"", ""    print('done')"", 'except KeyboardInterrupt:', ""    print('interrupt')    ""]'

 
code:
# plot results
def moving_average(a, n=10) :
    ret = np.cumsum(a, dtype=float)
    ret[n:] = ret[n:] - ret[:-n]
    return ret / n",0.9396036863327026,CoursePlan.txt,1.0,"You can also sign up to Google cloud (GCP) and get free credits there. Here are instructions on how to set up GPU computation on Google cloud. Follow the instructions until Optional.
Topics in the first eight weeks

    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part I do it yourself on pen and paper.
    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part II do it yourself in Python.
    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part III PyTorch.
    Convolutional neural networks (CNN)
    Transformers and recurrent neural networks (RNN)
    Tricks of the trade and data science with PyTorch
    Variational learning and generative adversarial networks for unsupervised and semi-supervised learning + deadline for selection of student projects on Friday, Oct 13th 2023 at 23.59.
    Reinforcement learning - policy gradient and deep Q-learning + start of student projects. 

Week 9-13 will be only project work

In the seven project weeks we will still meet on Mondays for project work and supervision.
Evaluation and peer grading during the course

​​Evaluation:

    The course is graded using the 7-step scale.
    The final grade is based solely on the evaluation of the final project, which starts in the 7th week of the course. The project group should consist of 3-4 students. In special circumstances we can also accept groups of 1 or 2 students. (In the course catalogue it says 1-3 students. We will correct that for next year but cannot change it now.)
    The evaluation of the final project is based on two parts, both of which are done in groups but evaluated individually:

    a poster exam presentation, where the project groups document the results of their project in a poster and present to two or more teachers acting as examiners and
    a report in which the project groups document their solution. The report should be a maximum of 6 pages plus references using this conference paper format.

More details are given below.

    The student gains access to the final project by passing 6 out of 8 lab sessions that precede it.
    A lab session is passed by:

    grading the reports from lab sessions of 3 other students on Peergrade and
    passing the lab as judged by the teacher. More details given below.

More details on peer grading: The 8 lab sessions are evaluated using peer grading. We use peer grading to ensure more accurate evaluation and better feedback. Graders get 3 reports at each deadline and have one week to carry out the feedback. If you forget to perform your peer grading it is not nice to your fellow students, but you can still pass that lab for which you forgot to grade.",0.9543881416320801,notebook 5_1,12.0,"# project the hidden state to the vocabulary space
        logits = self.proj(hidden_states)
        return logits

    def sample(
            self,
            batch_size:int=1,
            num_steps:int=10,
            temperature: float=1.0,
            prevent_repetitions: bool=False
        ):
        token_ids = torch.empty((batch_size, 0), device=self.embeddings.weight.device, dtype=torch.long)
        for t in tqdm(range(num_steps), desc=f""Sampling {num_steps} steps..""):
            logits = self.forward(token_ids)
            logits_t = logits[:, -1:] / temperature
            if prevent_repetitions and t > 0:
                # mask the last generated tokens to avoid repetitions
                logits_t.scatter_(index=token_ids[:,-1:, None], dim=2, value=-math.inf)
            p_wt = torch.distributions.Categorical(logits=logits_t)
            tokens_t = p_wt.sample()
            token_ids = torch.cat([token_ids, tokens_t], dim=1)
        return token_ids


# init RNN initialized from GloVe vectors
# delete the checkpoint if you get `PytorchStreamReader` error
checkpoint_file = Path(""rrn-lm.ckpt"")
rnn = RNNLM(glove_vectors)
if checkpoint_file.exists():
    # checkpoint_file.unlink() # delete the checkpoint by un-commenting this line
    rnn.load_state_dict(torch.load(checkpoint_file, map_location=""cpu""))'

 
markdown:
**Testing** Let's make sure the autoregressive constrains are enforced ($\\mathbf{h}_t$ only depends on $\\mathbf{w}_{<t}$). We take differentiate a loss that depends only on a step $t = t'$ for each element $t'$ of the input batch and visualize the gradients with regards to the input word vectors (right after the embedding layers) $\\mathbf{w}_{1:T}$. The gradient map tells use which input positions are influencing the differentiated output position.""]'

 
code:
# Test whether the autoregressive constrains (h_t only depends on w_{<t}) is enforced
rnn.zero_grad()
# get dummy token ids
token_ids = torch.arange(0, 10)
token_ids = token_ids[None].repeat(10, 1)
# run through the RNN
logits = rnn(token_ids, retain_ws=True)

# compute a loss for a which depends only on step `t=i`
loss_locations = torch.arange(0, 10)[:, None, None].expand(10, 1, logits.shape[-1])
loss = logits.gather(index=loss_locations, dim=1).mean()

# backward pass and retrieve the gradients with respect to the word vectors w_{1:T}
loss.backward()
grad_magnitude = rnn.ws.grad.norm(dim=2)
rnn.ws = None",0.9633152484893799,notebook 4_1,2.0,"code:
# Load the MNIST data. 

# Note that we reshape the data from:
#   (nsamples, num_features) = (nsamples, channels * height * width)
# to:
#   (nsamples, channels, height, width)
# in order to retain the spatial arrangements of the pixels.
', ""data = np.load('mnist.npz')"", 'channels, height, width = 1, 28, 28


def get_data(split, size):
    x = data[f""X_{split}""][:size].astype(\'float32\')
    x = x.reshape((-1, channels, height, width))
    targets = data[f""y_{split}""][:size].astype(\'int64\')
    return torch.from_numpy(x), torch.from_numpy(targets)

', ""x_train, targets_train = get_data('train', 50000)"", ""x_valid, targets_valid = get_data('valid', 2000)"", ""x_test, targets_test = get_data('test', 5000)"", '
num_classes = len(np.unique(targets_train))

print(""Information on dataset"")
print(""Shape of x_train:"", x_train.shape)
print(""Shape of targets_train:"", targets_train.shape)
print(""Shape of x_valid:"", x_valid.shape)
print(""Shape of targets_valid:"", targets_valid.shape)
print(""Shape of x_test:"", x_test.shape)
print(""Shape of targets_test:"", targets_test.shape)'

 
code:
# Plot a few MNIST examples
plt.figure(figsize=(7, 7))
plt.imshow(make_grid(x_train[:100], nrow=10).permute(1, 2, 0))', ""plt.axis('off')"", 'plt.show()'

 
markdown:
# Define a simple feed forward neural network'

 
code:
assert (channels, height, width) == x_train.shape[1:]
n_features = channels * height * width


class PrintSize(nn.Module):
    """"""Utility module to print current shape of a Tensor in Sequential, only at the first forward pass.""""""
    
    first = True
    
    def forward(self, x):
        if self.first:
            print(f""Size: {x.size()}"")
            self.first = False
        return x


class Model(nn.Module):

    def __init__(self):
        super(Model, self).__init__()
        activation_fn = nn.ReLU

        self.net = nn.Sequential(
            nn.Flatten(),  # from (1, channels, height, width) to (1, channels * height * width)
            nn.Linear(n_features, 128),
            activation_fn(),
            nn.Linear(128, 128),
            activation_fn(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.net(x)


model = Model()
print(model)

loss_fn = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)'

 
code:
# Test the forward pass with dummy data
out = model(torch.randn(2, 1, 28, 28))
print(""Output shape:"", out.size())
print(f""Output logits:\{out.detach().numpy()}"")
print(f""Output probabilities:\{out.softmax(1).detach().numpy()}"")'

 
markdown:
# Train network'",0.9654374122619629,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0
How are students expected to communicate and evaluate their project work?,"Organize and present project results at the final project presentation and in report. Read, evaluate and give feedback to work of other students", LearningObjectives.txt,LearningObjectives.txt,0.0,"Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.

Understand and explain the choices and limitations of a model for a given setting.

Apply and analyze results from deep learning models in exercises and own project work.

Plan, delimit and carry out an applied or methods-oriented project in collaboration with fellow students and project supervisor.

Assess and summarize the project results in relation to aims, methods and available data.

Carry out the project and interpret results by use of computational framework for GPU programming such as PyTorch.

Structure and write a final short technical report including problem formulation, description of methods, experiments, evaluation and conclusion.

Organize and present project results at the final project presentation and in report.

Read, evaluate and give feedback to work of other students.",0.6326117515563965,CoursePlan.txt,2.0,"Handing in and peer grading six of the eight labs reports is required for being able to execute the project and eventually pass the course. If a hand-in is not passed you will be contacted with the option of re-submitting the lab directly to the teacher so if you hear nothing assume that you have passed the lab. You can also contact the teacher directly on Slack if something went wrong with the submission of the lab. Peergrade deadlines are strict so no need to write about getting an extension.

The following reports should be handed in jupyter notebook format. The weeks refer to weeks in term, and the fall break week is not counted.",0.7124963998794556,CoursePlan.txt,3.0,"Week 1 computer exercise. Deadline: Monday week 2.
    Week 2 computer exercise. Deadline: Monday week 3.
    Week 3 computer exercise and 1 exercise of your own choice from course material week 1. Deadline: Monday week 4
    Week 4 computer exercise  and 1 exercise of your own choice from course material week 1-2. Deadline: Monday week 5.
    Week 5 computer exercise. Deadline: Monday week 6.
    Week 6 computer exercise. Deadline: Monday week 7.
    Week 7 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 8
    Week 8 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 9.
    Project selection. Deadline Friday, Oct 20th 2023 at 23.59.
    Link to 2023 project selection sheet
    Project synopsis. Deadline: Monday week 9 at 23:59. The synopsis should be approximately half a page and maximum one page with a project title, motivation, background, milestones and references. It is important that the plan is realistic. The main purposes of the synopsis are to make sure the project size is well-calibrated and is concrete enough to start working from day one. The synopsis will not be used in the evaluation. The synopsis should be sent to your project supervisor.
    Project poster session. PhD students taking the course as part of their PhD will not have to make a poster and take part of the poster session. In mixed groups of PhD and non-PhD students, only the non-PhD students have to take part in the poster session. The exam date is December 7th from 9 to 17. We divide the day into half hour slots and your group will later be given the possibility to register for a slot. A link to sign up for the poster session will appear here in due time. So having another exam on the same day should not be a problem. We will also organise an extra exam date for those of you who cannot make it on the date. It will be group poster presentations. We will invite outside guests and we will walk around and ask questions to all groups. We will make a schedule for when the teachers visit your poster. Plan for a 2 minute presentation per group member and 1-2 minutes for questions. The remainder of the time you can either present your poster to other students and guests or go visit other posters. Remember that it is important for the overall impression that you divide the presentation and answering of the questions more or less equally between you. The poster should be in A1 format. Remember to put both your names and student numbers under title. Here and here are links to examples using the latex template and here is one in powerpoint. You do not have to use that. The DTU library offers poster printing for a not too high price.",0.7887870073318481,CoursePlan.txt,1.0,"You can also sign up to Google cloud (GCP) and get free credits there. Here are instructions on how to set up GPU computation on Google cloud. Follow the instructions until Optional.
Topics in the first eight weeks

    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part I do it yourself on pen and paper.
    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part II do it yourself in Python.
    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part III PyTorch.
    Convolutional neural networks (CNN)
    Transformers and recurrent neural networks (RNN)
    Tricks of the trade and data science with PyTorch
    Variational learning and generative adversarial networks for unsupervised and semi-supervised learning + deadline for selection of student projects on Friday, Oct 13th 2023 at 23.59.
    Reinforcement learning - policy gradient and deep Q-learning + start of student projects. 

Week 9-13 will be only project work

In the seven project weeks we will still meet on Mondays for project work and supervision.
Evaluation and peer grading during the course

​​Evaluation:

    The course is graded using the 7-step scale.
    The final grade is based solely on the evaluation of the final project, which starts in the 7th week of the course. The project group should consist of 3-4 students. In special circumstances we can also accept groups of 1 or 2 students. (In the course catalogue it says 1-3 students. We will correct that for next year but cannot change it now.)
    The evaluation of the final project is based on two parts, both of which are done in groups but evaluated individually:

    a poster exam presentation, where the project groups document the results of their project in a poster and present to two or more teachers acting as examiners and
    a report in which the project groups document their solution. The report should be a maximum of 6 pages plus references using this conference paper format.

More details are given below.

    The student gains access to the final project by passing 6 out of 8 lab sessions that precede it.
    A lab session is passed by:

    grading the reports from lab sessions of 3 other students on Peergrade and
    passing the lab as judged by the teacher. More details given below.

More details on peer grading: The 8 lab sessions are evaluated using peer grading. We use peer grading to ensure more accurate evaluation and better feedback. Graders get 3 reports at each deadline and have one week to carry out the feedback. If you forget to perform your peer grading it is not nice to your fellow students, but you can still pass that lab for which you forgot to grade.",0.8177725076675415,CoursePlan.txt,4.0,"Final report deadline December 21st at 23:59. [Note this was earlier set to a later date but according to DTU rules, the latest allowed deadline is December 21st.] The report should be a maximum 6 pages plus references using this conference paper format. The report should also contain a link to your project code Github repository. Among the files in the repository should be a jupyter notebook that ideally should recreate the main results of your report. If some of your data is confidential then use some shareable data instead. For MSc students, please also include your poster in the submission.",0.892407238483429,CoursePlan.txt,0.0,"02456 Deep learning 2023 - course plan and information

Time: Mondays at 13:00-17:00 (first session is August 28th, 2023)

Locations: We will use the following rooms - building/room - (Campus map):

B303A-A042

B303A-046

B303A-047

B303A-048

B303A-HOEST

Zoom (You need to sign-in with you DTU account)

We use flipped classroom teaching. During the weeks with labs, the teachers and teaching assistants will circulate between the rooms so there will be opportunity to meet all. Any short lectures/instructions will be repeated in all rooms. You are free to choose whatever room you prefer of course respecting the limits on room capacity. During the weeks with project work each room will cover specific topics.

If you are not able to be on campus or prefer to work remotely you will be able to participate through Zoom. One teaching assistant will be dedicated to the Zoom channel: Zoom.

We also use Slack for communication: We will make dedicated channels for labs and projects. Here is a Slack invite link. (In Slack you can add channels from the list of channels by clicking the “+” next to Channels in the left panel and click “Browse channels” to choose.)

Bring a laptop.

The first eight weeks of the course will be dedicated to lab work. There will be a brief introduction to the course at the first session and a number of dedicated meetings online or in person with project supervisors.

Teachers

    Ole Winther
    Jes Frellsen

Teaching assistants

    Aleksander Nagaj
    Anders Christensen
    Anna Maria Clara Schibelle
    Anshuk Uppal
    Beatrix Miranda Ginn Nielsen
    Bo Li
    Kenny Olsen
    Marco Miani
    Nina Weng
    Paul Jeha
    Pawel Tomasz Pieta
    Raul Ortega Ochoa
    Teresa Karen Scheidt
    Thea Brüsch

Google CoLab

Google CoLab is a free cloud based Jupyter notebook platform with collaboration functionality. It even has GPUs and you don't need any credits, just log in with your Google account. To start, import a notebook using a github link or upload it from your pc: https://colab.research.google.com/. Setting up is quite straightforward. If you need to install libraries you can add that in a code cell with `! pip install <library name>`. You can upload some extra files (such as additional py scripts) that your jupyter notebook will use.
Other free GPU compute resources

It might be that Google CoLab will start putting restrictions if you use it too much. But there are alternatives:
DTU HPC

Nicklas Hansen and Aleksander Nagaj and Anna Schibelle (2023 update) have made this guide.
Google cloud platform (GCP)

You can also sign up to Google cloud (GCP) and get free credits there. Here are instructions on how to set up GPU computation on Google cloud. Follow the instructions until Optional.
Topics in the first eight weeks",0.8963309526443481,notebook 4_2,3.0,"test_accuracy = np.sum(test_accuracies) / len(test_set)
    
    model.train()'

 
markdown:
Here we report the **average test accuracy** (number of correct predictions divided by test set size).'

 
code:
print(f""Test accuracy: {test_accuracy:.3f}"")'

 
markdown:
Here we look a bit more in depth into the performance of the classifier, using the **confusion matrix**. The entry at the i-th row and j-th column indicates the number of samples with true label being the i-th class and predicted label being the j-th class.

We normalize the rows: given all examples of a specific class (row), we can observe here how they are classified by our model. Ideally, we would like the entries on the diagonals to be 1, and everything else 0. This would mean that all examples from that class are classified correctly.

The classes that are harder to classify for our model have lower numbers on the diagonal. We can then see exactly *how* they are misclassified by looking at the rest of the row.'

 
code:
def normalize(matrix, axis):', ""    axis = {'true': 1, 'pred': 0}[axis]"", '    return matrix / matrix.sum(axis=axis, keepdims=True)

x_labels = [classes[i] for i in classes]
y_labels = x_labels
plt.figure(figsize=(6, 6))
sns.heatmap(
    ax=plt.gca(),', ""    data=normalize(confusion_matrix, 'true'),"", '    annot=True,
    linewidths=0.5,
    cmap=""Reds"",
    cbar=False,
    fmt="".2f"",
    xticklabels=x_labels,
    yticklabels=y_labels,
)
plt.xticks(rotation=90)
plt.yticks(rotation=0)
plt.ylabel(""True class"")
plt.xlabel(""Predicted class"")
plt.tight_layout()
plt.show()'

 
markdown:
Here we focus on the diagonal and plot the numbers in a bar plot. This gives us a clearer picture of the accuracy of the model for different classes.'

 
code:
with sns.axes_style('whitegrid'):"", '    plt.figure(figsize=(8, 4))', ""    sns.barplot(x=x_labels, y=np.diag(normalize(confusion_matrix, 'true')))"", '    plt.xticks(rotation=90)
    plt.title(""Per-class accuracy"")
    plt.ylabel(""Accuracy"")
    plt.show()'

 
markdown:
**Assignment 4:** 
1. Go back and improve performance of the network. By using enough convolutional layers with enough channels (and by training for long enough), you should easily be able to get a test accuracy above 60%, but see how much further you can get it! Can you reach 70%?

2. Briefly describe what you did and any experiments you did along the way as well as what results you obtained.
Did anything surprise you during the exercise?
What were the changes that seemed to improve performance the most?

3. Write down key lessons/insights you got during this exercise.

**Answer:**'

 
markdown:
# Training on GPU",0.9351180195808411,notebook 3_4,4.0,"net.eval()
    ### Evaluate training
    train_preds, train_targs = [], []
    for i in range(num_batches_train):
        slce = get_slice(i, batch_size)
        output = net(x_train[slce])
        
        preds = torch.max(output, 1)[1]
        
        train_targs += list(targets_train[slce].numpy())
        train_preds += list(preds.data.numpy())
    
    ### Evaluate validation
    val_preds, val_targs = [], []
    for i in range(num_batches_valid):
        slce = get_slice(i, batch_size)
        
        output = net(x_valid[slce])
        preds = torch.max(output, 1)[1]
        val_targs += list(targets_valid[slce].numpy())
        val_preds += list(preds.data.numpy())
        

    train_acc_cur = accuracy_score(train_targs, train_preds)
    valid_acc_cur = accuracy_score(val_targs, val_preds)
    
    train_acc.append(train_acc_cur)
    valid_acc.append(valid_acc_cur)
    
    if epoch % 10 == 0:
        print(""Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f"" % (
                epoch+1, losses[-1], train_acc_cur, valid_acc_cur))

epoch = np.arange(len(train_acc))
plt.figure()', ""plt.plot(epoch, train_acc, 'r', epoch, valid_acc, 'b')"", ""plt.legend(['Train Accucary','Validation Accuracy'])"", ""plt.xlabel('Updates'), plt.ylabel('Acc')""]'

 
markdown:
# Assignments

Try and add these modifications (might require some Googleing -- an important skill in deep learning):
- Kaiming He initialization instead of Xavier Glorot
- add an extra layer
- use the relu activation function
- add momentum to the optimizer
- use the ADAM optimizer instead of stochastic gradient descent

### Advanced - Regularization

Regularization is VERY important in practice and is used practically every time.
Many important results are completely dependent on clever use of regularization, and it is something you need to become familiar with if you want to work with deep learning.

- add L1 or L2 weight regularization (aka. weight decay) 
- add dropout to the network (**note** the `net.train()` and `net.eval()` are already in the code)
- add batchnorm",0.9363557696342468,CourseOutline.txt,0.0,"The purpose of this course is to give the student a detailed understanding of the deep artificial neural network models, their training, computational frameworks for deployment on fast graphical processing units, their limitations and how to formulate learning in a diverse range of settings. These settings include classification, regression, sequences and other types of structured input and outputs and for reasoning in complex environments.

The course outline is:
1. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part I do it yourself on pen and paper.
2. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part II do it yourself in NumPy.
3. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part III PyTorch.
4. Convolutional neural networks (CNN) + presentation of student projects.
5. Sequence modelling for text data with Transformers.
6. Tricks of the trade and data science with PyTorch + Start of student projects.
7. Variational learning and generative adversarial networks for unsupervised and semi-supervised learning.
8. Reinforcement learning - policy gradient and deep Q-learning.

Starting from week 6 and full time from week 9 and the rest of the term will be spent on tutored project work.",0.9441598653793335,notebook 5_3,13.0,"# Plot training and validation loss
epoch = np.arange(len(training_loss))
plt.figure()', ""plt.plot(epoch, training_loss, 'r', label='Training loss',)"", ""plt.plot(epoch, validation_loss, 'b', label='Validation loss')"", 'plt.legend()', ""plt.xlabel('Epoch'), plt.ylabel('NLL')"", 'plt.show()'

 
markdown:
## Exercise E:'

 
markdown:
Complete the training loop above and run the training. You can leave the hyper-parameters and network size unchanged.

A correct implementation should yield a loss of around **1** (using mean CE) or around **4** (using sum CE) after 1000 epochs. Does it work? If not, try to identify the issue -- perhaps something in the backward pass is not right?'

 
markdown:
## Extrapolation'

 
markdown:
Now that we have trained an RNN, it's time to put it to test. We will provide the network with a starting sentence and let it `freestyle` from there!""]'

 
code:
def freestyle(params, sentence='', num_generate=10):"", '    """"""
    Takes in a sentence as a string and outputs a sequence
    based on the predictions of the RNN.
    
    Args:
     `params`: the parameters of the network
     `sentence`: string with whitespace-separated tokens
     `num_generate`: the number of tokens to generate
    """"""', ""    sentence = sentence.split(' ')"", '    
    sentence_one_hot = one_hot_encode_sequence(sentence, vocab_size)
    
    # Initialize hidden state as zeros
    hidden_state = np.zeros((hidden_size, 1))

    # Generate hidden state for sentence
    outputs, hidden_states = forward_pass(sentence_one_hot, hidden_state, params)
    
    # Output sentence
    output_sentence = sentence
    
    # Append first prediction
    word = idx_to_word[np.argmax(outputs[-1])]    
    output_sentence.append(word)
    
    # Forward pass
    for i in range(num_generate):

        # Get the latest prediction and latest hidden state
        output = outputs[-1]
        hidden_state = hidden_states[-1]
    
        # Reshape our output to match the input shape of our forward pass
        output = output.reshape(1, output.shape[0], output.shape[1])
    
        # Forward pass
        outputs, hidden_states = forward_pass(output, hidden_state, params)
        
        # Compute the index of the most likely word and look up the corresponding word
        word = idx_to_word[np.argmax(outputs)]
        
        output_sentence.append(word)
        ', ""        if word == 'EOS':"", '            break
        
    return output_sentence


# Perform freestyle (extrapolation)', ""test_examples = ['a a b
a a a a b
a a a a a a b
a
r n n']"", 'for i, test_example in enumerate(test_examples):', ""    print(f'Example {i}:', test_example)"", ""    print('Predicted sequence:', freestyle(params, sentence=test_example), end='\\')""]'

 
markdown:
## Exercise F:

How well does your RNN extrapolate -- does it work as expected? Are there any imperfections? If yes, why could that be?'

 
markdown:
## Exercise G (optional):'",0.9597211480140686,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
What are the expectations regarding the final project report and presentation?,"Structure and write a final short technical report including problem formulation, description of methods, experiments, evaluation and conclusion. Organize and present project results at the final project presentation and in report.", LearningObjectives.txt,CoursePlan.txt,4.0,"Final report deadline December 21st at 23:59. [Note this was earlier set to a later date but according to DTU rules, the latest allowed deadline is December 21st.] The report should be a maximum 6 pages plus references using this conference paper format. The report should also contain a link to your project code Github repository. Among the files in the repository should be a jupyter notebook that ideally should recreate the main results of your report. If some of your data is confidential then use some shareable data instead. For MSc students, please also include your poster in the submission.",0.5919259786605835,LearningObjectives.txt,0.0,"Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.

Understand and explain the choices and limitations of a model for a given setting.

Apply and analyze results from deep learning models in exercises and own project work.

Plan, delimit and carry out an applied or methods-oriented project in collaboration with fellow students and project supervisor.

Assess and summarize the project results in relation to aims, methods and available data.

Carry out the project and interpret results by use of computational framework for GPU programming such as PyTorch.

Structure and write a final short technical report including problem formulation, description of methods, experiments, evaluation and conclusion.

Organize and present project results at the final project presentation and in report.

Read, evaluate and give feedback to work of other students.",0.7027618885040283,CoursePlan.txt,3.0,"Week 1 computer exercise. Deadline: Monday week 2.
    Week 2 computer exercise. Deadline: Monday week 3.
    Week 3 computer exercise and 1 exercise of your own choice from course material week 1. Deadline: Monday week 4
    Week 4 computer exercise  and 1 exercise of your own choice from course material week 1-2. Deadline: Monday week 5.
    Week 5 computer exercise. Deadline: Monday week 6.
    Week 6 computer exercise. Deadline: Monday week 7.
    Week 7 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 8
    Week 8 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 9.
    Project selection. Deadline Friday, Oct 20th 2023 at 23.59.
    Link to 2023 project selection sheet
    Project synopsis. Deadline: Monday week 9 at 23:59. The synopsis should be approximately half a page and maximum one page with a project title, motivation, background, milestones and references. It is important that the plan is realistic. The main purposes of the synopsis are to make sure the project size is well-calibrated and is concrete enough to start working from day one. The synopsis will not be used in the evaluation. The synopsis should be sent to your project supervisor.
    Project poster session. PhD students taking the course as part of their PhD will not have to make a poster and take part of the poster session. In mixed groups of PhD and non-PhD students, only the non-PhD students have to take part in the poster session. The exam date is December 7th from 9 to 17. We divide the day into half hour slots and your group will later be given the possibility to register for a slot. A link to sign up for the poster session will appear here in due time. So having another exam on the same day should not be a problem. We will also organise an extra exam date for those of you who cannot make it on the date. It will be group poster presentations. We will invite outside guests and we will walk around and ask questions to all groups. We will make a schedule for when the teachers visit your poster. Plan for a 2 minute presentation per group member and 1-2 minutes for questions. The remainder of the time you can either present your poster to other students and guests or go visit other posters. Remember that it is important for the overall impression that you divide the presentation and answering of the questions more or less equally between you. The poster should be in A1 format. Remember to put both your names and student numbers under title. Here and here are links to examples using the latex template and here is one in powerpoint. You do not have to use that. The DTU library offers poster printing for a not too high price.",0.7473291158676147,CoursePlan.txt,2.0,"Handing in and peer grading six of the eight labs reports is required for being able to execute the project and eventually pass the course. If a hand-in is not passed you will be contacted with the option of re-submitting the lab directly to the teacher so if you hear nothing assume that you have passed the lab. You can also contact the teacher directly on Slack if something went wrong with the submission of the lab. Peergrade deadlines are strict so no need to write about getting an extension.

The following reports should be handed in jupyter notebook format. The weeks refer to weeks in term, and the fall break week is not counted.",0.8450481295585632,CoursePlan.txt,1.0,"You can also sign up to Google cloud (GCP) and get free credits there. Here are instructions on how to set up GPU computation on Google cloud. Follow the instructions until Optional.
Topics in the first eight weeks

    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part I do it yourself on pen and paper.
    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part II do it yourself in Python.
    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part III PyTorch.
    Convolutional neural networks (CNN)
    Transformers and recurrent neural networks (RNN)
    Tricks of the trade and data science with PyTorch
    Variational learning and generative adversarial networks for unsupervised and semi-supervised learning + deadline for selection of student projects on Friday, Oct 13th 2023 at 23.59.
    Reinforcement learning - policy gradient and deep Q-learning + start of student projects. 

Week 9-13 will be only project work

In the seven project weeks we will still meet on Mondays for project work and supervision.
Evaluation and peer grading during the course

​​Evaluation:

    The course is graded using the 7-step scale.
    The final grade is based solely on the evaluation of the final project, which starts in the 7th week of the course. The project group should consist of 3-4 students. In special circumstances we can also accept groups of 1 or 2 students. (In the course catalogue it says 1-3 students. We will correct that for next year but cannot change it now.)
    The evaluation of the final project is based on two parts, both of which are done in groups but evaluated individually:

    a poster exam presentation, where the project groups document the results of their project in a poster and present to two or more teachers acting as examiners and
    a report in which the project groups document their solution. The report should be a maximum of 6 pages plus references using this conference paper format.

More details are given below.

    The student gains access to the final project by passing 6 out of 8 lab sessions that precede it.
    A lab session is passed by:

    grading the reports from lab sessions of 3 other students on Peergrade and
    passing the lab as judged by the teacher. More details given below.

More details on peer grading: The 8 lab sessions are evaluated using peer grading. We use peer grading to ensure more accurate evaluation and better feedback. Graders get 3 reports at each deadline and have one week to carry out the feedback. If you forget to perform your peer grading it is not nice to your fellow students, but you can still pass that lab for which you forgot to grade.",0.8856679201126099,notebook 3_4,4.0,"net.eval()
    ### Evaluate training
    train_preds, train_targs = [], []
    for i in range(num_batches_train):
        slce = get_slice(i, batch_size)
        output = net(x_train[slce])
        
        preds = torch.max(output, 1)[1]
        
        train_targs += list(targets_train[slce].numpy())
        train_preds += list(preds.data.numpy())
    
    ### Evaluate validation
    val_preds, val_targs = [], []
    for i in range(num_batches_valid):
        slce = get_slice(i, batch_size)
        
        output = net(x_valid[slce])
        preds = torch.max(output, 1)[1]
        val_targs += list(targets_valid[slce].numpy())
        val_preds += list(preds.data.numpy())
        

    train_acc_cur = accuracy_score(train_targs, train_preds)
    valid_acc_cur = accuracy_score(val_targs, val_preds)
    
    train_acc.append(train_acc_cur)
    valid_acc.append(valid_acc_cur)
    
    if epoch % 10 == 0:
        print(""Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f"" % (
                epoch+1, losses[-1], train_acc_cur, valid_acc_cur))

epoch = np.arange(len(train_acc))
plt.figure()', ""plt.plot(epoch, train_acc, 'r', epoch, valid_acc, 'b')"", ""plt.legend(['Train Accucary','Validation Accuracy'])"", ""plt.xlabel('Updates'), plt.ylabel('Acc')""]'

 
markdown:
# Assignments

Try and add these modifications (might require some Googleing -- an important skill in deep learning):
- Kaiming He initialization instead of Xavier Glorot
- add an extra layer
- use the relu activation function
- add momentum to the optimizer
- use the ADAM optimizer instead of stochastic gradient descent

### Advanced - Regularization

Regularization is VERY important in practice and is used practically every time.
Many important results are completely dependent on clever use of regularization, and it is something you need to become familiar with if you want to work with deep learning.

- add L1 or L2 weight regularization (aka. weight decay) 
- add dropout to the network (**note** the `net.train()` and `net.eval()` are already in the code)
- add batchnorm",0.9264650344848633,notebook 5_1,12.0,"# project the hidden state to the vocabulary space
        logits = self.proj(hidden_states)
        return logits

    def sample(
            self,
            batch_size:int=1,
            num_steps:int=10,
            temperature: float=1.0,
            prevent_repetitions: bool=False
        ):
        token_ids = torch.empty((batch_size, 0), device=self.embeddings.weight.device, dtype=torch.long)
        for t in tqdm(range(num_steps), desc=f""Sampling {num_steps} steps..""):
            logits = self.forward(token_ids)
            logits_t = logits[:, -1:] / temperature
            if prevent_repetitions and t > 0:
                # mask the last generated tokens to avoid repetitions
                logits_t.scatter_(index=token_ids[:,-1:, None], dim=2, value=-math.inf)
            p_wt = torch.distributions.Categorical(logits=logits_t)
            tokens_t = p_wt.sample()
            token_ids = torch.cat([token_ids, tokens_t], dim=1)
        return token_ids


# init RNN initialized from GloVe vectors
# delete the checkpoint if you get `PytorchStreamReader` error
checkpoint_file = Path(""rrn-lm.ckpt"")
rnn = RNNLM(glove_vectors)
if checkpoint_file.exists():
    # checkpoint_file.unlink() # delete the checkpoint by un-commenting this line
    rnn.load_state_dict(torch.load(checkpoint_file, map_location=""cpu""))'

 
markdown:
**Testing** Let's make sure the autoregressive constrains are enforced ($\\mathbf{h}_t$ only depends on $\\mathbf{w}_{<t}$). We take differentiate a loss that depends only on a step $t = t'$ for each element $t'$ of the input batch and visualize the gradients with regards to the input word vectors (right after the embedding layers) $\\mathbf{w}_{1:T}$. The gradient map tells use which input positions are influencing the differentiated output position.""]'

 
code:
# Test whether the autoregressive constrains (h_t only depends on w_{<t}) is enforced
rnn.zero_grad()
# get dummy token ids
token_ids = torch.arange(0, 10)
token_ids = token_ids[None].repeat(10, 1)
# run through the RNN
logits = rnn(token_ids, retain_ws=True)

# compute a loss for a which depends only on step `t=i`
loss_locations = torch.arange(0, 10)[:, None, None].expand(10, 1, logits.shape[-1])
loss = logits.gather(index=loss_locations, dim=1).mean()

# backward pass and retrieve the gradients with respect to the word vectors w_{1:T}
loss.backward()
grad_magnitude = rnn.ws.grad.norm(dim=2)
rnn.ws = None",0.9285931587219238,notebook 3_3,5.0,"# plot boundary on testset before training session
plot_decision_boundary(lambda x: pred(x), X_te, y_te)
plt.title(""Untrained Classifier"")

# training loop
for e in range(num_epochs):
    # get training input and expected output as torch Variables and make sure type is correct
    tr_input = torch.from_numpy(X_tr)
    tr_targets = torch.from_numpy(onehot(y_tr, num_output)).float()
    
    # zeroize accumulated gradients in parameters
    optimizer.zero_grad()
    # predict by running forward pass
    tr_output = net(tr_input)
    # compute cross entropy loss
    tr_loss = cross_entropy(tr_output, tr_targets)
    # compute gradients given loss
    tr_loss.backward()
    # update the parameters given the computed gradients
    optimizer.step()
    train_acc = accuracy(tr_output, tr_targets)
    
    # store training loss
    train_losses.append(tr_loss.data.numpy())
    train_accs.append(train_acc)
    
    # get validation input and expected output as torch Variables and make sure type is correct
    val_input = torch.from_numpy(X_val)
    val_targets = torch.from_numpy(onehot(y_val, num_output)).float()
    
    # predict with validation input
    val_output = net(val_input)
    # compute loss and accuracy
    val_loss = cross_entropy(val_output, val_targets)
    val_acc = accuracy(val_output, val_targets)
    
    # store loss and accuracy
    val_losses.append(val_loss.data.numpy())
    val_accs.append(val_acc.data.numpy())
    
    if e % 100 == 0:
        print(""Epoch %i, ""
              ""Train Cost: %0.3f""
              ""\\tVal Cost: %0.3f""
              ""\\t Val acc: %0.3f"" % (e, 
                                     train_losses[-1],
                                     val_losses[-1],
                                     val_accs[-1]))
        
        
# get test input and expected output
te_input = torch.from_numpy(X_te)
te_targets = torch.from_numpy(onehot(y_te, num_output)).float()
# predict on testset
te_output = net(te_input)
# compute loss and accuracy
te_loss = cross_entropy(te_output, te_targets)
te_acc = accuracy(te_output, te_targets)
print(""\Test Cost: %0.3f\\tTest Accuracy: %0.3f"" % (te_loss.data.numpy(), te_acc.data.numpy()))

# plot boundary on testset after training session
plot_decision_boundary(lambda x: pred(x), X_te, y_te)
plt.title(""Trained Classifier"")

plt.figure()
epoch = np.arange(len(train_losses))', ""plt.plot(epoch, train_losses, 'r', label='Train Loss')"", ""plt.plot(epoch, val_losses, 'b', label='Val Loss')"", 'plt.legend()', ""plt.xlabel('Updates')"", ""plt.ylabel('Loss')"", 'plt.show()

plt.figure()', ""plt.plot(epoch, train_accs, 'r', label='Train Acc')"", ""plt.plot(epoch, val_accs, 'b', label='Val Acc')"", 'plt.legend()', ""plt.xlabel('Updates')"", ""plt.ylabel('Accuracy')"", 'plt.show()'

 
markdown:
# Assignments",0.9295114278793335,notebook 4_2,2.0,"code:
batch_size = 64
num_epochs = 2
validation_every_steps = 500

step = 0
model.train()

train_accuracies = []
valid_accuracies = []
        
for epoch in range(num_epochs):
    
    train_accuracies_batches = []
    
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        
        # Forward pass, compute gradients, perform one training step.
        # Your code here!
        
        # Increment step counter
        step += 1
        
        # Compute accuracy.
        predictions = output.max(1)[1]
        train_accuracies_batches.append(accuracy(targets, predictions))
        
        if step % validation_every_steps == 0:
            
            # Append average training accuracy to list.
            train_accuracies.append(np.mean(train_accuracies_batches))
            
            train_accuracies_batches = []
        
            # Compute accuracies on validation set.
            valid_accuracies_batches = []
            with torch.no_grad():
                model.eval()
                for inputs, targets in test_loader:
                    inputs, targets = inputs.to(device), targets.to(device)
                    output = model(inputs)
                    loss = loss_fn(output, targets)

                    predictions = output.max(1)[1]

                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).
                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))

                model.train()
                
            # Append average validation accuracy to list.
            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))
     
            print(f""Step {step:<5}   training accuracy: {train_accuracies[-1]}"")
            print(f""             test accuracy: {valid_accuracies[-1]}"")

print(""Finished training."")'

 
markdown:
## Test the network

Now we show a batch of test images and generate a table below with the true and predicted class for each of these images.'

 
code:
inputs, targets = next(iter(test_loader))
inputs, targets = inputs.to(device), targets.to(device)
show_image(make_grid(inputs))
plt.show()

outputs = model(inputs)
_, predicted = torch.max(outputs.data, 1)

print(""    TRUE        PREDICTED"")
print(""-----------------------------"")
for target, pred in zip(targets, predicted):
    print(f""{classes[target.item()]:^13} {classes[pred.item()]:^13}"")'

 
markdown:
We now evaluate the network as above, but on the entire test set.'

 
code:
# Evaluate test set
confusion_matrix = np.zeros((n_classes, n_classes))
with torch.no_grad():
    model.eval()
    test_accuracies = []
    for inputs, targets in test_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        output = model(inputs)
        loss = loss_fn(output, targets)

        predictions = output.max(1)[1]

        # Multiply by len(inputs) because the final batch of DataLoader may be smaller (drop_last=True).
        test_accuracies.append(accuracy(targets, predictions) * len(inputs))
        
        confusion_matrix += compute_confusion_matrix(targets, predictions)

    test_accuracy = np.sum(test_accuracies) / len(test_set)
    
    model.train()'",0.9354797601699829,notebook 8_3,4.0,"code:
# plot results
def moving_average(a, n=10) :
    ret = np.cumsum(a, dtype=float)
    ret[n:] = ret[n:] - ret[:-n]
    return ret / n

plt.figure(figsize=(16,6))
plt.subplot(211)', ""plt.plot(range(1, len(training_rewards)+1), training_rewards, label='training reward')"", 'plt.plot(moving_average(training_rewards))', ""plt.xlabel('episode'); plt.ylabel('reward')"", 'plt.xlim((0, len(training_rewards)))
plt.legend(loc=4); plt.grid()
plt.subplot(212)', ""plt.plot(range(1, len(losses)+1), losses, label='loss')"", 'plt.plot(moving_average(losses))', ""plt.xlabel('episode'); plt.ylabel('loss')"", 'plt.xlim((0, len(losses)))
plt.legend(loc=4); plt.grid()
plt.tight_layout(); plt.show()'

 
markdown:
Now let's review the solution!""]'

 
code:
env = Recorder(env, ""./gym-results"") # wrappers.Monitor(env, ""./gym-results"", force=True) # Create wrapper to display environment
s = env.reset()

for _ in range(500):
    a = policy(torch.from_numpy(np.atleast_2d(s)).float()).argmax().item()
    s, r, done, _ = env.step(a)
    if done: break
    
# env.close()
env.play()'

 
markdown:
## Reducing variance

By default, this gradient estimator has high variance and therefore variance reduction becomes important to learn more complex tasks.
We can reduce variance by subtracting a baseline from the returns, which is unbiased in expectation:

$$
\abla_\\theta \\mathbb{E}[R|\\theta] \\approx \\frac{1}{T} \\sum_{t=0}^T \abla_\\theta \\log p_\\theta(a_t|s_t) (R_t-b_t) \\ ,
$$

where the baseline, $b_t$, is estimated by the return a timestep $t$ averaged over $V$ rollouts.

$$
b_t = \\frac{1}{V} \\sum_{v=1}^V R_t^{(v)} \\ .
$$'

 
markdown:
## Exercises

Now it is your turn! Make sure you read and understand the code, then play around with it and try to make it learn better and faster.

Experiment with the:

* number of episodes
* discount factor
* learning rate
* network layers


### Exercise 1 

*Describe any changes you made to the code and why you think they improve the agent. Are you able to get solutions consistently?*

**Answer:**

*Answer here...*

### Exercise 2 

*Consider the following sequence of rewards produced by an agent interacting with an environment for 10 timesteps:*

[0, 1, 1, 1, 0, 1, 1, 0, 0, 0]

* *What is the total reward?*
* *What is the total future reward in each timestep?*
* *What is the discounted future reward in each timestep if $\\gamma = 0.9$?*

*Hint: See introdution notebook.*",0.9354962110519409,0.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0
What is the schedule for the '02456 Deep Learning 2023' course and what teaching method is used?,"Time: Mondays at 13:00-17:00 (first session is August 28th, 2023)... We use flipped classroom teaching.", CoursePlan.txt,CoursePlan.txt,0.0,"02456 Deep learning 2023 - course plan and information

Time: Mondays at 13:00-17:00 (first session is August 28th, 2023)

Locations: We will use the following rooms - building/room - (Campus map):

B303A-A042

B303A-046

B303A-047

B303A-048

B303A-HOEST

Zoom (You need to sign-in with you DTU account)

We use flipped classroom teaching. During the weeks with labs, the teachers and teaching assistants will circulate between the rooms so there will be opportunity to meet all. Any short lectures/instructions will be repeated in all rooms. You are free to choose whatever room you prefer of course respecting the limits on room capacity. During the weeks with project work each room will cover specific topics.

If you are not able to be on campus or prefer to work remotely you will be able to participate through Zoom. One teaching assistant will be dedicated to the Zoom channel: Zoom.

We also use Slack for communication: We will make dedicated channels for labs and projects. Here is a Slack invite link. (In Slack you can add channels from the list of channels by clicking the “+” next to Channels in the left panel and click “Browse channels” to choose.)

Bring a laptop.

The first eight weeks of the course will be dedicated to lab work. There will be a brief introduction to the course at the first session and a number of dedicated meetings online or in person with project supervisors.

Teachers

    Ole Winther
    Jes Frellsen

Teaching assistants

    Aleksander Nagaj
    Anders Christensen
    Anna Maria Clara Schibelle
    Anshuk Uppal
    Beatrix Miranda Ginn Nielsen
    Bo Li
    Kenny Olsen
    Marco Miani
    Nina Weng
    Paul Jeha
    Pawel Tomasz Pieta
    Raul Ortega Ochoa
    Teresa Karen Scheidt
    Thea Brüsch

Google CoLab

Google CoLab is a free cloud based Jupyter notebook platform with collaboration functionality. It even has GPUs and you don't need any credits, just log in with your Google account. To start, import a notebook using a github link or upload it from your pc: https://colab.research.google.com/. Setting up is quite straightforward. If you need to install libraries you can add that in a code cell with `! pip install <library name>`. You can upload some extra files (such as additional py scripts) that your jupyter notebook will use.
Other free GPU compute resources

It might be that Google CoLab will start putting restrictions if you use it too much. But there are alternatives:
DTU HPC

Nicklas Hansen and Aleksander Nagaj and Anna Schibelle (2023 update) have made this guide.
Google cloud platform (GCP)

You can also sign up to Google cloud (GCP) and get free credits there. Here are instructions on how to set up GPU computation on Google cloud. Follow the instructions until Optional.
Topics in the first eight weeks",0.3795384168624878,CourseOutline.txt,0.0,"The purpose of this course is to give the student a detailed understanding of the deep artificial neural network models, their training, computational frameworks for deployment on fast graphical processing units, their limitations and how to formulate learning in a diverse range of settings. These settings include classification, regression, sequences and other types of structured input and outputs and for reasoning in complex environments.

The course outline is:
1. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part I do it yourself on pen and paper.
2. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part II do it yourself in NumPy.
3. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part III PyTorch.
4. Convolutional neural networks (CNN) + presentation of student projects.
5. Sequence modelling for text data with Transformers.
6. Tricks of the trade and data science with PyTorch + Start of student projects.
7. Variational learning and generative adversarial networks for unsupervised and semi-supervised learning.
8. Reinforcement learning - policy gradient and deep Q-learning.

Starting from week 6 and full time from week 9 and the rest of the term will be spent on tutored project work.",0.5075609683990479,CoursePlan.txt,5.0,"Detailed content

Links to individual video lectures and lecture slides are given below. Here is a link to all 2016 video lectures as a playlist and a Google doc folder with all the lecture slides. More videos have been added over the years. They are all linked below. A very good alternative video resource is Hugo Larochelle’s YouTube playlist.
Week 1 - Feed-forward neural networks - do it yourself pen and paper

    During this week and the following two weeks watch video lectures: 

    Part 0 Overview
    Part 1 Deep learning
    Part 2.1 Feed-forward neural networks
    Part 2.2 Feed-forward neural networks
    Part 3 Error Backpropagation
    Part 4 Optimization

and take notes for at least 3 questions to ask. Link to lecture slides is here.

    During this week and the following two weeks read Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapters 1-3 (stop when reaching the section called Overfitting and regularization) and browse Chapter 4. Note that this is reading material for the first three weeks of the course. Also, in total six exercises of your own choice will be homework later in the course.
    Alternative textbooks: All topics are also covered in the deep learning book that may be read as a supplement. The book can also be bought from the DTU bookstore. You will get 10% discount with this link. Feed-forward neural networks are covered in this chapter. Chapter 1 gives an introduction to deep learning and Part II gives the necessary background on linear algebra, probability, numerical computation and machine learning. Alternative textbook 2: Chris Bishop, Pattern recognition and machine learning. If you need to up your game in mathematics, the book Mathematics for machine learning is an excellent resource and the note Mathematics for Machine Learning offers a concise and compressed collection of the mathematical concepts used in deep learning. These resources are freely available online and are very valuable sources of information.
    Install software on your laptop or go directly to Google CoLab (see above). Installation guide for laptop and cloud may be found here.
    Carry out computer exercises week 1. It is encouraged to work together with other students. Type in everything yourself. Code answers are fine not to differ much within the group and text answers should be in your own words. Note that the computer exercises may experience minor change up to 3 days before the actual session. The hand-in is the notebook with your modifications. It is only allowed to hand in .ipynb files. Each week you should only hand in one file. It is the file with EXE in its name. You hand in on peergrade.io. In order to be able to hand in on peergrade you can use this invitation link https://app.peergrade.io/join/JFFJBF or login into peergrade and use the invitation code JFFJBF. There you will receive information on handing in exercises and deadlines for activities. Some students have previously by accident signed up twice with different emails or forgotten the “student” in their DTU student mail address. If you then submit and check with different email addresses it will look as though you have not handed in.
    Peergrade exercise from three other students through peergrade.io. 

Week 2 - Feed-forward neural networks - do it yourself in NumPy",0.5160199999809265,LearningObjectives.txt,0.0,"Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.

Understand and explain the choices and limitations of a model for a given setting.

Apply and analyze results from deep learning models in exercises and own project work.

Plan, delimit and carry out an applied or methods-oriented project in collaboration with fellow students and project supervisor.

Assess and summarize the project results in relation to aims, methods and available data.

Carry out the project and interpret results by use of computational framework for GPU programming such as PyTorch.

Structure and write a final short technical report including problem formulation, description of methods, experiments, evaluation and conclusion.

Organize and present project results at the final project presentation and in report.

Read, evaluate and give feedback to work of other students.",0.5363016128540039,CoursePlan.txt,1.0,"You can also sign up to Google cloud (GCP) and get free credits there. Here are instructions on how to set up GPU computation on Google cloud. Follow the instructions until Optional.
Topics in the first eight weeks

    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part I do it yourself on pen and paper.
    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part II do it yourself in Python.
    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part III PyTorch.
    Convolutional neural networks (CNN)
    Transformers and recurrent neural networks (RNN)
    Tricks of the trade and data science with PyTorch
    Variational learning and generative adversarial networks for unsupervised and semi-supervised learning + deadline for selection of student projects on Friday, Oct 13th 2023 at 23.59.
    Reinforcement learning - policy gradient and deep Q-learning + start of student projects. 

Week 9-13 will be only project work

In the seven project weeks we will still meet on Mondays for project work and supervision.
Evaluation and peer grading during the course

​​Evaluation:

    The course is graded using the 7-step scale.
    The final grade is based solely on the evaluation of the final project, which starts in the 7th week of the course. The project group should consist of 3-4 students. In special circumstances we can also accept groups of 1 or 2 students. (In the course catalogue it says 1-3 students. We will correct that for next year but cannot change it now.)
    The evaluation of the final project is based on two parts, both of which are done in groups but evaluated individually:

    a poster exam presentation, where the project groups document the results of their project in a poster and present to two or more teachers acting as examiners and
    a report in which the project groups document their solution. The report should be a maximum of 6 pages plus references using this conference paper format.

More details are given below.

    The student gains access to the final project by passing 6 out of 8 lab sessions that precede it.
    A lab session is passed by:

    grading the reports from lab sessions of 3 other students on Peergrade and
    passing the lab as judged by the teacher. More details given below.

More details on peer grading: The 8 lab sessions are evaluated using peer grading. We use peer grading to ensure more accurate evaluation and better feedback. Graders get 3 reports at each deadline and have one week to carry out the feedback. If you forget to perform your peer grading it is not nice to your fellow students, but you can still pass that lab for which you forgot to grade.",0.5608553290367126,CoursePlan.txt,8.0,"Week 7 - Un- and semi-supervised learning

    Watch week 5 video lectures

    02456week5 1 1 unsupervised learning
    02456week5 1 2 unsupervised learning latent variables
    02456week5 2 1 autoencoders
    02456week5 2 2 autoencoders layerwise pretraining
    02456week5 3 1 variational autoencoders
    02456week5 3 2 semi-supervised variational autoencoders 
    2017 Generative adversarial networks
    2020 Flows
    2020 Self-supervised learning
    2020 Self-training/noisy student
    2020 Distribution Augmentation
    2020 Flat minima

and take notes for at least 3 questions to ask. Link to lecture slides 2016 slides and 2017 slides and 2020 slides.

    Reading material DL Chapter 14 and 20.10.3. (Further learning a course dedicated to generative modelling.)
    One exercise from the book chapters.
    Carry out computer exercises week 7 on autoencoder un- and semi-supervised. Hand in and peergrade on peergrade.io like in previous weeks.
    Project selection deadline is this week (see above).

Week 8 - Reinforcement learning 

    Watch week 6 video lectures 

    02456week6 1 1 reinforcement learning
    02456week6 1 2 reinforcement learning approaches
    02456week6 2 1 AlphaGo policy and value networks
    02456week6 2 2 AlphaGo steps 1 to 4
    02456week6 3 policy gradients
    02456week6 4 a few last words
    2017 Deep Q learning
    2017 Evolutionary strategies

and take notes for at least 3 questions to ask. Link to lectures here and here for 2017 update.

    Reading: another nice blog post by Andrei Karpathy. Optional reading material on the connection between variational and reinforcement learning.
    One exercise from the book chapters. 
    Computer exercises on reinforcement learning methods (policy gradient, deep Q learning, evolutionary strategies) in the openAI Gym. Carry out exercises week 8. Hand in and peergrade on peergrade.io like in previous weeks.
    Project work.",0.5814615488052368,CoursePlan.txt,6.0,"Week 2 - Feed-forward neural networks - do it yourself in NumPy

    See 1. and 2. from Week 1.
    Carry out computer exercises week 2.
    Peergrade exercise from three other students through peergrade.io. 

Week 3 - Feed-forward neural networks in PyTorch

    See 1. and 2. from Week 1.
    Carry out computer exercises week 3.
    Peergrade exercise from three other students through peergrade.io.
    Hand in the notebook marked with EXE on peergrade.io. It should contain your added code in the exercises and the answer of one exercise from Michael Nielsen's book (see point 3. above). The answer to the book exercise should be in a markdown cell at the bottom of the notebook.
    Peergrade exercise from three other students through peergrade.io.  

Week 4 - Convolutional neural networks

    Watch week 2 video lectures  

    Part 1 Introduction to CNNs (PART 1/2)
    Part 1 Introduction to CNNs (PART 2/2)
    Part 2 CNNs the details (PART 1/2)
    Part 2 CNNs the details (PART 2/2)
    2017 CNN update
    2017 Activation functions update
    2017 Image segmentation

and take notes for at least 3 questions to ask. Link to lecture slides is here and here for 2017 updates.

    Reading material Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapter 6 (stop when reaching section called Other approaches to deep neural nets).
    Alternative textbook chapter in the deep learning book.
    One exercise from the book chapters.
    Carry out computer exercises week 4.
    Hand in the notebook marked with EXE on peergrade.io.
    Peergrade exercise from three other students through peergrade.io. You will receive instructions about this from peergrade.io.

Week 5 - Transformers and recurrent neural networks

    Watch week 3 video lectures

    02456week3 1 RNN (PART 1 of 3)
    02456week3 1 RNN (PART 2 of 3)
    02456week3 1 RNN (PART 3 of 3)
    02456week3.2_RNN_training (PART 1 of 3)
    02456week3.2_RNN_training (PART 2 of 3)
    02456week3 2 RNN training (PART 3 of 3)
    02456week3 3 Attention (PART 1 of 2)
    02456week3 3 Attention (PART 2 of 2)
    02456week3 4 Supervised learning recap
    2017 Quasi RNN
    2017 Non-recurrent sequence to sequence models
    2017 Text summarization
    2020 Transformers (PART 1 of 2)
    2020 Transformers (PART 2 of 2)
    2020 Language modelling - GPT-2 and 3
    2020 BERT

and take notes for at least 3 questions to ask. Link to: 2016 lectures, 2017 lecture updates and 2020 lecture updates.",0.5904198884963989,CoursePlan.txt,7.0,"and take notes for at least 3 questions to ask. Link to: 2016 lectures, 2017 lecture updates and 2020 lecture updates.

    Reading material Alex Graves book, Supervised Sequence Labelling with Recurrent Neural Networks Chapters 3.1, 3.2 and 4. Browse Michael Nielsen, Neural networks and deep learning Chapter 6 section Other approaches to deep neural nets) and onwards. A good introduction to Transformers is The Illustrated Transformer. New tutorial on Transformers https://aman.ai/primers/ai/transformers/#one-hot-encoding
    Alternative textbook chapter in the deep learning book. Andrej Karpathy has a nice blogpost that gives a good flavour of the whats and hows of RNNs.
    Carry out computer exercises week 5
    Hand in and peergrade on peergrade.io like in previous week.

Week 6 - Tricks of the trade and data science challenge

    Watch week 4 video lectures 

    02456week4 1 1 Initialization and gradient clipping 
    02456week4 1 2 batch normalization
    02456week4 2 1 regularization
    02456week4 2 2 regularization methods
    02456week4 2 3 data augmentation
    02456week4 2 4 ensemble methods and dropout
    02456week4 3 recap
    2017 37 reasons your nn working (part 1 of 2) Walk through of the 37 reasons why your neural network is not working blog post.
    2017 37 reasons you not working (part 2 of 2)
    2020 Recipe to training neural networks - become one with data (part 1 of 3).
    2020 Recipe to training neural networks - baselines (part 2 of 3).
    2020 Recipe to training neural networks - overfit, tune and tune some more (part 3 of 3).

and take notes for at least 3 questions to ask. Link to lecture slides 2016 lecture slides, 2017 blog post and 2020 lecture slides.  

    Reading material Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapter 3 from section Overfitting and regularization and Chapter 5.
    Alternative textbook chapters on regularization, optimization, deep learning practice and applications from the deep learning book.  
    Additional material: Andrei Karpathy blogpost on how to approach a data science problem with deep learning, blogpost on things that can go wrong in neural network training and interactive initialization demo.
    Computer exercises week 6 using PyTorch on the Kaggle competition leaf classification. Hand in and peergrade on peergrade.io like in previous weeks.

Week 7 - Un- and semi-supervised learning

    Watch week 5 video lectures",0.598605215549469,notebook 3_4,4.0,"net.eval()
    ### Evaluate training
    train_preds, train_targs = [], []
    for i in range(num_batches_train):
        slce = get_slice(i, batch_size)
        output = net(x_train[slce])
        
        preds = torch.max(output, 1)[1]
        
        train_targs += list(targets_train[slce].numpy())
        train_preds += list(preds.data.numpy())
    
    ### Evaluate validation
    val_preds, val_targs = [], []
    for i in range(num_batches_valid):
        slce = get_slice(i, batch_size)
        
        output = net(x_valid[slce])
        preds = torch.max(output, 1)[1]
        val_targs += list(targets_valid[slce].numpy())
        val_preds += list(preds.data.numpy())
        

    train_acc_cur = accuracy_score(train_targs, train_preds)
    valid_acc_cur = accuracy_score(val_targs, val_preds)
    
    train_acc.append(train_acc_cur)
    valid_acc.append(valid_acc_cur)
    
    if epoch % 10 == 0:
        print(""Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f"" % (
                epoch+1, losses[-1], train_acc_cur, valid_acc_cur))

epoch = np.arange(len(train_acc))
plt.figure()', ""plt.plot(epoch, train_acc, 'r', epoch, valid_acc, 'b')"", ""plt.legend(['Train Accucary','Validation Accuracy'])"", ""plt.xlabel('Updates'), plt.ylabel('Acc')""]'

 
markdown:
# Assignments

Try and add these modifications (might require some Googleing -- an important skill in deep learning):
- Kaiming He initialization instead of Xavier Glorot
- add an extra layer
- use the relu activation function
- add momentum to the optimizer
- use the ADAM optimizer instead of stochastic gradient descent

### Advanced - Regularization

Regularization is VERY important in practice and is used practically every time.
Many important results are completely dependent on clever use of regularization, and it is something you need to become familiar with if you want to work with deep learning.

- add L1 or L2 weight regularization (aka. weight decay) 
- add dropout to the network (**note** the `net.train()` and `net.eval()` are already in the code)
- add batchnorm",0.642799973487854,notebook 5_3,23.0,"markdown:
### Training loop'

 
markdown:
It's time for us to train our network. In the section below, you will get to put your deep learning skills to use and create your own training loop. You may want to consult previous exercises if you cannot recall how to define the training loop.""]'

 
code:
# Hyper-parameters
num_epochs = 200

# Initialize a new network
net = MyRecurrentNet()

# Define a loss function and optimizer for this problem
# YOUR CODE HERE!
criterion = 
optimizer = 

# Track loss
training_loss, validation_loss = [], []

# For each epoch
for i in range(num_epochs):
    
    # Track loss
    epoch_training_loss = 0
    epoch_validation_loss = 0
    
    net.eval()
        
    # For each sentence in validation set
    for inputs, targets in validation_set:
        
        # One-hot encode input and target sequence
        inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
        targets_idx = [word_to_idx[word] for word in targets]
        
        # Convert input to tensor
        inputs_one_hot = torch.Tensor(inputs_one_hot)
        inputs_one_hot = inputs_one_hot.permute(0, 2, 1)
        
        # Convert target to tensor
        targets_idx = torch.LongTensor(targets_idx)
        
        # Forward pass
        # YOUR CODE HERE!
        outputs = 
        
        # Compute loss
        # YOUR CODE HERE!
        loss = 
        
        # Update loss
        epoch_validation_loss += loss.detach().numpy()
    
    net.train()
    
    # For each sentence in training set
    for inputs, targets in training_set:
        
        # One-hot encode input and target sequence
        inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
        targets_idx = [word_to_idx[word] for word in targets]
        
        # Convert input to tensor
        inputs_one_hot = torch.Tensor(inputs_one_hot)
        inputs_one_hot = inputs_one_hot.permute(0, 2, 1)
        
        # Convert target to tensor
        targets_idx = torch.LongTensor(targets_idx)
        
        # Forward pass
        # YOUR CODE HERE!
        outputs = 
        
        # Compute loss
        # YOUR CODE HERE!
        loss = 
        
        # Backward pass
        # YOUR CODE HERE!
        # zero grad, backward, step...
        
        # Update loss
        epoch_training_loss += loss.detach().numpy()
        
    # Save loss for plot
    training_loss.append(epoch_training_loss/len(training_set))
    validation_loss.append(epoch_validation_loss/len(validation_set))

    # Print loss every 10 epochs
    if i % 10 == 0:', ""        print(f'Epoch {i}, training loss: {training_loss[-1]}, validation loss: {validation_loss[-1]}')"", '
        
# Get first sentence in test set
inputs, targets = test_set[1]

# One-hot encode input and target sequence
inputs_one_hot = one_hot_encode_sequence(inputs, vocab_size)
targets_idx = [word_to_idx[word] for word in targets]

# Convert input to tensor
inputs_one_hot = torch.Tensor(inputs_one_hot)
inputs_one_hot = inputs_one_hot.permute(0, 2, 1)",0.6451147198677063,1.0,1.0,2.0,2.0,3.0,4.0,5.0,6.0,6.0,6.0
What are the requirements for students to gain access to the final project in the '02456 Deep Learning 2023' course?,The student gains access to the final project by passing 6 out of 8 lab sessions that precede it. A lab session is passed by: grading the reports from lab sessions of 3 other students on Peergrade and passing the lab as judged by the teacher, CoursePlan.txt,CoursePlan.txt,0.0,"02456 Deep learning 2023 - course plan and information

Time: Mondays at 13:00-17:00 (first session is August 28th, 2023)

Locations: We will use the following rooms - building/room - (Campus map):

B303A-A042

B303A-046

B303A-047

B303A-048

B303A-HOEST

Zoom (You need to sign-in with you DTU account)

We use flipped classroom teaching. During the weeks with labs, the teachers and teaching assistants will circulate between the rooms so there will be opportunity to meet all. Any short lectures/instructions will be repeated in all rooms. You are free to choose whatever room you prefer of course respecting the limits on room capacity. During the weeks with project work each room will cover specific topics.

If you are not able to be on campus or prefer to work remotely you will be able to participate through Zoom. One teaching assistant will be dedicated to the Zoom channel: Zoom.

We also use Slack for communication: We will make dedicated channels for labs and projects. Here is a Slack invite link. (In Slack you can add channels from the list of channels by clicking the “+” next to Channels in the left panel and click “Browse channels” to choose.)

Bring a laptop.

The first eight weeks of the course will be dedicated to lab work. There will be a brief introduction to the course at the first session and a number of dedicated meetings online or in person with project supervisors.

Teachers

    Ole Winther
    Jes Frellsen

Teaching assistants

    Aleksander Nagaj
    Anders Christensen
    Anna Maria Clara Schibelle
    Anshuk Uppal
    Beatrix Miranda Ginn Nielsen
    Bo Li
    Kenny Olsen
    Marco Miani
    Nina Weng
    Paul Jeha
    Pawel Tomasz Pieta
    Raul Ortega Ochoa
    Teresa Karen Scheidt
    Thea Brüsch

Google CoLab

Google CoLab is a free cloud based Jupyter notebook platform with collaboration functionality. It even has GPUs and you don't need any credits, just log in with your Google account. To start, import a notebook using a github link or upload it from your pc: https://colab.research.google.com/. Setting up is quite straightforward. If you need to install libraries you can add that in a code cell with `! pip install <library name>`. You can upload some extra files (such as additional py scripts) that your jupyter notebook will use.
Other free GPU compute resources

It might be that Google CoLab will start putting restrictions if you use it too much. But there are alternatives:
DTU HPC

Nicklas Hansen and Aleksander Nagaj and Anna Schibelle (2023 update) have made this guide.
Google cloud platform (GCP)

You can also sign up to Google cloud (GCP) and get free credits there. Here are instructions on how to set up GPU computation on Google cloud. Follow the instructions until Optional.
Topics in the first eight weeks",0.421761155128479,LearningObjectives.txt,0.0,"Demonstrate knowledge of machine learning terminology such as likelihood function, maximum likelihood, Bayesian inference, feed-forward, convolutional and Transformer neural networks, and error back propagation.

Understand and explain the choices and limitations of a model for a given setting.

Apply and analyze results from deep learning models in exercises and own project work.

Plan, delimit and carry out an applied or methods-oriented project in collaboration with fellow students and project supervisor.

Assess and summarize the project results in relation to aims, methods and available data.

Carry out the project and interpret results by use of computational framework for GPU programming such as PyTorch.

Structure and write a final short technical report including problem formulation, description of methods, experiments, evaluation and conclusion.

Organize and present project results at the final project presentation and in report.

Read, evaluate and give feedback to work of other students.",0.44861432909965515,CoursePlan.txt,1.0,"You can also sign up to Google cloud (GCP) and get free credits there. Here are instructions on how to set up GPU computation on Google cloud. Follow the instructions until Optional.
Topics in the first eight weeks

    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part I do it yourself on pen and paper.
    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part II do it yourself in Python.
    Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part III PyTorch.
    Convolutional neural networks (CNN)
    Transformers and recurrent neural networks (RNN)
    Tricks of the trade and data science with PyTorch
    Variational learning and generative adversarial networks for unsupervised and semi-supervised learning + deadline for selection of student projects on Friday, Oct 13th 2023 at 23.59.
    Reinforcement learning - policy gradient and deep Q-learning + start of student projects. 

Week 9-13 will be only project work

In the seven project weeks we will still meet on Mondays for project work and supervision.
Evaluation and peer grading during the course

​​Evaluation:

    The course is graded using the 7-step scale.
    The final grade is based solely on the evaluation of the final project, which starts in the 7th week of the course. The project group should consist of 3-4 students. In special circumstances we can also accept groups of 1 or 2 students. (In the course catalogue it says 1-3 students. We will correct that for next year but cannot change it now.)
    The evaluation of the final project is based on two parts, both of which are done in groups but evaluated individually:

    a poster exam presentation, where the project groups document the results of their project in a poster and present to two or more teachers acting as examiners and
    a report in which the project groups document their solution. The report should be a maximum of 6 pages plus references using this conference paper format.

More details are given below.

    The student gains access to the final project by passing 6 out of 8 lab sessions that precede it.
    A lab session is passed by:

    grading the reports from lab sessions of 3 other students on Peergrade and
    passing the lab as judged by the teacher. More details given below.

More details on peer grading: The 8 lab sessions are evaluated using peer grading. We use peer grading to ensure more accurate evaluation and better feedback. Graders get 3 reports at each deadline and have one week to carry out the feedback. If you forget to perform your peer grading it is not nice to your fellow students, but you can still pass that lab for which you forgot to grade.",0.5176016092300415,CourseOutline.txt,0.0,"The purpose of this course is to give the student a detailed understanding of the deep artificial neural network models, their training, computational frameworks for deployment on fast graphical processing units, their limitations and how to formulate learning in a diverse range of settings. These settings include classification, regression, sequences and other types of structured input and outputs and for reasoning in complex environments.

The course outline is:
1. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part I do it yourself on pen and paper.
2. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part II do it yourself in NumPy.
3. Introduction to statistical machine learning, feed-forward neural networks (FFNN) and error back-propagation. Part III PyTorch.
4. Convolutional neural networks (CNN) + presentation of student projects.
5. Sequence modelling for text data with Transformers.
6. Tricks of the trade and data science with PyTorch + Start of student projects.
7. Variational learning and generative adversarial networks for unsupervised and semi-supervised learning.
8. Reinforcement learning - policy gradient and deep Q-learning.

Starting from week 6 and full time from week 9 and the rest of the term will be spent on tutored project work.",0.548279881477356,CoursePlan.txt,5.0,"Detailed content

Links to individual video lectures and lecture slides are given below. Here is a link to all 2016 video lectures as a playlist and a Google doc folder with all the lecture slides. More videos have been added over the years. They are all linked below. A very good alternative video resource is Hugo Larochelle’s YouTube playlist.
Week 1 - Feed-forward neural networks - do it yourself pen and paper

    During this week and the following two weeks watch video lectures: 

    Part 0 Overview
    Part 1 Deep learning
    Part 2.1 Feed-forward neural networks
    Part 2.2 Feed-forward neural networks
    Part 3 Error Backpropagation
    Part 4 Optimization

and take notes for at least 3 questions to ask. Link to lecture slides is here.

    During this week and the following two weeks read Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapters 1-3 (stop when reaching the section called Overfitting and regularization) and browse Chapter 4. Note that this is reading material for the first three weeks of the course. Also, in total six exercises of your own choice will be homework later in the course.
    Alternative textbooks: All topics are also covered in the deep learning book that may be read as a supplement. The book can also be bought from the DTU bookstore. You will get 10% discount with this link. Feed-forward neural networks are covered in this chapter. Chapter 1 gives an introduction to deep learning and Part II gives the necessary background on linear algebra, probability, numerical computation and machine learning. Alternative textbook 2: Chris Bishop, Pattern recognition and machine learning. If you need to up your game in mathematics, the book Mathematics for machine learning is an excellent resource and the note Mathematics for Machine Learning offers a concise and compressed collection of the mathematical concepts used in deep learning. These resources are freely available online and are very valuable sources of information.
    Install software on your laptop or go directly to Google CoLab (see above). Installation guide for laptop and cloud may be found here.
    Carry out computer exercises week 1. It is encouraged to work together with other students. Type in everything yourself. Code answers are fine not to differ much within the group and text answers should be in your own words. Note that the computer exercises may experience minor change up to 3 days before the actual session. The hand-in is the notebook with your modifications. It is only allowed to hand in .ipynb files. Each week you should only hand in one file. It is the file with EXE in its name. You hand in on peergrade.io. In order to be able to hand in on peergrade you can use this invitation link https://app.peergrade.io/join/JFFJBF or login into peergrade and use the invitation code JFFJBF. There you will receive information on handing in exercises and deadlines for activities. Some students have previously by accident signed up twice with different emails or forgotten the “student” in their DTU student mail address. If you then submit and check with different email addresses it will look as though you have not handed in.
    Peergrade exercise from three other students through peergrade.io. 

Week 2 - Feed-forward neural networks - do it yourself in NumPy",0.5902082920074463,CoursePlan.txt,6.0,"Week 2 - Feed-forward neural networks - do it yourself in NumPy

    See 1. and 2. from Week 1.
    Carry out computer exercises week 2.
    Peergrade exercise from three other students through peergrade.io. 

Week 3 - Feed-forward neural networks in PyTorch

    See 1. and 2. from Week 1.
    Carry out computer exercises week 3.
    Peergrade exercise from three other students through peergrade.io.
    Hand in the notebook marked with EXE on peergrade.io. It should contain your added code in the exercises and the answer of one exercise from Michael Nielsen's book (see point 3. above). The answer to the book exercise should be in a markdown cell at the bottom of the notebook.
    Peergrade exercise from three other students through peergrade.io.  

Week 4 - Convolutional neural networks

    Watch week 2 video lectures  

    Part 1 Introduction to CNNs (PART 1/2)
    Part 1 Introduction to CNNs (PART 2/2)
    Part 2 CNNs the details (PART 1/2)
    Part 2 CNNs the details (PART 2/2)
    2017 CNN update
    2017 Activation functions update
    2017 Image segmentation

and take notes for at least 3 questions to ask. Link to lecture slides is here and here for 2017 updates.

    Reading material Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapter 6 (stop when reaching section called Other approaches to deep neural nets).
    Alternative textbook chapter in the deep learning book.
    One exercise from the book chapters.
    Carry out computer exercises week 4.
    Hand in the notebook marked with EXE on peergrade.io.
    Peergrade exercise from three other students through peergrade.io. You will receive instructions about this from peergrade.io.

Week 5 - Transformers and recurrent neural networks

    Watch week 3 video lectures

    02456week3 1 RNN (PART 1 of 3)
    02456week3 1 RNN (PART 2 of 3)
    02456week3 1 RNN (PART 3 of 3)
    02456week3.2_RNN_training (PART 1 of 3)
    02456week3.2_RNN_training (PART 2 of 3)
    02456week3 2 RNN training (PART 3 of 3)
    02456week3 3 Attention (PART 1 of 2)
    02456week3 3 Attention (PART 2 of 2)
    02456week3 4 Supervised learning recap
    2017 Quasi RNN
    2017 Non-recurrent sequence to sequence models
    2017 Text summarization
    2020 Transformers (PART 1 of 2)
    2020 Transformers (PART 2 of 2)
    2020 Language modelling - GPT-2 and 3
    2020 BERT

and take notes for at least 3 questions to ask. Link to: 2016 lectures, 2017 lecture updates and 2020 lecture updates.",0.6390868425369263,CoursePlan.txt,7.0,"and take notes for at least 3 questions to ask. Link to: 2016 lectures, 2017 lecture updates and 2020 lecture updates.

    Reading material Alex Graves book, Supervised Sequence Labelling with Recurrent Neural Networks Chapters 3.1, 3.2 and 4. Browse Michael Nielsen, Neural networks and deep learning Chapter 6 section Other approaches to deep neural nets) and onwards. A good introduction to Transformers is The Illustrated Transformer. New tutorial on Transformers https://aman.ai/primers/ai/transformers/#one-hot-encoding
    Alternative textbook chapter in the deep learning book. Andrej Karpathy has a nice blogpost that gives a good flavour of the whats and hows of RNNs.
    Carry out computer exercises week 5
    Hand in and peergrade on peergrade.io like in previous week.

Week 6 - Tricks of the trade and data science challenge

    Watch week 4 video lectures 

    02456week4 1 1 Initialization and gradient clipping 
    02456week4 1 2 batch normalization
    02456week4 2 1 regularization
    02456week4 2 2 regularization methods
    02456week4 2 3 data augmentation
    02456week4 2 4 ensemble methods and dropout
    02456week4 3 recap
    2017 37 reasons your nn working (part 1 of 2) Walk through of the 37 reasons why your neural network is not working blog post.
    2017 37 reasons you not working (part 2 of 2)
    2020 Recipe to training neural networks - become one with data (part 1 of 3).
    2020 Recipe to training neural networks - baselines (part 2 of 3).
    2020 Recipe to training neural networks - overfit, tune and tune some more (part 3 of 3).

and take notes for at least 3 questions to ask. Link to lecture slides 2016 lecture slides, 2017 blog post and 2020 lecture slides.  

    Reading material Michael Nielsen, Neural networks and deep learning http://neuralnetworksanddeeplearning.com/ Chapter 3 from section Overfitting and regularization and Chapter 5.
    Alternative textbook chapters on regularization, optimization, deep learning practice and applications from the deep learning book.  
    Additional material: Andrei Karpathy blogpost on how to approach a data science problem with deep learning, blogpost on things that can go wrong in neural network training and interactive initialization demo.
    Computer exercises week 6 using PyTorch on the Kaggle competition leaf classification. Hand in and peergrade on peergrade.io like in previous weeks.

Week 7 - Un- and semi-supervised learning

    Watch week 5 video lectures",0.6554598808288574,notebook 3_4,4.0,"net.eval()
    ### Evaluate training
    train_preds, train_targs = [], []
    for i in range(num_batches_train):
        slce = get_slice(i, batch_size)
        output = net(x_train[slce])
        
        preds = torch.max(output, 1)[1]
        
        train_targs += list(targets_train[slce].numpy())
        train_preds += list(preds.data.numpy())
    
    ### Evaluate validation
    val_preds, val_targs = [], []
    for i in range(num_batches_valid):
        slce = get_slice(i, batch_size)
        
        output = net(x_valid[slce])
        preds = torch.max(output, 1)[1]
        val_targs += list(targets_valid[slce].numpy())
        val_preds += list(preds.data.numpy())
        

    train_acc_cur = accuracy_score(train_targs, train_preds)
    valid_acc_cur = accuracy_score(val_targs, val_preds)
    
    train_acc.append(train_acc_cur)
    valid_acc.append(valid_acc_cur)
    
    if epoch % 10 == 0:
        print(""Epoch %2i : Train Loss %f , Train acc %f, Valid acc %f"" % (
                epoch+1, losses[-1], train_acc_cur, valid_acc_cur))

epoch = np.arange(len(train_acc))
plt.figure()', ""plt.plot(epoch, train_acc, 'r', epoch, valid_acc, 'b')"", ""plt.legend(['Train Accucary','Validation Accuracy'])"", ""plt.xlabel('Updates'), plt.ylabel('Acc')""]'

 
markdown:
# Assignments

Try and add these modifications (might require some Googleing -- an important skill in deep learning):
- Kaiming He initialization instead of Xavier Glorot
- add an extra layer
- use the relu activation function
- add momentum to the optimizer
- use the ADAM optimizer instead of stochastic gradient descent

### Advanced - Regularization

Regularization is VERY important in practice and is used practically every time.
Many important results are completely dependent on clever use of regularization, and it is something you need to become familiar with if you want to work with deep learning.

- add L1 or L2 weight regularization (aka. weight decay) 
- add dropout to the network (**note** the `net.train()` and `net.eval()` are already in the code)
- add batchnorm",0.673926055431366,CoursePlan.txt,3.0,"Week 1 computer exercise. Deadline: Monday week 2.
    Week 2 computer exercise. Deadline: Monday week 3.
    Week 3 computer exercise and 1 exercise of your own choice from course material week 1. Deadline: Monday week 4
    Week 4 computer exercise  and 1 exercise of your own choice from course material week 1-2. Deadline: Monday week 5.
    Week 5 computer exercise. Deadline: Monday week 6.
    Week 6 computer exercise. Deadline: Monday week 7.
    Week 7 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 8
    Week 8 computer exercise  and 1 exercise of your own choice from course material week 1-3. Deadline: Monday week 9.
    Project selection. Deadline Friday, Oct 20th 2023 at 23.59.
    Link to 2023 project selection sheet
    Project synopsis. Deadline: Monday week 9 at 23:59. The synopsis should be approximately half a page and maximum one page with a project title, motivation, background, milestones and references. It is important that the plan is realistic. The main purposes of the synopsis are to make sure the project size is well-calibrated and is concrete enough to start working from day one. The synopsis will not be used in the evaluation. The synopsis should be sent to your project supervisor.
    Project poster session. PhD students taking the course as part of their PhD will not have to make a poster and take part of the poster session. In mixed groups of PhD and non-PhD students, only the non-PhD students have to take part in the poster session. The exam date is December 7th from 9 to 17. We divide the day into half hour slots and your group will later be given the possibility to register for a slot. A link to sign up for the poster session will appear here in due time. So having another exam on the same day should not be a problem. We will also organise an extra exam date for those of you who cannot make it on the date. It will be group poster presentations. We will invite outside guests and we will walk around and ask questions to all groups. We will make a schedule for when the teachers visit your poster. Plan for a 2 minute presentation per group member and 1-2 minutes for questions. The remainder of the time you can either present your poster to other students and guests or go visit other posters. Remember that it is important for the overall impression that you divide the presentation and answering of the questions more or less equally between you. The poster should be in A1 format. Remember to put both your names and student numbers under title. Here and here are links to examples using the latex template and here is one in powerpoint. You do not have to use that. The DTU library offers poster printing for a not too high price.",0.6789658069610596,notebook 4_3,5.0,"num_trainable_model_parameters = 0
    for p in model.parameters():
        if p.requires_grad:
            num_trainable_model_parameters += p.numel()

    return model, {
        ""num_model_parameters"": num_model_parameters,
        ""num_trainable_model_parameters"": num_trainable_model_parameters,
    }
', ""model, data = initialize_model('resnet34d', num_classes=len(np.unique(labels)), finetune_entire_model=False)"", '
print(model)
print(""Number of model parameters:"", data[""num_model_parameters""])
print(""Number of trainable parameters:"", data[""num_trainable_model_parameters""])
', ""device = torch.device('cuda')  # use cuda or cpu"", 'model = model.to(device)'

 
markdown:
**Assignment 3:** 

1. Train the linear classifier on top of the pre-trained network, and observe how quickly you can get pretty good results, compared to training a smaller network from scratch as above.

2. Go back and change argument to finetune entire network, maybe adjust learning rate, see if you can get better performance than before and if you run into any issues.

3. Optional: experiment with `timm`: try smaller or larger models, including state-of-the-art models, e.g. based on vision transformers (ViT) or MLP-Mixers.

4. Briefly describe what you did and any experiments you did along the way as well as what results you obtained.
Did anything surprise you during the exercise?

5. Write down key lessons/insights you got during this exercise.'

 
code:
'[]'",0.6849684715270996,1.0,1.0,2.0,2.0,3.0,4.0,5.0,5.0,6.0,6.0
